{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tree.ctutils as ctu\n",
    "from tree import treeutils\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "# Calculate merger event parameters\n",
    "def find_merger(atree, idx=None, aexp_min=0.0):\n",
    "    \"\"\"\n",
    "        find indices of merger event from a tree.\n",
    "        (Full tree or main progenitor trunk)\n",
    "    \"\"\"\n",
    "    if idx == None:\n",
    "        idx = atree['id'][0]\n",
    "        \n",
    "    nprg = 1\n",
    "    merger_list=[]\n",
    "\n",
    "    i = 0\n",
    "    while nprg > 0:\n",
    "        idx = ctu.get_progenitors(atree, idx, main=True)[0]\n",
    "        ind = np.where(atree['id'] == idx)[0]\n",
    "        if atree['aexp'][ind] < aexp_min:\n",
    "            break\n",
    "        nprg = ctu.get_npr(atree, idx)\n",
    "\n",
    "        if nprg > 1:\n",
    "            merger_list.append(i)\n",
    "        i +=1\n",
    "    return merger_list\n",
    "\n",
    "\n",
    "def merger_mass_ratio(atree, idx=None):\n",
    "    \"\"\"\n",
    "    return mass ratio of the given merger event\n",
    "    \"\"\"\n",
    "    if idx == None:\n",
    "        idx = atree['id'][0]\n",
    "        \n",
    "    prgs = ctu.get_progenitors(atree, idx)\n",
    "    \n",
    "    # only for mergers\n",
    "    if len(prgs) > 1:\n",
    "        i_prgs = [np.where(atree['id'] == i)[0] for i in prgs]\n",
    "        mass = []\n",
    "        for iprg in i_prgs:\n",
    "            mass.append(atree['m'])\n",
    "    else:\n",
    "        print(\"This is not a merger\")\n",
    "        return 0\n",
    "    \n",
    "\n",
    "def merger_properties_main_prg(atree, idx):\n",
    "    \"\"\"\n",
    "        Calculate merger mass ratio for \"one\" merger event.\n",
    "\n",
    "    if idx == None:\n",
    "        if nout == None:\n",
    "            print(\"Both idx and nout are missing\")\n",
    "            return\n",
    "    else:\n",
    "        if nout == None:\n",
    "            nout = np.where(atree['id'] == idx)[0]\n",
    "\n",
    "    idx = atree['id'][ind]\n",
    "    \"\"\"    \n",
    "\n",
    "    #prgs = get_progenitors(atree, idx)\n",
    "    #if len(prgs) > 1:\n",
    "    #    i_prgs = [np.where(atree['id'] == i)[0] for i in prgs]\n",
    "    \n",
    "    i_prgs = np.where(atree['desc_id'] == idx)[0]\n",
    "        \n",
    "    print(i_prgs)\n",
    "    id_prgs = atree['id'][i_prgs]\n",
    "    mass_prgs = atree['m'][i_prgs]\n",
    "    \n",
    "    #mass_prgs_norm = mass_prgs / sum(mass_prgs)\n",
    "\n",
    "    return mass_prgs\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def distance_to(xc, xx):\n",
    "    import numpy as np\n",
    "    return np.sqrt([(xc[0] - xx[0])**2 + (xc[1] - xx[1])**2 + (xc[2] - xx[2])**2])[0]\n",
    "\n",
    "def extract_halos_within(halos, i_center, info, dist_in_mpc=1.0):\n",
    "\n",
    "    xc = halos['x'][i_center]\n",
    "    yc = halos['y'][i_center]\n",
    "    zc = halos['z'][i_center]\n",
    "\n",
    "    xx = halos['x']\n",
    "    yy = halos['y']\n",
    "    zz = halos['z']\n",
    "\n",
    "    dd = np.multiply(distance_to([xc,yc,zc], [xx,yy,zz]), info.pboxsize)\n",
    "\n",
    "    return (dd < (dist_in_mpc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded an extended tree\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/hoseung/Work/data/36413/snapshots/output_00187/info_00187.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-9247f110cc0c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     45\u001b[0m     \u001b[1;31m#allgals = ft['id'][ft['m'] > 5e9]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m     \u001b[0minfo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnout_fi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbase\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mwdir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mload\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m     \u001b[0mcat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwdir\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'catalog_GM/catalog'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnout_fi\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'.pickle'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m     \u001b[0mfinal_gals_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcat\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'idx'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/hoseung/Copy/pyclusterevol/load/info.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, nout, base, fn, load)\u001b[0m\n\u001b[0;32m     12\u001b[0m                  fn = None, load=False):\n\u001b[0;32m     13\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mbase\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbase\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbase\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mload\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/hoseung/Copy/pyclusterevol/load/info.py\u001b[0m in \u001b[0;36msetup\u001b[1;34m(self, nout, base, fn)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mall_set\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# sets ncpu_tot,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/hoseung/Copy/pyclusterevol/load/info.py\u001b[0m in \u001b[0;36mread_info\u001b[1;34m(self, base, nout, verbose)\u001b[0m\n\u001b[0;32m    147\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mread_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbase\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    148\u001b[0m         \u001b[1;34m\"\"\" backward compatibility. but use .load instead\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 149\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbase\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbase\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    150\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    151\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbase\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/hoseung/Copy/pyclusterevol/load/info.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(self, base, nout, verbose)\u001b[0m\n\u001b[0;32m    170\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    171\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 172\u001b[1;33m         \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    173\u001b[0m             \u001b[0marr1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    174\u001b[0m             \u001b[0marr2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/hoseung/Work/data/36413/snapshots/output_00187/info_00187.txt'"
     ]
    }
   ],
   "source": [
    "import utils.match as mtc\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import tree.ctutils as ctu\n",
    "import load \n",
    "import tree.halomodule as hmo\n",
    "\n",
    "\n",
    "r_cluster_scale = 2.5\n",
    "mstar_min = 2e9\n",
    "\n",
    "\n",
    "nout_fi = 187\n",
    "\n",
    "#Last merger\n",
    "import matplotlib.pyplot as plt\n",
    "nout_ini = 87 # recent merger after z =1.\n",
    "\n",
    "# Load tree\n",
    "is_gal = True\n",
    "\n",
    "# all catalogs\n",
    "verbose=False\n",
    "\n",
    "#\n",
    "most_recent_only = False\n",
    "\n",
    "#clusters = ['39990', '36415', '10002', '05427', '36413', '01605']\n",
    "clusters = ['36413']\n",
    "for cluster in clusters:\n",
    "\n",
    "    # final result arrays\n",
    "\n",
    "    gal_list=[]\n",
    "    mr_list=[]\n",
    "    nout_list=[]\n",
    "\n",
    "    #for cluster in clusters:\n",
    "    wdir = '/home/hoseung/Work/data/' + clusters[0] + '/'\n",
    "    #wdir = './'\n",
    "\n",
    "    alltrees = ctu.load_tree(wdir, is_gal=is_gal)\n",
    "\n",
    "    ft = alltrees.data[alltrees.data['nout'] == nout_fi]\n",
    "    #allgals = ft['id'][ft['m'] > 5e9]\n",
    "\n",
    "    info = load.info.Info(nout=nout_fi, base=wdir, load=True)\n",
    "    cat = pickle.load(open(wdir + 'catalog_GM/catalog' + str(nout_fi) + '.pickle', 'rb'))\n",
    "    final_gals_idx = cat['idx']\n",
    "    hhal = hmo.Halo(base=wdir, nout=nout_fi, halofinder='HM', info=info, load=True, is_gal=False)\n",
    "    i_center = np.where(hhal.data['np'] == max(hhal.data['np']))[0]\n",
    "    r_cluster = hhal.data['rvir'][i_center] * info.pboxsize\n",
    "\n",
    "    hh = hmo.Halo(base=wdir, nout=nout_fi, halofinder='HM', info=info, load=True, is_gal=is_gal)\n",
    "    i_center = np.where(hh.data['np'] == max(hh.data['np']))[0]\n",
    "    i_satellites = extract_halos_within(hh.data, i_center, info, dist_in_mpc = r_cluster * r_cluster_scale)\n",
    "    print(\"Total {0} galaxies \\n{1} galaxies are selected\".format(\n",
    "          len(i_satellites),sum(i_satellites)))\n",
    "\n",
    "    # halos found inside the cluster and have complete tree back to nout_ini\n",
    "    large_enugh = hh.data['m'] > mstar_min\n",
    "    halo_list = hh.data['id'][i_satellites * large_enugh]\n",
    "    final_ids = ctu.check_tree_complete(alltrees.data, 87, nout_fi, halo_list, idx=False) # 87: z = 1\n",
    "\n",
    "    #final_gals_idx = [ft['id'][ft['Orig_halo_id'] == final_gal] for final_gal in final_ids]\n",
    "    #print(len(final_gals_idx), \"halos left\")\n",
    "    #ngals = len(final_gals_idx)\n",
    "    # Search for all galaxies that listed in the trees of final_gals\n",
    "    #all_gals_in_trees = all_gals(tt, final_gals_idx)\n",
    "    verbose=True\n",
    "    for idx in final_gals_idx:\n",
    "        #gal = cat['id']\n",
    "        if verbose: print(\"analyzing merger events of galaxy \", idx)\n",
    "\n",
    "        # Convert halo id to tree id\n",
    "        #idx = id2idx(alltrees.data, gal, 187)\n",
    "        #idx = cat['idx']\n",
    "\n",
    "        # full tree of a galaxy\n",
    "        atree = ctu.extract_a_tree(alltrees.data, idx)\n",
    "\n",
    "        # main progenitor tree\n",
    "        mtree = ctu.extract_main_tree(alltrees.data, idx)\n",
    "\n",
    "        x_nout = mtree['nout'].flatten()\n",
    "        x_nout = x_nout[x_nout > nout_ini]\n",
    "\n",
    "        mass_ratios_single = np.zeros(len(x_nout))\n",
    "        for i, nout in enumerate(x_nout):\n",
    "            # merger ratio\n",
    "            i_prgs = np.where(atree['desc_id'] == mtree['id'][i])[0]\n",
    "\n",
    "            # multiple prgs = merger\n",
    "            if len(i_prgs) > 1:\n",
    "                if verbose: print(\" {} mergers at nout = {}\".format(len(i_prgs), nout))\n",
    "                id_prgs = atree['id'][i_prgs]\n",
    "                mass_prgs = atree['m'][i_prgs]\n",
    "                m_r = mass_prgs / max(mass_prgs)\n",
    "                if verbose:\n",
    "                    print(\" Mass ratios : \", m_r)\n",
    "                mass_ratios_single[i] = max([mass_prgs[1:] / max(mass_prgs)][0])\n",
    "            else:\n",
    "                mass_ratios_single[i] = 0\n",
    "\n",
    "        ind_ok = np.where(mass_ratios_single > 0.1)[0]\n",
    "        #print(\"all ind_ok\", ind_ok)\n",
    "        if len(ind_ok) > 0:\n",
    "            # if a satellite oscillates around the host, \n",
    "            # it could be identified as multiple mergers with short time interval. \n",
    "            # leave only the first passage / merger.\n",
    "            good =[]\n",
    "            for i in range(len(ind_ok)-1):\n",
    "                if ind_ok[i+1] > ind_ok[i] + 2:\n",
    "                    good.append(ind_ok[i])\n",
    "            good.append(ind_ok[-1])\n",
    "            ind_ok = good\n",
    "    #        if most_recent_only:\n",
    "    #            ind_ok = max(ind_ok) # most recent \n",
    "\n",
    "    #        print(\"  galaxy {}, Last nout {}, Merger ratio 1:{:.1f}\".format(idx,\n",
    "    #                                                                     x_nout[ind_ok],\n",
    "    #                                                                       1./mass_ratios_single[ind_ok]))\n",
    "            mr = 1./mass_ratios_single[ind_ok]\n",
    "\n",
    "            gal_list.append(idx)\n",
    "            mr_list.append(mr)\n",
    "            nout_list.append(x_nout[ind_ok])\n",
    "\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(1)\n",
    "\n",
    "    ax.scatter(nout_list, mr_list)\n",
    "    ax.set_title(\"last merger Vs final lambda\")\n",
    "    ax.set_ylabel(r\"$\\lambda _R$\")\n",
    "    ax.set_xlabel(\"Last merger\")\n",
    "    for i,gal_name in enumerate(gal_list):\n",
    "        ax.text(nout_list[i]+0.5, mr_list[i]+0.1, str(gal_name))\n",
    "    plt.show()\n",
    "    \"\"\"\n",
    "    with open(wdir + 'merger_list.txt', 'w') as f:\n",
    "    #    print(\"Major mergers in this cluster\")\n",
    "        for gal, nout, mr in zip(gal_list, mr_list, nout_list):\n",
    "            for ni, mi in zip(nout, mr):\n",
    "                f.write(\"{}  {}  {} \\n\".format(gal, ni, mi))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
