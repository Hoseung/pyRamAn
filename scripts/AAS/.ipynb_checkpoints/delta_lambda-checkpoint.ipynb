{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Measure delta Lambda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lambda fluctuates, and it fluctuates more as two galaxies get closer.\n",
    "It is hard to separate 'normal' stage and 'merging' stage of lambda.\n",
    "Measuring L at normal stage may require some fitting algorithm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_pickle(fname):\n",
    "    with open(fname, 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "## time\n",
    "def aexp2zred(aexp):\n",
    "    return [1.0/a - 1.0 for a in aexp]\n",
    "\n",
    "def zred2aexp(zred):\n",
    "    return [1.0/(1.0 + z) for z in zred]\n",
    "\n",
    "def lbt2aexp(lts):\n",
    "    import astropy.units as u\n",
    "    from astropy.cosmology import WMAP7, z_at_value\n",
    "    zreds = [z_at_value(WMAP7.lookback_time, ll * u.Gyr) for ll in lts]\n",
    "    return [1.0/(1+z) for z in zreds]\n",
    "\n",
    "def density_map(x, y, ax, sort=True):\n",
    "    from scipy.stats import gaussian_kde\n",
    "    xy = np.vstack([x,y])\n",
    "    z = gaussian_kde(xy)(xy) \n",
    "    z /= max(z)\n",
    "\n",
    "    idx = z.argsort()    \n",
    "    xx, yy = x[idx], y[idx]\n",
    "    z = z[idx]\n",
    "    \n",
    "    im = ax.scatter(xx, yy, c=z, s=50, edgecolor='')\n",
    "    return im\n",
    "\n",
    "\n",
    "def sigma_clip_ind(c, high, low):\n",
    "    \"\"\"\n",
    "        returns indices of sigma-clipping-safe elements.\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    ind = (np.mean(c) - np.std(c)*low < c) * (c < np.mean(c) + np.std(c)*high)\n",
    "    return ind\n",
    "\n",
    "\n",
    "def mask_outlier(y, low=1.5, high=1.5):\n",
    "    \"\"\"\n",
    "        maks outlier assuming monotonic trend.\n",
    "    \"\"\"\n",
    "    x = np.arange(len(y))\n",
    "\n",
    "    # linear fitting .. more desirably, a very strong smoothing scheme that can reconstrcut mild curve.\n",
    "    slope, intercept, r_value, p_value, std_err = scipy.stats.linregress(x,y)\n",
    "\n",
    "    # extract linear fit\n",
    "    yy = y - (slope * x + intercept)\n",
    "\n",
    "    # sigma clipped value = mean of the rest \n",
    "    i_good = sigma_clip_ind(yy, low, high)\n",
    "    yy[~i_good] = np.mean(yy[i_good])\n",
    "\n",
    "    # add linear fit again\n",
    "    return yy + (slope * x + intercept)\n",
    "\n",
    "\n",
    "def smooth(x, beta=5, window_len=20, monotonic=False):\n",
    "    \"\"\" \n",
    "    kaiser window smoothing \n",
    "    beta = 5 : Similar to a Hamming\n",
    "    \"\"\"\n",
    "    \n",
    "    if monotonic:\n",
    "        \"\"\"\n",
    "        if there is an overall slope, smoothing may result in offset.\n",
    "        compensate for that. \n",
    "        \"\"\"\n",
    "        slope, intercept, r_value, p_value, std_err = scipy.stats.linregress(x, y=np.arange(len(x)))\n",
    "        xx = np.arange(len(x)) * slope + intercept\n",
    "        x = x - xx\n",
    "    \n",
    "    # extending the data at beginning and at the end\n",
    "    # to apply the window at the borders\n",
    "    s = np.r_[x[window_len-1:0:-1], x, x[-1:-window_len:-1]]\n",
    "    w = np.kaiser(window_len,beta)\n",
    "    y = np.convolve(w/w.sum(), s, mode='valid')\n",
    "    if monotonic: \n",
    "         return y[int(window_len)/2:len(y)-int(window_len/2) + 1] + xx#[x[window_len-1:0:-1],x,x[-1:-window_len:-1]]\n",
    "    else:\n",
    "        return y[int(window_len)/2:len(y)-int(window_len/2) + 1]\n",
    "        #return y[5:len(y)-5]\n",
    "\n",
    "        \n",
    "class MainPrg():\n",
    "    import tree.ctutils as ctu\n",
    "    import numpy as np\n",
    "    \n",
    "    def __init__(self, treedata, final_gal, nout_ini=None, nout_fi=None):\n",
    "\n",
    "        temp_tree = ctu.extract_main_tree(treedata, final_gal)\n",
    "        if nout_ini == None:\n",
    "            nout_ini = min(temp_tree['nout'])\n",
    "        if nout_fi == None:\n",
    "            nout_fi = max(temp_tree['nout'])            \n",
    "            \n",
    "        self.nouts = np.arange(nout_fi, nout_ini -1, -1)\n",
    "        self.idxs = temp_tree['id'] # nout_ini, nout_fi consideration needed.\n",
    "        self.ids = temp_tree['Orig_halo_id']\n",
    "        self.data = None\n",
    "    \n",
    "    def set_data(self, cat, nout):\n",
    "        \"\"\"\n",
    "        compile data from catalogs.\n",
    "        \"\"\"\n",
    "        if nout in self.nouts:\n",
    "            # Declare self.data first if there isn't.\n",
    "            if self.data == None:\n",
    "                self.data = np.zeros(len(self.nouts), dtype=cat.dtype)\n",
    "            inow = self.nouts == nout\n",
    "            a = np.where(cat['idx'] == self.idxs[inow])[0]\n",
    "            if len(a) > 0:\n",
    "                self.data[inow] = cat[a]        \n",
    "            else:\n",
    "                pass\n",
    "                #print(self.ids[inow],cat['id'])\n",
    "        else:\n",
    "            pass\n",
    "            #print(\"No {} in the catalog\".format(nout))\n",
    "            \n",
    "    def clip_non_detection(self):\n",
    "        # end of galaxy tree = last non-zero position.\n",
    "        # Note that 'id' can be 0 if phantom. But phantom is a valid datapoint\n",
    "        i_first_nout = max(np.where(self.data['idx'] > 0)[0])\n",
    "        print('i_first', i_first_nout)\n",
    "        # then, only [0-i_first_nout] are valid.\n",
    "        # earlier then 187 - 91-th are zero. so get rid of them.\n",
    "        self.data = self.data[:i_first_nout].copy()\n",
    "        self.nouts = self.nouts[:i_first_nout].copy()\n",
    "        self.ids = self.ids[:i_first_nout].copy()\n",
    "        self.idxs = self.idxs[:i_first_nout].copy()\n",
    "        \n",
    "    def fill_missing_data(self):\n",
    "        assert (self.ids[-1] != 0)\n",
    "        \n",
    "        # loop over all fields except id, index, and non-physical entries.\n",
    "        i_bad = np.where(self.data['idx'] == 0)[0]\n",
    "        for field in self.data.dtype.names:\n",
    "            # do not modify index and id fields.\n",
    "            if field in [\"index\", \"id\", \"idx\"]:\n",
    "                continue\n",
    "            arr = self.data[field] # it's a view.\n",
    "\n",
    "            for i_b in i_bad:\n",
    "                # neighbouring array might also be empty. Search for closest valid element.\n",
    "                # left point\n",
    "                i_l = i_b - 1\n",
    "                while(i_l in i_bad):\n",
    "                    i_l = i_l - 1\n",
    "                # right point\n",
    "                i_r = i_b + 1\n",
    "                while(i_r in i_bad):\n",
    "                    i_r = i_r + 1\n",
    "\n",
    "                arr[i_b] = (arr[i_b -1] + arr[i_b +1])/2.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "중간에 비는 것은 아마도 phantom이라 'Orig_halo_id'는 없는 경우일 듯. \n",
    "그렇기 때문에..! cat을 만들때 idx를 넣어야함!  : 넣었음. (근데 final_ID는 뺐나...?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### fix Reff of a galaxy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def fixed_ind_Lr(gal):\n",
    "    nnouts = len(gal.nouts)\n",
    "    ind_reff_fix = np.zeros(nnouts, dtype='i4')\n",
    "\n",
    "    #print(gal.data['rgal'])\n",
    "    smooth_r = smooth(mask_outlier(gal.data['rgal'], 1.5, 1.5), 50, monotonic=False)\n",
    "\n",
    "    # fixed Reff array\n",
    "    for i in range(nnouts):\n",
    "        # 1Reff = 5 points\n",
    "        reff = gal.data['rgal'][i]\n",
    "        reff_real = smooth_r[i]\n",
    "        \n",
    "        try:\n",
    "            ind_reff_fix[i] = np.round(reff_real/reff * 5) -1\n",
    "        except:\n",
    "            pass\n",
    "    return ind_reff_fix\n",
    "\n",
    "\n",
    "def smoothed_reff(cat, nout_merger):\n",
    "    \"\"\"\n",
    "    returns \"representative\" lambda at each nout by assuming monotonic change in Reff. \n",
    "    During merger, Reff can fluctuate, and if has no physical meaning to infer Labda at Reff during merger stage. \n",
    "    So Reff' is derived by linear interpolating Reffs before and after the merger. \n",
    "    \n",
    "    cat is one galaxy catalog over time.\n",
    "    \"\"\"\n",
    "    import utils.match as mtc\n",
    "    i_merger = np.where(cat['nout'] == nout_merger)[0]\n",
    "    ind_lower = 20\n",
    "    ind_upper = 20\n",
    "    \n",
    "    reffs = cat['rgal']\n",
    "    # left and right values chosen by sigma-clipping\n",
    "    r_lefts, b, c = scipy.stats.sigmaclip(reffs[max([0,i_merger-ind_lower]):i_merger], sig_lower, sig_upper)\n",
    "    #print(r_lefts)\n",
    "    r_left = r_lefts[-1]\n",
    "    i_left = np.where(reffs == r_left)[0]\n",
    "    \n",
    "\n",
    "    r_rights, b,c = scipy.stats.sigmaclip(reffs[i_merger:min([i_merger+ind_upper,len(reffs)])], sig_lower, sig_upper)\n",
    "    r_right = r_rights[0]\n",
    "    i_right = np.where(reffs == r_right)[0]\n",
    "\n",
    "    r_prime = reffs\n",
    "    #print(\"chekc\")\n",
    "    #print(r_prime)\n",
    "    r_prime[i_left : i_right + 1] = np.linspace(r_left, r_right, i_right - i_left + 1)\n",
    "    return r_prime    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded an extended tree\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hoseung/.local/lib/python3.4/site-packages/IPython/kernel/__main__.py:111: FutureWarning: comparison to `None` will result in an elementwise object comparison in the future.\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/hoseung/Work/data/39990/merger_list.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-ebeb068e5c70>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[1;31m# load merger galaxy list (geneated by scripts/notebooks/halo/Merter_no_cat.ipynb)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwdir\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'merger_list.txt'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m         \u001b[0mmgl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenfromtxt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'idx'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'i8'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'mr'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'f8'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'nout'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'i4'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/hoseung/Work/data/39990/merger_list.txt'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.stats\n",
    "import tree.ctutils as ctu\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Read a single galaxy evolution catalog.\n",
    "import pickle\n",
    "\n",
    "clusters = ['39990','36413', '05427', '36415']\n",
    "# parameters used for lambda_arr clipping.\n",
    "ind_upper = 20\n",
    "ind_lower = 20\n",
    "sig_upper = 2.0\n",
    "sig_lower = 2.0\n",
    "\n",
    "nout_fi = 187\n",
    "\n",
    "bad = 0\n",
    "\n",
    "fix_ind=False\n",
    "\n",
    "mr = []\n",
    "dl = []\n",
    "\n",
    "verbose=True\n",
    "\n",
    "nout_ini = 68\n",
    "nnouts = nout_fi - nout_ini + 1\n",
    "\n",
    "\n",
    "for cluster in clusters:\n",
    "    wdir = '/home/hoseung/Work/data/' + cluster + '/' #'05427/'\n",
    "    cdir = 'catalog_GM/'\n",
    "\n",
    "    # Serialize catalogs. -> Only main galaxies\n",
    "\n",
    "    # main galaxy list\n",
    "\n",
    "    alltrees = ctu.load_tree(wdir, is_gal=True)\n",
    "    ad = alltrees.data\n",
    "    tn = ad[ad['nout'] == nout_fi]\n",
    "\n",
    "    cat = pickle.load(open(wdir + cdir + 'catalog' + str(nout_fi) + '.pickle', 'rb'))\n",
    "\n",
    "    #idx_all = [tn['id'][tn['Orig_halo_id'] == id_final][0] for id_final in cat['id']]\n",
    "    idx_all = cat['idx']\n",
    "    mpgs = [MainPrg(ad, idx) for idx in idx_all]\n",
    "    #print(mpgs[0].nouts)\n",
    "    #print(mpgs[0].ids)\n",
    "    for nout in range(nout_ini, nout_fi + 1):\n",
    "        cat = pickle.load(open(wdir + cdir + 'catalog' + str(nout) + '.pickle', 'rb'))\n",
    "        for mpg in mpgs:\n",
    "            mpg.set_data(cat, nout)\n",
    "        print(nout)\n",
    "    #idx = mgl['idx'][2]\n",
    "\n",
    "    # load merger galaxy list (geneated by scripts/notebooks/halo/Merter_no_cat.ipynb)\n",
    "    with open(wdir + 'merger_list.txt', 'rb') as f:\n",
    "        mgl = np.genfromtxt(f, dtype=[('idx','i8'),('mr','f8'),('nout','i4')])\n",
    "\n",
    "    mids = mgl['idx']\n",
    "    mrs = mgl['mr'] #np.random.random(len(mpgs)) # just as a test.\n",
    "    nout_mergers = mgl['nout'] #np.round(mrs * 50).astype(\"int\") + 137\n",
    "    i_mergers = nout_fi - nout_mergers \n",
    "\n",
    "    gal_idxs = [gal.idxs[0] for gal in mpgs]\n",
    "\n",
    "    for igal, mid in enumerate(mids):\n",
    "    #gal = mpgs[3]\n",
    "        if mid not in gal_idxs:\n",
    "            print(\"Merger gal {} is not in catalog, skipping\".format(mid))\n",
    "            continue\n",
    "        else:\n",
    "            gal = mpgs[np.where(gal_idxs == mid)[0]]\n",
    "            \n",
    "        if len(gal.nouts) < 20:\n",
    "            continue\n",
    "        gal.clip_non_detection()\n",
    "        try:\n",
    "            gal.fill_missing_data()\n",
    "        except:\n",
    "            bad = bad + 1\n",
    "            pass\n",
    "\n",
    "\n",
    "        if verbose: print(\"Galaxy ID at the final nout, idx = {}, id = {}\".format(gal.idxs[0], gal.ids[0]))\n",
    "\n",
    "        i_merger = i_mergers[igal]  #i_merger = 187 - mgl[igal][2]\n",
    "        merger_ratio = mrs[igal]\n",
    "\n",
    "        if verbose: print(\"nnouts: {}, i_merger {}\".format(len(gal.nouts), i_merger))\n",
    "\n",
    "        if i_merger > len(gal.nouts):\n",
    "            print(\"Too short evolution history, aborting..\")\n",
    "            continue\n",
    "\n",
    "        # fixed Lambda array based on Reff_fix.\n",
    "#        print(\"Length\", len(gal.nouts))\n",
    "        \n",
    "        if fix_ind:\n",
    "            ind_reff_fix = fixed_ind_Lr(gal)\n",
    "            lam = np.zeros(len(ind_reff_fix))\n",
    "\n",
    "            ind_max = len(gal.data['lambda_arr'][0]) - 1\n",
    "\n",
    "            for inout, ind in enumerate(ind_reff_fix):#[ind_reff_fix > 0]):\n",
    "                if ind == 0 : print(ind)\n",
    "                lam[inout] = gal.data['lambda_arr'][inout][min([ind_max,ind])] # fixed value\n",
    "        else:\n",
    "            lam = gal.data['lambda_r']\n",
    "\n",
    "        x_al = range(max([0,i_merger-ind_lower]), i_merger)\n",
    "        x_ar = range(i_merger,min([i_merger+ind_upper, len(lam)]))\n",
    "\n",
    "        al, b1, c1 = scipy.stats.sigmaclip(lam[x_al], sig_lower, sig_upper)\n",
    "        ar, b2, c2 = scipy.stats.sigmaclip(lam[x_ar], sig_lower, sig_upper)\n",
    "\n",
    "        if (len(al) > 1) & (len(ar) > 0):\n",
    "            dl.append(np.median(ar) - np.median(al))\n",
    "            mr.append(merger_ratio)\n",
    "#        except:\n",
    "#            bad = bad +1\n",
    "#            pass\n",
    "\n",
    "print('BAD', bad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load merger galaxy list (geneated by scripts/notebooks/halo/Merter_no_cat.ipynb)\n",
    "with open(wdir + 'merger_list.txt', 'rb') as f:\n",
    "    mgl = np.genfromtxt(f, dtype=[('idx','i8'),('mr','f8'),('nout','i4')])\n",
    "\n",
    "mids = mgl['idx']\n",
    "mrs = mgl['mr'] #np.random.random(len(mpgs)) # just as a test.\n",
    "nout_mergers = mgl['nout'] #np.round(mrs * 50).astype(\"int\") + 137\n",
    "i_mergers = nout_fi - nout_mergers \n",
    "\n",
    "gal_idxs = [gal.idxs[0] for gal in mpgs]\n",
    "\n",
    "for igal, mid in enumerate(mids):\n",
    "#gal = mpgs[3]\n",
    "    if mid not in gal_idxs:\n",
    "        print(\"Merger gal {} is not in catalog, skipping\".format(mid))\n",
    "        continue\n",
    "    else:\n",
    "        gal = mpgs[np.where(gal_idxs == mid)[0]]\n",
    "\n",
    "    if len(gal.nouts) < 20:\n",
    "        continue\n",
    "    gal.clip_non_detection()\n",
    "    try:\n",
    "        gal.fill_missing_data()\n",
    "    except:\n",
    "        bad = bad + 1\n",
    "        pass\n",
    "\n",
    "\n",
    "    if verbose: print(\"Galaxy ID at the final nout, idx = {}, id = {}\".format(gal.idxs[0], gal.ids[0]))\n",
    "\n",
    "    i_merger = i_mergers[igal]  #i_merger = 187 - mgl[igal][2]\n",
    "    merger_ratio = mrs[igal]\n",
    "\n",
    "    if verbose: print(\"nnouts: {}, i_merger {}\".format(len(gal.nouts), i_merger))\n",
    "\n",
    "    if i_merger > len(gal.nouts):\n",
    "        print(\"Too short evolution history, aborting..\")\n",
    "        continue\n",
    "\n",
    "    # fixed Lambda array based on Reff_fix.\n",
    "#        print(\"Length\", len(gal.nouts))\n",
    "\n",
    "    if fix_ind:\n",
    "        ind_reff_fix = fixed_ind_Lr(gal)\n",
    "        lam = np.zeros(len(ind_reff_fix))\n",
    "\n",
    "        ind_max = len(gal.data['lambda_arr'][0]) - 1\n",
    "\n",
    "        for inout, ind in enumerate(ind_reff_fix):#[ind_reff_fix > 0]):\n",
    "            if ind == 0 : print(ind)\n",
    "            lam[inout] = gal.data['lambda_arr'][inout][min([ind_max,ind])] # fixed value\n",
    "    else:\n",
    "        lam = gal.data['lambda_r']\n",
    "\n",
    "    x_al = range(max([0,i_merger-ind_lower]), i_merger)\n",
    "    x_ar = range(i_merger,min([i_merger+ind_upper, len(lam)]))\n",
    "\n",
    "    al, b1, c1 = scipy.stats.sigmaclip(lam[x_al], sig_lower, sig_upper)\n",
    "    ar, b2, c2 = scipy.stats.sigmaclip(lam[x_ar], sig_lower, sig_upper)\n",
    "\n",
    "    if (len(al) > 1) & (len(ar) > 0):\n",
    "        dl.append(np.median(ar) - np.median(al))\n",
    "        mr.append(merger_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "with open('/home/hoseung/Work/data/01605/m_l.txt', 'rb') as f:\n",
    "    mrdl  = np.genfromtxt(f)#, dtype=[('idx','i8'),('mr','f8'),('nout','i4')])\n",
    "mr_1 = mrdl[:,0]\n",
    "mr_1 = mr_1 + np.random.random(len(mr_1)) * 0.02\n",
    "dl_1 = mrdl[:,1]\n",
    "dl_1 = dl_1 + np.random.random(len(dl_1)) * 0.01 - 0.005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "[mr.append(i) for i in mr_1]\n",
    "[dl.append(i) for i in dl_1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hoseung/.local/lib/python3.4/site-packages/matplotlib/collections.py:590: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if self._edgecolors == str('face'):\n"
     ]
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1)\n",
    "ax.scatter(mr, dl)\n",
    "ax.set_ylim([-0.5, +0.5])\n",
    "ax.set_xlim([0, 10])\n",
    "ax.set_title(\"d$\\lambda$ vs Merger Mass Ratio\")\n",
    "ax.set_ylabel(\"d$\\lambda$\")\n",
    "ax.set_xlabel(\"Merger Mass Ratio\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lambda_mp_gal에서 은하에 대해 np = max 를 i_center로 잡았는데, halo에서 np = max와 다름.....\n",
    "어째 생긴 은하단인가. 허허. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have regularized galaxy evolution data.\n",
    "\n",
    "I want to measure rotation parameter before and after a merger.\n",
    "I take 20 lambda values before and after the merger, sigma clip outliers, and take median value.\n",
    "So dLambda = media(Lambda_after) - median(Lambda_before).\n",
    "\n",
    "However, Lambda measurement at 1Reff requires robust Reff measurement, which is very tough during merger events.\n",
    "So I smooth Reff evolution history to guess more reasonable Reff values at all points. Following is the procedure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ind_reff_fix points to the Lambda_arr element closest to the fixed Reff at every nout."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "왜 lambda_r 이랑 lambda_arr[4]랑 다르지? -> 0.5Reff에서 측정했었음..!\n",
    "그림에는 0.5Reff이지만 나머지는 1.0Reff로 쓸래.. \n",
    "나중에 그림도 1.0으로 바꾸지 뭐.. (lambda_single.py로)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1)\n",
    "ax.plot(lam, 'b-')\n",
    "ax.plot(lam_fix, 'g--')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y = gal.data['rgal']\n",
    "fig, ax = plt.subplots(1)\n",
    "ax.plot(y)\n",
    "ax.plot(smooth_r, 'r--')\n",
    "#ax.plot(smoothed_reff(gal.data['reff'], 102))\n",
    "ax.plot(gal.data['lambda_r'] * 20)\n",
    "ax.set_title(\"Rgal, Rgal_smoothed, and Lambda_r\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plot all properties of a galaxy\n",
    "\n",
    "fig, axs = plt.subplots(4,4)\n",
    "axs = axs.flatten()\n",
    "for i, field in enumerate(gal.data.dtype.names[:16]):\n",
    "    if field == \"lambda_arr\":\n",
    "        continue\n",
    "    axs[i].plot(gal.data[field])\n",
    "    axs[i].set_ylabel(field)\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.247116707298 0.241349076274\n",
      "0.240646574733 0.245995951079\n"
     ]
    }
   ],
   "source": [
    "# i_merger가 정확해야하는데... \n",
    "# Tree에서 주는 merger는 final coalescence일 가능성이 높음. \n",
    "print(np.mean(al), np.mean(ar))\n",
    "print(np.median(al), np.median(ar))\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1)\n",
    "ax.plot(x_al, lam[x_al], 'r')\n",
    "ax.plot(x_ar, lam[x_ar], 'b')\n",
    "ax.axhline(np.mean(al), color='r')\n",
    "ax.axhline(np.mean(ar), color='b')\n",
    "#ax.plot(smoothed_reff(gal.data['reff'], 102))\n",
    "ax.set_title(\"Rgal, Rgal_smoothed, and Lambda_r\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I can measure dL in this way, but am I following the right galaxy? is the tree right?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
