{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_pickle(fname):\n",
    "    with open(fname, 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "## time\n",
    "def aexp2zred(aexp):\n",
    "    return [1.0/a - 1.0 for a in aexp]\n",
    "\n",
    "def zred2aexp(zred):\n",
    "    return [1.0/(1.0 + z) for z in zred]\n",
    "\n",
    "def lbt2aexp(lts):\n",
    "    import astropy.units as u\n",
    "    from astropy.cosmology import WMAP7, z_at_value\n",
    "    zreds = [z_at_value(WMAP7.lookback_time, ll * u.Gyr) for ll in lts]\n",
    "    return [1.0/(1+z) for z in zreds]\n",
    "\n",
    "def density_map(x, y, sort=True):\n",
    "    from scipy.stats import gaussian_kde\n",
    "    xy = np.vstack([x,y])\n",
    "    z = gaussian_kde(xy)(xy) \n",
    "    z /= max(z)\n",
    "\n",
    "    idx = z.argsort()    \n",
    "    xx, yy = x[idx], y[idx]\n",
    "    z = z[idx]\n",
    "    \n",
    "    return xx, yy, z\n",
    "\n",
    "\n",
    "def sigma_clip_ind(c, high, low):\n",
    "    \"\"\"\n",
    "        returns indices of sigma-clipping-safe elements.\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    ind = (np.mean(c) - np.std(c)*low < c) * (c < np.mean(c) + np.std(c)*high)\n",
    "    return ind\n",
    "\n",
    "\n",
    "def mask_outlier(y, low=1.5, high=1.5):\n",
    "    \"\"\"\n",
    "        maks outlier assuming monotonic trend.\n",
    "    \"\"\"\n",
    "    x = np.arange(len(y))\n",
    "\n",
    "    # linear fitting .. more desirably, a very strong smoothing scheme that can reconstrcut mild curve.\n",
    "    slope, intercept, r_value, p_value, std_err = scipy.stats.linregress(x,y)\n",
    "\n",
    "    # extract linear fit\n",
    "    yy = y - (slope * x + intercept)\n",
    "\n",
    "    # sigma clipped value = mean of the rest \n",
    "    i_good = sigma_clip_ind(yy, low, high)\n",
    "    yy[~i_good] = np.mean(yy[i_good])\n",
    "\n",
    "    # add linear fit again\n",
    "    return yy + (slope * x + intercept)\n",
    "\n",
    "\n",
    "def smooth(x, beta=5, window_len=20, monotonic=False):\n",
    "    \"\"\" \n",
    "    kaiser window smoothing \n",
    "    beta = 5 : Similar to a Hamming\n",
    "    \"\"\"\n",
    "    \n",
    "    if monotonic:\n",
    "        \"\"\"\n",
    "        if there is an overall slope, smoothing may result in offset.\n",
    "        compensate for that. \n",
    "        \"\"\"\n",
    "        slope, intercept, r_value, p_value, std_err = scipy.stats.linregress(x, y=np.arange(len(x)))\n",
    "        xx = np.arange(len(x)) * slope + intercept\n",
    "        x = x - xx\n",
    "    \n",
    "    # extending the data at beginning and at the end\n",
    "    # to apply the window at the borders\n",
    "    s = np.r_[x[window_len-1:0:-1], x, x[-1:-window_len:-1]]\n",
    "    w = np.kaiser(window_len,beta)\n",
    "    y = np.convolve(w/w.sum(), s, mode='valid')\n",
    "    if monotonic: \n",
    "         return y[int(window_len)/2:len(y)-int(window_len/2) + 1] + xx#[x[window_len-1:0:-1],x,x[-1:-window_len:-1]]\n",
    "    else:\n",
    "        return y[int(window_len)/2:len(y)-int(window_len/2) + 1]\n",
    "        #return y[5:len(y)-5]\n",
    "\n",
    "        \n",
    "class MainPrg():\n",
    "    import tree.ctutils as ctu\n",
    "    import numpy as np\n",
    "    \n",
    "    def __init__(self, treedata, final_gal, nout_ini=None, nout_fi=None):\n",
    "\n",
    "        temp_tree = ctu.extract_main_tree(treedata, final_gal)\n",
    "        if nout_ini == None:\n",
    "            nout_ini = min(temp_tree['nout'])\n",
    "        if nout_fi == None:\n",
    "            nout_fi = max(temp_tree['nout'])            \n",
    "            \n",
    "        self.nouts = np.arange(nout_fi, nout_ini -1, -1)\n",
    "        self.idxs = temp_tree['id'] # nout_ini, nout_fi consideration needed.\n",
    "        self.ids = temp_tree['Orig_halo_id']\n",
    "        self.data = None\n",
    "    \n",
    "    def set_data(self, cat, nout):\n",
    "        \"\"\"\n",
    "        compile data from catalogs.\n",
    "        \"\"\"\n",
    "        if nout in self.nouts:\n",
    "            # Declare self.data first if there isn't.\n",
    "            if self.data == None:\n",
    "                self.data = np.zeros(len(self.nouts), dtype=cat.dtype)\n",
    "            inow = self.nouts == nout\n",
    "            a = np.where(cat['idx'] == self.idxs[inow])[0]\n",
    "            if len(a) > 0:\n",
    "                self.data[inow] = cat[a]        \n",
    "            else:\n",
    "                pass\n",
    "                #print(self.ids[inow],cat['id'])\n",
    "        else:\n",
    "            pass\n",
    "            #print(\"No {} in the catalog\".format(nout))\n",
    "            \n",
    "    def clip_non_detection(self):\n",
    "        # end of galaxy tree = last non-zero position.\n",
    "        # Note that 'id' can be 0 if phantom. But phantom is a valid datapoint\n",
    "        i_first_nout = max(np.where(self.data['idx'] > 0)[0])\n",
    "        #print('i_first', i_first_nout)\n",
    "        # then, only [0-i_first_nout] are valid.\n",
    "        # earlier then 187 - 91-th are zero. so get rid of them.\n",
    "        self.data = self.data[:i_first_nout].copy()\n",
    "        self.nouts = self.nouts[:i_first_nout].copy()\n",
    "        self.ids = self.ids[:i_first_nout].copy()\n",
    "        self.idxs = self.idxs[:i_first_nout].copy()\n",
    "        \n",
    "    def fill_missing_data(self):\n",
    "        assert (self.ids[-1] != 0)\n",
    "        \n",
    "        # loop over all fields except id, index, and non-physical entries.\n",
    "        i_bad = np.where(self.data['idx'] == 0)[0]\n",
    "        for field in self.data.dtype.names:\n",
    "            # do not modify index and id fields.\n",
    "            if field in [\"index\", \"id\", \"idx\"]:\n",
    "                continue\n",
    "            arr = self.data[field] # it's a view.\n",
    "\n",
    "            for i_b in i_bad:\n",
    "                # neighbouring array might also be empty. Search for closest valid element.\n",
    "                # left point\n",
    "                i_l = i_b - 1\n",
    "                while(i_l in i_bad):\n",
    "                    i_l = i_l - 1\n",
    "                # right point\n",
    "                i_r = i_b + 1\n",
    "                while(i_r in i_bad):\n",
    "                    i_r = i_r + 1\n",
    "\n",
    "                arr[i_b] = (arr[i_b -1] + arr[i_b +1])/2.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fixed_ind_Lr(gal):\n",
    "    nnouts = len(gal.nouts)\n",
    "    ind_reff_fix = np.zeros(nnouts, dtype='i4')\n",
    "\n",
    "    #print(gal.data['rgal'])\n",
    "    smooth_r = smooth(mask_outlier(gal.data['rgal'], 1.5, 1.5), 50, monotonic=False)\n",
    "\n",
    "    # fixed Reff array\n",
    "    for i in range(nnouts):\n",
    "        # 1Reff = 5 points\n",
    "        reff_real = smooth_r[i]\n",
    "        reff = gal.data['rgal'][i]\n",
    "        try:\n",
    "            ind_reff_fix[i] = np.round(reff_real/reff * 5) -1\n",
    "        except:\n",
    "            pass\n",
    "    return ind_reff_fix\n",
    "\n",
    "\n",
    "def smoothed_reff(cat, nout_merger):\n",
    "    \"\"\"\n",
    "    returns \"representative\" lambda at each nout by assuming monotonic change in Reff. \n",
    "    During merger, Reff can fluctuate, and if has no physical meaning to infer Labda at Reff during merger stage. \n",
    "    So Reff' is derived by linear interpolating Reffs before and after the merger. \n",
    "    \n",
    "    cat is one galaxy catalog over time.\n",
    "    \"\"\"\n",
    "    import utils.match as mtc\n",
    "    i_merger = np.where(cat['nout'] == nout_merger)[0]\n",
    "    ind_lower = 20\n",
    "    ind_upper = 20\n",
    "    \n",
    "    reffs = cat['rgal']\n",
    "    # left and right values chosen by sigma-clipping\n",
    "    r_lefts, b, c = scipy.stats.sigmaclip(reffs[max([0,i_merger-ind_lower]):i_merger], sig_lower, sig_upper)\n",
    "    #print(r_lefts)\n",
    "    r_left = r_lefts[-1]\n",
    "    i_left = np.where(reffs == r_left)[0]\n",
    "    \n",
    "\n",
    "    r_rights, b,c = scipy.stats.sigmaclip(reffs[i_merger:min([i_merger+ind_upper,len(reffs)])], sig_lower, sig_upper)\n",
    "    r_right = r_rights[0]\n",
    "    i_right = np.where(reffs == r_right)[0]\n",
    "\n",
    "    r_prime = reffs\n",
    "    #print(\"chekc\")\n",
    "    #print(r_prime)\n",
    "    r_prime[i_left : i_right + 1] = np.linspace(r_left, r_right, i_right - i_left + 1)\n",
    "    return r_prime    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats\n",
    "import tree.ctutils as ctu\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Read a single galaxy evolution catalog.\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clusters = ['36413', '05427'][:2]\n",
    "# parameters used for lambda_arr clipping.\n",
    "ind_upper = 20\n",
    "ind_lower = 20\n",
    "sig_upper = 2.0\n",
    "sig_lower = 2.0\n",
    "\n",
    "nout_ini = 60\n",
    "nout_fi = 187\n",
    "\n",
    "bad = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36413\n",
      "Loaded an extended tree\n",
      "done\n",
      "05427\n",
      "Loaded an extended tree\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.4/dist-packages/IPython/kernel/__main__.py:110: FutureWarning: comparison to `None` will result in an elementwise object comparison in the future.\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 0 is out of bounds for axis 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-73d6e44c9987>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[1;31m#idx_all = [tn['id'][tn['Orig_halo_id'] == id_final][0] for id_final in cat['id']]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[0midx_all\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcat\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'idx'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m     \u001b[0mmpg_tmp\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mMainPrg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0midx_all\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m     \u001b[1;31m#print(mpgs[0].nouts)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[1;31m#print(mpgs[0].ids)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-73d6e44c9987>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[1;31m#idx_all = [tn['id'][tn['Orig_halo_id'] == id_final][0] for id_final in cat['id']]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[0midx_all\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcat\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'idx'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m     \u001b[0mmpg_tmp\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mMainPrg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0midx_all\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m     \u001b[1;31m#print(mpgs[0].nouts)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[1;31m#print(mpgs[0].ids)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-4b565f217d16>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, treedata, final_gal, nout_ini, nout_fi)\u001b[0m\n\u001b[0;32m     91\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtreedata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinal_gal\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnout_ini\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnout_fi\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 93\u001b[1;33m         \u001b[0mtemp_tree\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mctu\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextract_main_tree\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtreedata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinal_gal\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     94\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnout_ini\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m             \u001b[0mnout_ini\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp_tree\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'nout'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/hoseung/Work/pyclusterevol/tree/ctutils.py\u001b[0m in \u001b[0;36mextract_main_tree\u001b[1;34m(treedata, idx)\u001b[0m\n\u001b[0;32m    148\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[0mnprg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m     \u001b[0mind_list\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtreedata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'id'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m     \u001b[1;32mwhile\u001b[0m \u001b[0mnprg\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 0 is out of bounds for axis 0 with size 0"
     ]
    }
   ],
   "source": [
    "cdir = 'catalog_GM/'\n",
    "\n",
    "verbose=True\n",
    "\n",
    "ngals_tot = 0\n",
    "for cluster in clusters:\n",
    "    wdir = '/home/hoseung/Work/data/' + cluster + '/'\n",
    "    # main galaxy list\n",
    "    cat = pickle.load(open(wdir + cdir + 'catalog' + str(nout_fi) + '.pickle', 'rb'))\n",
    "    ngals_tot = ngals_tot + len(cat['idx'])\n",
    "\n",
    "\n",
    "nnouts = nout_fi - nout_ini + 1\n",
    "lambda_evol_all = np.zeros([ngals_tot, nnouts])\n",
    "\n",
    "mpgs = []\n",
    "for cluster in clusters:\n",
    "    print(cluster)\n",
    "    wdir = '/home/hoseung/Work/data/' + cluster + '/'\n",
    "\n",
    "    # Serialize catalogs. -> Only main galaxies\n",
    "    # main galaxy list\n",
    "    alltrees = ctu.load_tree(wdir, is_gal=True)\n",
    "    ad = alltrees.data\n",
    "    tn = ad[ad['nout'] == nout_fi]\n",
    "\n",
    "    cat = pickle.load(open(wdir + cdir + 'catalog' + str(nout_fi) + '.pickle', 'rb'))\n",
    "    #idx_all = [tn['id'][tn['Orig_halo_id'] == id_final][0] for id_final in cat['id']]\n",
    "    idx_all = cat['idx']\n",
    "    mpg_tmp =[MainPrg(ad, idx) for idx in idx_all]\n",
    "    #print(mpgs[0].nouts)\n",
    "    #print(mpgs[0].ids)\n",
    "    for nout in range(nout_ini, nout_fi + 1):\n",
    "        cat = pickle.load(open(wdir + cdir + 'catalog' + str(nout) + '.pickle', 'rb'))\n",
    "        for gal in mpg_tmp:\n",
    "            gal.set_data(cat, nout)\n",
    "\n",
    "    while len(mpg_tmp) > 0:\n",
    "        mpgs.append(mpg_tmp.pop())\n",
    "\n",
    "    print(\"done\")\n",
    "#mpgs = (x for y in mpgs for x in y) # similar to flatten()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/scipy/stats/stats.py:3025: RuntimeWarning: invalid value encountered in sqrt\n",
      "  t = r*np.sqrt(df/((1.0-r+TINY)*(1.0+r+TINY)))\n",
      "/usr/lib/python3/dist-packages/scipy/stats/stats.py:3027: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  slope = r_num / ssxm\n",
      "/usr/lib/python3/dist-packages/scipy/stats/stats.py:3029: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  sterrest = np.sqrt((1-r*r)*ssym / ssxm / df)\n",
      "/home/hoseung/.local/lib/python3.4/site-packages/numpy/core/_methods.py:59: RuntimeWarning: Mean of empty slice.\n",
      "  warnings.warn(\"Mean of empty slice.\", RuntimeWarning)\n",
      "/home/hoseung/.local/lib/python3.4/site-packages/numpy/core/_methods.py:70: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "#mpgs = (x for y in mpgs for x in y) # similar to flatten()\n",
    "for igal, gal in enumerate(mpgs):\n",
    "    try:\n",
    "        gal.clip_non_detection()\n",
    "        gal.fill_missing_data()\n",
    "        ind_reff_fix = fixed_ind_Lr(gal)\n",
    "\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "    ind_max = len(gal.data['lambda_arr'][0]) - 1\n",
    "\n",
    "    for inout, ind in enumerate(ind_reff_fix):\n",
    "        if ind == 0 : print(ind)\n",
    "        lambda_evol_all[igal][inout] = gal.data['lambda_arr'][inout][min([ind_max,ind])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#mpgs = (x for y in mpgs for x in y) # similar to flatten()\n",
    "for igal, gal in enumerate(mpgs):\n",
    "    try:\n",
    "        gal.clip_non_detection()\n",
    "        gal.fill_missing_data()\n",
    "        #ind_reff_fix = fixed_ind_Lr(gal)\n",
    "\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "    #ind_max = len(gal.data['lambda_arr'][0]) - 1\n",
    "\n",
    "    for inout in range(len(gal.nouts)):\n",
    "        if ind == 0 : print(ind)\n",
    "        lambda_evol_all[igal][inout] = gal.data['lambda_r'][inout]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "zreds=[]\n",
    "aexps=[]\n",
    "import load\n",
    "for nout in range(nout_ini, nout_fi+1):\n",
    "    info = load.info.Info(nout=nout, base=wdir, load=True)\n",
    "    aexps.append(info.aexp)\n",
    "    zreds.append(info.zred)\n",
    "aexps = np.array(aexps)\n",
    "zreds = np.array(zreds)\n",
    "\n",
    "# For a given list of nouts, \n",
    "# calculate a nice-looking set of zreds AND lookback times\n",
    "z_targets=[0, 0.2, 0.5, 1, 2, 3]\n",
    "z_target_str=[\"{:.2f}\".format(z) for z in z_targets]\n",
    "a_targets_z = zred2aexp(z_targets)\n",
    "z_pos =  [nout_ini + (1 - (max(aexps) - a)/aexps.ptp()) * nnouts for a in a_targets_z]\n",
    "\n",
    "lbt_targets=[0.00001,1,3,5,8,12]\n",
    "lbt_target_str=[\"{:.0f}\".format(l) for l in lbt_targets]\n",
    "a_targets_lbt = lbt2aexp(lbt_targets)\n",
    "lbt_pos = [nout_ini + (1 - (max(aexps) - a)/aexps.ptp()) * nnouts for a in a_targets_lbt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lambda_range=[0., 0.8]\n",
    "yticks_ok=[0.0, 0.2, 0.4, 0.6, 0.8]\n",
    "nbins = 20\n",
    "den_map = np.zeros((nbins, nnouts))\n",
    "\n",
    "for i in range(nnouts):\n",
    "    den_map[:,i], ypoints = np.histogram(lambda_evol_all[:,i], bins=nbins, range=lambda_range)\n",
    "    den_map[:,i] /= den_map[:,i].max()\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from astropy.stats import sigma_clip\n",
    "\n",
    "\n",
    "\n",
    "nouts = np.arange(nout_ini, nout_fi + 1)\n",
    "xx = np.tile(nouts, ngals_tot) \n",
    "all_data = lambda_evol_all.ravel()\n",
    "data = all_data.copy()\n",
    "data[np.isnan(data)] = 10\n",
    "data[np.isinf(data)] = 10\n",
    "data[data==0] = 10\n",
    "\n",
    "#al, b1, c1 = scipy.stats.sigmaclip(data, 1.0, 1.0)\n",
    "filtered_data = sigma_clip(data, sig=1.0, copy=True)\n",
    "x = xx[~filtered_data.mask]\n",
    "y = all_data[~filtered_data.mask]\n",
    "\n",
    "xx,yy,z = density_map(x,y)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1.73972577e+00,   1.70270268e+00,   1.66666662e+00,\n",
       "         1.63157889e+00,   1.59740260e+00,   1.56410245e+00,\n",
       "         1.53164542e+00,   1.49999994e+00,   1.46913579e+00,\n",
       "         1.43902430e+00,   1.40963854e+00,   1.38095237e+00,\n",
       "         1.35294102e+00,   1.32558128e+00,   1.29885047e+00,\n",
       "         1.27272726e+00,   1.24719091e+00,   1.22222220e+00,\n",
       "         1.19780216e+00,   1.17391291e+00,   1.15053756e+00,\n",
       "         1.12765957e+00,   1.10526298e+00,   1.08333330e+00,\n",
       "         1.06185564e+00,   1.04081632e+00,   1.02020202e+00,\n",
       "         9.99999924e-01,   9.80198017e-01,   9.60784241e-01,\n",
       "         9.41747460e-01,   9.23076797e-01,   9.04761848e-01,\n",
       "         8.86792387e-01,   8.69158763e-01,   8.51851840e-01,\n",
       "         8.34862321e-01,   8.18181764e-01,   8.01801651e-01,\n",
       "         7.85714239e-01,   7.69911496e-01,   7.54385907e-01,\n",
       "         7.39130432e-01,   7.24137901e-01,   7.09401681e-01,\n",
       "         6.94915248e-01,   6.80672223e-01,   6.66666656e-01,\n",
       "         6.52892510e-01,   6.39344120e-01,   6.26016253e-01,\n",
       "         6.12903198e-01,   5.99999945e-01,   5.87301573e-01,\n",
       "         5.74803066e-01,   5.62499930e-01,   5.50387516e-01,\n",
       "         5.38461508e-01,   5.26717421e-01,   5.15151394e-01,\n",
       "         5.03759395e-01,   4.92537284e-01,   4.81481370e-01,\n",
       "         4.70588235e-01,   4.59853946e-01,   4.49275244e-01,\n",
       "         4.38848894e-01,   4.28571303e-01,   4.18439686e-01,\n",
       "         4.08450692e-01,   3.98601259e-01,   3.88888847e-01,\n",
       "         3.79310344e-01,   3.69862971e-01,   3.60544213e-01,\n",
       "         3.51351346e-01,   3.42281840e-01,   3.33333332e-01,\n",
       "         3.24503255e-01,   3.15789401e-01,   3.07189541e-01,\n",
       "         2.98701275e-01,   2.90322449e-01,   2.82051250e-01,\n",
       "         2.73885349e-01,   2.65822779e-01,   2.57861597e-01,\n",
       "         2.49999989e-01,   2.42236024e-01,   2.34567901e-01,\n",
       "         2.26993838e-01,   2.19512180e-01,   2.12121209e-01,\n",
       "         2.04819275e-01,   1.97604786e-01,   1.90476155e-01,\n",
       "         1.83431942e-01,   1.76470587e-01,   1.69590593e-01,\n",
       "         1.62790675e-01,   1.56069354e-01,   1.49425285e-01,\n",
       "         1.42857064e-01,   1.36363618e-01,   1.29943483e-01,\n",
       "         1.23595471e-01,   1.17318424e-01,   1.11111108e-01,\n",
       "         1.04972370e-01,   9.89010870e-02,   9.28961221e-02,\n",
       "         8.69565128e-02,   8.10810768e-02,   7.52688136e-02,\n",
       "         6.95187104e-02,   6.38297832e-02,   5.82010305e-02,\n",
       "         5.26315788e-02,   4.71203860e-02,   4.16666124e-02,\n",
       "         3.62694284e-02,   3.09278350e-02,   2.56409871e-02,\n",
       "         2.04078275e-02,   1.52284256e-02,   1.01010097e-02,\n",
       "         5.02510951e-03,  -5.90099969e-10])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zreds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hoseung/.local/lib/python3.4/site-packages/matplotlib/collections.py:590: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if self._edgecolors == str('face'):\n"
     ]
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1)\n",
    "im = ax.scatter(xx, yy, c=z, s=50, edgecolor='')\n",
    "ax.set_ylim([-0.05, 0.9])\n",
    "ax.set_yticks([0.0, 0.2, 0.4, 0.6, 0.8])\n",
    "ax.set_yticklabels([str(yy) for yy in yticks_ok])\n",
    "\n",
    "ax.set_xlabel(\"Redshift\")\n",
    "ax.set_xlim([nout_ini, nout_fi+1])\n",
    "zz_target = [0, 0.2, 0.5, 1.0, 2.0, 3.0]\n",
    "x_tick_pos = np.searchsorted(zreds[::-1], zz_target) + nout_ini# + nout_min\n",
    "\n",
    "ax.set_xticks(x_tick_pos)#[::-1])\n",
    "ax.set_xticklabels(labels = [\"{:0.1f}\".format(z) for z in zz_target])\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "fig, ax = plt.subplots(1)\n",
    "    \n",
    "im = ax.imshow(den_map, origin=\"lower\"#, cmap=\"Blues\", interpolation=\"none\"\n",
    "               , extent=[0,nnouts,0,nbins], aspect='auto')\n",
    "\n",
    "#ax.set_xlim([-1.5, lr_points*nreff])\n",
    "ax.set_ylim([-0.5,nbins]) \n",
    "#ax.set_title(r\"{:.1e} $< M_\\ast <$ {:.1e}\".format(mass_cut_l[imass], mass_cut_r[imass]))\n",
    "#ax.text(2,17, \"# gals:\" + str(ngood)) # data coordinates\n",
    "\n",
    "ax.set_yticks([0.5 + nbins * ly for ly in [0.0, 0.2, 0.4, 0.6, 0.8]])\n",
    "ax.set_yticklabels([str(yy) for yy in yticks_ok])\n",
    "\n",
    "ax.set_xlabel(\"Redshift\")\n",
    "#nout_min = 37\n",
    "#ax.set_xlim([nout_min, 190])\n",
    "#plt.gca().invert_xaxis()\n",
    "\n",
    "# Redshift axis\n",
    "#ax2 = ax.twiny()\n",
    "zz_target = [0, 0.2, 0.5, 1.0, 2.0, 3.0]\n",
    "x_tick_pos = np.searchsorted(zreds[::-1], zz_target)# + nout_min\n",
    "\n",
    "ax.set_xticks(x_tick_pos)#[::-1])\n",
    "ax.set_xticklabels(labels = [\"{:0.1f}\".format(z) for z in zz_target])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
