{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  find merger event\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "A reliable galaxy tree is ready. That is, now reliable stellar mass history, lambda evolution history, and so on are available. To see the relationship between lambda evolution and mergers, I need a catalog of merger events.\n",
    "\n",
    "Necessary information are: nout_start, nout_end, mass ratio, orbital parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To derive merger mass ratio, I need mass of galaxy as the sum of particle mass. \n",
    "1) add mass2 to consistent tree parameter set.\n",
    "2) retrieve data from original GalaxyMaker output. \n",
    "\n",
    "I prefer 2). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def join_struct_arrays(arrays):\n",
    "    sizes = np.array([a.itemsize for a in arrays])\n",
    "    offsets = np.r_[0, sizes.cumsum()]\n",
    "    n = len(arrays[0])\n",
    "    joint = np.empty((n, offsets[-1]), dtype=np.uint8)\n",
    "    for a, size, offset in zip(arrays, sizes, offsets):\n",
    "        joint[:,offset:offset+size] = a.view(np.uint8).reshape(n,size)\n",
    "    dtype = sum((a.dtype.descr for a in arrays), [])\n",
    "    return joint.ravel().view(dtype)\n",
    "\n",
    "def augment_tree(treedata, base, is_gal=False):\n",
    "    \"\"\"\n",
    "        Add more quantities to existing tree data. \n",
    "        \n",
    "        Consistent tree (built with HM/GM output) does not provide much detail of halos/galaxies.\n",
    "        I need to add some more information from original HM/GM output.\n",
    "    \"\"\"\n",
    "    \n",
    "    dtype_new_quantities = [('np', '<i4'), ('id', '<i4'), ('m', '<f4'), ('mvir', '<f4'),\n",
    "                            ('r', '<f4'), ('rvir', '<f4'), ('tvir', '<f4'), ('cvel', '<f4'),\n",
    "                            ('x', '<f4'), ('y', '<f4'), ('z', '<f4'),\n",
    "                            ('vx', '<f4'), ('vy', '<f4'), ('vz', '<f4'),\n",
    "                            ('ax', '<f4'), ('ay', '<f4'), ('az', '<f4'),\n",
    "                            ('sp', '<f4')]\n",
    "    if is_gal:\n",
    "        [dtype_new_quantities.append(i) for i in [('sig', '<f4'), ('sigbulge', '<f4'), ('mbulge', '<f4')]]\n",
    "           \n",
    "    New_arr = np.zeros(len(treedata), dtype=dtype_new_quantities)\n",
    "    import tree.halomodule as hmo\n",
    "    for nout in np.unique(treedata['nout']):\n",
    "        # nout and Orig_halo_id are required.\n",
    "        gal_org = hmo.Halo(base=wdir, nout=nout, halofinder='HM', load=True, is_gal=is_gal)\n",
    "        # Before we start, remove unnecessary coulmns\n",
    "        dtype_names = [field[0] for field in dtype_new_quantities]\n",
    "        gal_org = gal_org.data[dtype_names]\n",
    "        \n",
    "        ind_tree_this_nout = np.where(treedata['nout'] == nout)[0]\n",
    "        ok_gals = treedata['Orig_halo_id'][ind_tree_this_nout]\n",
    "        \n",
    "        # Galaxies are from a snapshot. Galaxy ID list must be a unique set.\n",
    "        assert len(ok_gals) == len(np.unique(ok_gals))\n",
    "        \n",
    "        ind_org_gals = [np.where(gal_org['id'] == gal)[0] for gal in ok_gals]\n",
    "        \n",
    "        for i, ind in enumerate(ind_org_gals):\n",
    "            assert sum(New_arr[ind_tree_this_nout[i]]) == 0. # array must be empty\n",
    "            New_arr[ind_tree_this_nout[i]] = gal_org[ind]\n",
    " \n",
    "    # Drop duplicate fields\n",
    "    #[\"id\", \"mvir\", \"rvir\", \"x\", \"y\", \"z\", \"vx\", \"vy\", \"vz\"]\n",
    "    keep_fields = [\"np\", \"m\", \"r\", \"tvir\", \"cvel\"]\n",
    "    if is_gal:\n",
    "        [keep_fields.append(i) for i in ['sig', 'sigbulge', 'mbulge']]\n",
    "        \n",
    "    return join_struct_arrays([treedata, New_arr[keep_fields]])\n",
    "\n",
    "##########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Consistent Tree data from ASCII is done\n",
      "------ NOUT fixed\n"
     ]
    }
   ],
   "source": [
    "from tree import treemodule\n",
    "from tree import treeutils\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "is_gal = True\n",
    "nout_fi = 187\n",
    "alltrees = treemodule.CTree()\n",
    "wdir = '/home/hoseung/Work/data/05427/'\n",
    "\n",
    "\n",
    "if is_gal:\n",
    "    # Galaxy tree\n",
    "    tree_path = 'GalaxyMaker/Trees/'\n",
    "    m_halo_min = 5e9 # minimum galaxy mass above which galaxies are searched for. \n",
    "else:\n",
    "    # halo tree\n",
    "    tree_path = 'org_halo/Trees/'\n",
    "    m_halo_min = 2e10 # minimum halo mass. \n",
    "\n",
    "try:    \n",
    "    alltrees = pickle.load(open(wdir + tree_path + \"extended_tree1.pickle\", \"rb\" ))\n",
    "    print(\"Loaded an extended tree\")\n",
    "except:\n",
    "    import tree.ctutils as ctu\n",
    "    alltrees = treemodule.CTree()\n",
    "    alltrees.load(filename= wdir + tree_path + 'tree_0_0_0.dat')\n",
    "    # Fix nout -----------------------------------------------------\n",
    "    nout_max = alltrees.data['nout'].max()\n",
    "    alltrees.data['nout'] += nout_fi - nout_max\n",
    "    print(\"------ NOUT fixed\")\n",
    "    #alltrees.data = ctu.augment_tree(alltrees.data, wdir, is_gal=is_gal)\n",
    "    #print(\"------ tree data extended\")\n",
    "    #pickle.dump(alltrees, open(wdir + tree_path + \"extended_tree.pickle\", \"wb\" ))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/hoseung/Work/data/05427/org_halo/Trees/tree_0_0_0.dat'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-44-ec74121a3c30>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtree_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'org_halo/Trees/'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0malltrees\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mwdir\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mtree_path\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'tree_0_0_0.dat'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/home/hoseung/Copy/pyclusterevol/tree/treemodule.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(self, filename)\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0m_is_ascii\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_load_ascii\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_load_pickle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/hoseung/Copy/pyclusterevol/tree/treemodule.py\u001b[0m in \u001b[0;36m_load_ascii\u001b[1;34m(self, filename)\u001b[0m\n\u001b[0;32m     49\u001b[0m                     \u001b[1;31m#'f8','f8','f8','f8','i8','i8']\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m         \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m180\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m                 \u001b[0mline\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/hoseung/Work/data/05427/org_halo/Trees/tree_0_0_0.dat'"
     ]
    }
   ],
   "source": [
    "tree_path = 'org_Trees/'    \n",
    "alltrees.load(filename= wdir + tree_path + 'tree_0_0_0.dat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_npr(treedata, idx):\n",
    "    ind = np.where(treedata['id'] == idx)[0]\n",
    "    return treedata['nprog'][ind][0] # I want int, not a int array\n",
    "\n",
    "def idx_to_ind(treedata, idx):\n",
    "    return np.where(treedata['id'] == idx)[0]\n",
    "\n",
    "def extract_a_tree(alltrees, idx_last):\n",
    "    \"\"\"\n",
    "        Returns one full tree.\n",
    "    \"\"\"\n",
    "    return alltrees[np.where(alltrees['tree_root_id'] == idx_last)]\n",
    "\n",
    "#def extract_main_tree(alltrees, idx_last):\n",
    "#    return alltrees[np.where((alltrees['tree_root_id'] == idx_last) & (alltrees['mmp'] == 1))]\n",
    "\n",
    "def get_progenitors(treedata, idx, main=False):\n",
    "    \"\"\"\n",
    "        Returns progenitors of a given halo/galaxy. \n",
    "        (from only one previous snapshot)\n",
    "    \"\"\"    \n",
    "    if main:\n",
    "        iprgs = np.where((treedata['desc_id'] == idx) & (treedata['mmp'] == 1))\n",
    "    else:\n",
    "        iprgs = np.where(treedata['desc_id'] == idx)\n",
    "\n",
    "    return treedata['id'][iprgs]\n",
    "\n",
    "def extract_main_tree(treedata, idx=None):\n",
    "    \"\"\"\n",
    "        Returns a single branch/trunk of tree following only the main progenitors.\n",
    "        Works whether the treedata is alltrees or atree.\n",
    "        Search until no progenitor is found. Doesn't matter how long the given tree is. \n",
    "    \"\"\"\n",
    "    if idx == None:\n",
    "        print(\"No idx is given\")\n",
    "        idx = treedata['id'][0]\n",
    "        print(\"idx = \", idx)\n",
    "    \n",
    "    nprg = 1\n",
    "    idx_list=[idx]\n",
    "    ind_list=[np.where(treedata['id'] == idx)[0]]\n",
    "    \n",
    "    while nprg > 0:\n",
    "        idx = get_progenitors(treedata, idx, main=True)[0]\n",
    "        ind_list.append(np.where(treedata['id'] == idx)[0])\n",
    "        nprg = get_npr(treedata, idx)\n",
    "        \n",
    "    return treedata[ind_list]\n",
    "\n",
    "def main_thread(atree, idx):\n",
    "    main_prg = extract_main_tree(atree, idx)\n",
    "    \n",
    "    ind = np.where(atree['id'] == idx)[0]\n",
    "    nout_now = atree['nout'][ind]\n",
    "    nout_fi = atree['nout'].max()\n",
    "    if nout_now < nout_fi:\n",
    "        desc = idx\n",
    "        ind_desc_list=[]\n",
    "        while desc > 0:\n",
    "            ind = np.where(atree['id'] == desc)[0]\n",
    "            ind_desc_list.insert(0,ind)\n",
    "            desc = atree['desc_id'][ind]\n",
    "\n",
    "    return np.concatenate((atree[ind_desc_list],main_prg))#,axis=1)\n",
    "\n",
    "def last_halos(treedata, return_ind=False):\n",
    "    nout_max = treedata['nout'].max()\n",
    "    if return_ind:\n",
    "        return np.where(treedata['nout'] == nout_max)[0]\n",
    "    else:\n",
    "        return treedata['id'][np.where(treedata['nout'] == nout_max)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "atree = extract_a_tree(alltrees.data, 119657)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "maintree = extract_main_tree(alltrees.data, 119377)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[187],\n",
       "       [186],\n",
       "       [185],\n",
       "       [184],\n",
       "       [183],\n",
       "       [182],\n",
       "       [181],\n",
       "       [180],\n",
       "       [179],\n",
       "       [178],\n",
       "       [177],\n",
       "       [176],\n",
       "       [175],\n",
       "       [174],\n",
       "       [173],\n",
       "       [172],\n",
       "       [171],\n",
       "       [170],\n",
       "       [169],\n",
       "       [168],\n",
       "       [167],\n",
       "       [166],\n",
       "       [165],\n",
       "       [164],\n",
       "       [163],\n",
       "       [162],\n",
       "       [161],\n",
       "       [160],\n",
       "       [159],\n",
       "       [158],\n",
       "       [157],\n",
       "       [156],\n",
       "       [155],\n",
       "       [154],\n",
       "       [153],\n",
       "       [152],\n",
       "       [151],\n",
       "       [150],\n",
       "       [149],\n",
       "       [148],\n",
       "       [147],\n",
       "       [146],\n",
       "       [145],\n",
       "       [144],\n",
       "       [143],\n",
       "       [142],\n",
       "       [141],\n",
       "       [140],\n",
       "       [139],\n",
       "       [138],\n",
       "       [137],\n",
       "       [136],\n",
       "       [135],\n",
       "       [134],\n",
       "       [133],\n",
       "       [132],\n",
       "       [131],\n",
       "       [130],\n",
       "       [129],\n",
       "       [128],\n",
       "       [127],\n",
       "       [126],\n",
       "       [125],\n",
       "       [124],\n",
       "       [123],\n",
       "       [122],\n",
       "       [121],\n",
       "       [120],\n",
       "       [119],\n",
       "       [118],\n",
       "       [117],\n",
       "       [116],\n",
       "       [115],\n",
       "       [114],\n",
       "       [113],\n",
       "       [112],\n",
       "       [111],\n",
       "       [110],\n",
       "       [109],\n",
       "       [108],\n",
       "       [107],\n",
       "       [106],\n",
       "       [105],\n",
       "       [104],\n",
       "       [103],\n",
       "       [102],\n",
       "       [101],\n",
       "       [100],\n",
       "       [ 99],\n",
       "       [ 98],\n",
       "       [ 97],\n",
       "       [ 96],\n",
       "       [ 95],\n",
       "       [ 94],\n",
       "       [ 93],\n",
       "       [ 92],\n",
       "       [ 91],\n",
       "       [ 90],\n",
       "       [ 89],\n",
       "       [ 88],\n",
       "       [ 87],\n",
       "       [ 86],\n",
       "       [ 85],\n",
       "       [ 84],\n",
       "       [ 83],\n",
       "       [ 82],\n",
       "       [ 81],\n",
       "       [ 80],\n",
       "       [ 79],\n",
       "       [ 78],\n",
       "       [ 77],\n",
       "       [ 76],\n",
       "       [ 75],\n",
       "       [ 74],\n",
       "       [ 73],\n",
       "       [ 72],\n",
       "       [ 71],\n",
       "       [ 70],\n",
       "       [ 69],\n",
       "       [ 68],\n",
       "       [ 67],\n",
       "       [ 66],\n",
       "       [ 65],\n",
       "       [ 64],\n",
       "       [ 63],\n",
       "       [ 62],\n",
       "       [ 61],\n",
       "       [ 60],\n",
       "       [ 59],\n",
       "       [ 58],\n",
       "       [ 57],\n",
       "       [ 56],\n",
       "       [ 55],\n",
       "       [ 54],\n",
       "       [ 53],\n",
       "       [ 52],\n",
       "       [ 51],\n",
       "       [ 50],\n",
       "       [ 49],\n",
       "       [ 48],\n",
       "       [ 47],\n",
       "       [ 46],\n",
       "       [ 45],\n",
       "       [ 44],\n",
       "       [ 43],\n",
       "       [ 42],\n",
       "       [ 41],\n",
       "       [ 40],\n",
       "       [ 39],\n",
       "       [ 38],\n",
       "       [ 37],\n",
       "       [ 36],\n",
       "       [ 35],\n",
       "       [ 34],\n",
       "       [ 33],\n",
       "       [ 32],\n",
       "       [ 31],\n",
       "       [ 30],\n",
       "       [ 29],\n",
       "       [ 28],\n",
       "       [ 27],\n",
       "       [ 26],\n",
       "       [ 25],\n",
       "       [ 24],\n",
       "       [ 23],\n",
       "       [ 22],\n",
       "       [ 21],\n",
       "       [ 20],\n",
       "       [ 19],\n",
       "       [ 18]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maintree['nout']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "maintree = extract_main_tree(alltrees.data, 119377)\n",
    "plt.plot(np.log10(maintree['mvir']))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "114697"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster evolution (BCGs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype([('aexp', '<f8'), ('id', '<i8'), ('desc_aexp', '<i8'), ('desc_id', '<i8'), ('nprog', '<i8'), ('pid', '<i8'), ('upid', '<i8'), ('desc_pid', '<i8'), ('phantom', '<i8'), ('sam_mvir', '<f8'), ('mvir', '<f8'), ('rvir', '<f8'), ('rs', '<i8'), ('vrms', '<f8'), ('mmp', '<f8'), ('aexp_last_MM', '<f8'), ('vmax', '<i8'), ('x', '<f8'), ('y', '<f8'), ('z', '<f8'), ('vx', '<f8'), ('vy', '<f8'), ('vz', '<i8'), ('jx', '<i8'), ('jy', '<i8'), ('jz', '<f8'), ('spin', '<i8'), ('b_id', '<i8'), ('d_id', '<i8'), ('tree_root_id', '<i8'), ('Orig_halo_id', '<i8'), ('nout', '<i8'), ('next_coprogenitor_d_id', '<i8'), ('last_progenitor_d_id', '<f8')])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_halos.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "no field of name np",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/home/hoseung/.local/lib/python3.4/site-packages/numpy/core/_internal.py\u001b[0m in \u001b[0;36m_index_fields\u001b[1;34m(ary, names)\u001b[0m\n\u001b[0;32m    316\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 317\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mary\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetfield\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfields\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnames\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfields\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnames\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    318\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'np'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-26ff5e3bdd8d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mi_last_halo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlast_halos\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malltrees\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_ind\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mfinal_halos\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0malltrees\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi_last_halo\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mi_cluster\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfinal_halos\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'np'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mcluster\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfinal_halos\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'id'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi_cluster\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/hoseung/.local/lib/python3.4/site-packages/numpy/core/_internal.py\u001b[0m in \u001b[0;36m_index_fields\u001b[1;34m(ary, names)\u001b[0m\n\u001b[0;32m    317\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mary\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetfield\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfields\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnames\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfields\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnames\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    318\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 319\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"no field of name %s\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    320\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    321\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: no field of name np"
     ]
    }
   ],
   "source": [
    "# Find the cluster\n",
    "i_last_halo = last_halos(alltrees.data, return_ind=True)\n",
    "final_halos = alltrees.data[i_last_halo]\n",
    "i_cluster = np.argmax(final_halos['np'])\n",
    "cluster = final_halos['id'][i_cluster]\n",
    "\n",
    "atree = extract_a_tree(alltrees.data, cluster)\n",
    "main = extract_main_tree(alltrees.data, cluster)\n",
    "x_clu, y_clu = atree['x'][0], atree['y'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create halo evolution animation\n",
    "import matplotlib.pyplot as plt\n",
    "import draw.pp as pp\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, aspect='equal')\n",
    "\n",
    "# color some halos\n",
    "i_z1 = np.where(atree['aexp'] == 0.5)[0]\n",
    "top5 = np.argsort(atree['mvir'][i_z1])[-5:]\n",
    "id_top5 = atree['id'][i_z1][top5]\n",
    "\n",
    "large_branches=[]\n",
    "for idx in id_top5:\n",
    "    large_branches.append(main_thread(atree, idx))\n",
    "\n",
    "x2 = np.zeros((100, len(id_top5)))\n",
    "y2 = np.zeros((100, len(id_top5)))\n",
    "r2 = np.zeros((100, len(id_top5)))\n",
    "for i, large_branch in enumerate(large_branches):\n",
    "    for j in range(100):\n",
    "        x2[j,i] = large_branch['x'][j]\n",
    "        y2[j,i] = large_branch['y'][j]\n",
    "        r2[j,i] = large_branch['rvir'][j]\n",
    "\n",
    "for nout in range(11,188):\n",
    "    plt.cla()\n",
    "    ax.set_xlim([x_clu-3, x_clu+3])\n",
    "    ax.set_ylim([y_clu-3, y_clu+3])\n",
    "    \n",
    "    halos_this_nout = atree[np.where(atree['nout'] == nout)[0]]\n",
    "\n",
    "    ax.set_title(\"aexp = {:<6.3f}\".format(halos_this_nout['aexp'][0]))\n",
    "    x = halos_this_nout['x']\n",
    "    y = halos_this_nout['y']\n",
    "    r = halos_this_nout['rvir'] / 1000\n",
    "    for i in range(len(halos_this_nout)):\n",
    "        pp.circle_scatter(ax, x[i], y[i], r[i], facecolor='none', edgecolor='b')\n",
    "    if nout > 90:\n",
    "        for i in range(len(id_top5)):\n",
    "            pp.circle_scatter(ax, x2[187-nout,i], y2[187-nout,i], r2[187-nout,i]/1000, facecolor='none', edgecolor='r')\n",
    "    plt.savefig(wdir + str(nout).zfill(3) + '.png')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merger properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Calculate merger event parameters\n",
    "def find_merger(atree, idx=None, aexp_min=0.0):\n",
    "    \"\"\"\n",
    "        find indices of merger event from a tree.\n",
    "        (Full tree or main progenitor trunk)\n",
    "    \"\"\"\n",
    "    if idx == None:\n",
    "        idx = atree['id'][0]\n",
    "        \n",
    "    nprg = 1\n",
    "    merger_list=[]\n",
    "\n",
    "    i = 0\n",
    "    while nprg > 0:\n",
    "        idx = get_progenitors(atree, idx, main=True)[0]\n",
    "        ind = np.where(atree['id'] == idx)[0]\n",
    "        if atree['aexp'][ind] < aexp_min:\n",
    "            break\n",
    "        nprg = get_npr(atree, idx)\n",
    "\n",
    "        if nprg > 1:\n",
    "            merger_list.append(i)\n",
    "        i +=1\n",
    "    return merger_list\n",
    "\n",
    "\n",
    "def merger_mass_ratio(atree, idx=None):\n",
    "    \"\"\"\n",
    "    return mass ratio of the given merger event\n",
    "    \"\"\"\n",
    "    if idx == None:\n",
    "        idx = atree['id'][0]\n",
    "        \n",
    "    prgs = get_progenitors(atree, idx)\n",
    "    \n",
    "    # only for mergers\n",
    "    if len(prgs) > 1:\n",
    "        i_prgs = [np.where(atree['id'] == i)[0] for i in prgs]\n",
    "        mass = []\n",
    "        for iprg in i_prgs:\n",
    "            mass.append(atree['m'])\n",
    "    else:\n",
    "        print(\"This is not a merger\")\n",
    "        return 0\n",
    "    \n",
    "\n",
    "def merger_properties_main_prg(atree, idx):\n",
    "    \"\"\"\n",
    "        Calculate merger mass ratio for \"one\" merger event.\n",
    "\n",
    "    if idx == None:\n",
    "        if nout == None:\n",
    "            print(\"Both idx and nout are missing\")\n",
    "            return\n",
    "    else:\n",
    "        if nout == None:\n",
    "            nout = np.where(atree['id'] == idx)[0]\n",
    "\n",
    "    idx = atree['id'][ind]\n",
    "    \"\"\"    \n",
    "\n",
    "    #prgs = get_progenitors(atree, idx)\n",
    "    #if len(prgs) > 1:\n",
    "    #    i_prgs = [np.where(atree['id'] == i)[0] for i in prgs]\n",
    "    \n",
    "    i_prgs = np.where(atree['desc_id'] == idx)[0]\n",
    "        \n",
    "    print(i_prgs)\n",
    "    id_prgs = atree['id'][i_prgs]\n",
    "    mass_prgs = atree['m'][i_prgs]\n",
    "    \n",
    "    #mass_prgs_norm = mass_prgs / sum(mass_prgs)\n",
    "\n",
    "    return mass_prgs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Merger mass ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of final halos 428\n",
      "top 10 galaxies \n",
      " [114718 114704 115122 114715 115082 114711 114703 115113 115072 114697]\n",
      "and there masses\n",
      " [  4.78841815e+10   5.33348434e+10   5.49385830e+10   5.87139891e+10\n",
      "   6.03292754e+10   8.05510349e+10   8.44200264e+10   1.31157328e+11\n",
      "   7.06910487e+11   9.57576839e+11]\n",
      "The last one is the BCG.\n"
     ]
    }
   ],
   "source": [
    "print(\"number of final halos\", len(final_halos['id']))\n",
    "ind = np.argsort(final_halos['m'])\n",
    "large_final_halos = final_halos['id'][ind[-10:]]\n",
    "print(\"top 10 galaxies \\n\", large_final_halos)\n",
    "print(\"and there masses\\n\", final_halos['m'][ind[-10:]])\n",
    "print(\"The last one is the BCG.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115082\n",
      "[60, 68, 69, 87]\n"
     ]
    }
   ],
   "source": [
    "thisgal = large_final_halos[4]\n",
    "print(thisgal)\n",
    "atree = extract_a_tree(alltrees.data, thisgal)\n",
    "mergers = find_merger(atree, idx=thisgal, aexp_min=0.1)\n",
    "print(mergers)\n",
    "main_prg = extract_main_tree(atree, idx=thisgal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  6.70292296e+10   3.75957402e+09]\n",
      "[  6.27755704e+10   9.33667226e+09]\n",
      "[78 79]\n",
      "Major Merger at nout = 122\n",
      " [  6.27755704e+10   9.33667226e+09]\n",
      "[  0.00000000e+00   1.15805256e+10]\n",
      "[  1.63997901e+10   3.62442528e+08]\n"
     ]
    }
   ],
   "source": [
    "# prg_mass = merger_properties_main_prg(atree, main_prg['id'][87])\n",
    "\n",
    "MM_ratio= 0.1\n",
    "for i in range(50, len(main_prg['nout'])):\n",
    "    i_prgs = np.where(atree['desc_id'] == main_prg['id'][i])[0]\n",
    "    if len(i_prgs) > 1:\n",
    "        id_prgs = atree['id'][i_prgs]\n",
    "        mass_prgs = atree['m'][i_prgs]   \n",
    "        mass_ratios = mass_prgs / max(mass_prgs)\n",
    "        print(mass_prgs)\n",
    "        major_mergers = i_prgs[np.where(mass_ratios > MM_ratio)[0]]\n",
    "        \n",
    "        if len(major_mergers) > 1:\n",
    "            print(major_mergers)\n",
    "            print(\"Major Merger at nout = {}\\n\".format(atree['nout'][i]), atree['m'][major_mergers])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
