{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Measure delta Lambda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lambda fluctuates, and it fluctuates more as two galaxies get closer.\n",
    "It is hard to separate 'normal' stage and 'merging' stage of lambda.\n",
    "Measuring L at normal stage may require some fitting algorithm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_pickle(fname):\n",
    "    with open(fname, 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "## time\n",
    "def aexp2zred(aexp):\n",
    "    return [1.0/a - 1.0 for a in aexp]\n",
    "\n",
    "def zred2aexp(zred):\n",
    "    return [1.0/(1.0 + z) for z in zred]\n",
    "\n",
    "def lbt2aexp(lts):\n",
    "    import astropy.units as u\n",
    "    from astropy.cosmology import WMAP7, z_at_value\n",
    "    zreds = [z_at_value(WMAP7.lookback_time, ll * u.Gyr) for ll in lts]\n",
    "    return [1.0/(1+z) for z in zreds]\n",
    "\n",
    "def density_map(x, y, ax, sort=True):\n",
    "    from scipy.stats import gaussian_kde\n",
    "    xy = np.vstack([x,y])\n",
    "    z = gaussian_kde(xy)(xy) \n",
    "    z /= max(z)\n",
    "\n",
    "    idx = z.argsort()    \n",
    "    xx, yy = x[idx], y[idx]\n",
    "    z = z[idx]\n",
    "    \n",
    "    im = ax.scatter(xx, yy, c=z, s=50, edgecolor='')\n",
    "    return im\n",
    "\n",
    "\n",
    "def sigma_clip_ind(c, high, low):\n",
    "    \"\"\"\n",
    "        returns indices of sigma-clipping-safe elements.\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    ind = (np.mean(c) - np.std(c)*low < c) * (c < np.mean(c) + np.std(c)*high)\n",
    "    return ind\n",
    "\n",
    "\n",
    "def mask_outlier(y, low=1.5, high=1.5):\n",
    "    \"\"\"\n",
    "        maks outlier assuming monotonic trend.\n",
    "    \"\"\"\n",
    "    x = np.arange(len(y))\n",
    "\n",
    "    # linear fitting .. more desirably, a very strong smoothing scheme that can reconstrcut mild curve.\n",
    "    slope, intercept, r_value, p_value, std_err = scipy.stats.linregress(x,y)\n",
    "\n",
    "    # extract linear fit\n",
    "    yy = y - (slope * x + intercept)\n",
    "\n",
    "    # sigma clipped value = mean of the rest \n",
    "    i_good = sigma_clip_ind(yy, low, high)\n",
    "    yy[~i_good] = np.mean(yy[i_good])\n",
    "\n",
    "    # add linear fit again\n",
    "    return yy + (slope * x + intercept)\n",
    "\n",
    "\n",
    "def smooth(x, beta=5, window_len=20, monotonic=False):\n",
    "    \"\"\" \n",
    "    kaiser window smoothing \n",
    "    beta = 5 : Similar to a Hamming\n",
    "    \"\"\"\n",
    "    \n",
    "    if monotonic:\n",
    "        \"\"\"\n",
    "        if there is an overall slope, smoothing may result in offset.\n",
    "        compensate for that. \n",
    "        \"\"\"\n",
    "        slope, intercept, r_value, p_value, std_err = scipy.stats.linregress(x, y=np.arange(len(x)))\n",
    "        xx = np.arange(len(x)) * slope + intercept\n",
    "        x = x - xx\n",
    "    \n",
    "    # extending the data at beginning and at the end\n",
    "    # to apply the window at the borders\n",
    "    s = np.r_[x[window_len-1:0:-1], x, x[-1:-window_len:-1]]\n",
    "    w = np.kaiser(window_len,beta)\n",
    "    y = np.convolve(w/w.sum(),s,mode='valid')\n",
    "    if monotonic: \n",
    "         return y[int(window_len)/2:len(y)-int(window_len/2) + 1] + xx#[x[window_len-1:0:-1],x,x[-1:-window_len:-1]]\n",
    "    else:\n",
    "        return y[int(window_len)/2:len(y)-int(window_len/2) + 1]\n",
    "        #return y[5:len(y)-5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class MainPrg():\n",
    "    import tree.ctutils as ctu\n",
    "    import numpy as np\n",
    "    \n",
    "    def __init__(self, treedata, final_gal, nout_ini=None, nout_fi=None):\n",
    "\n",
    "        temp_tree = ctu.extract_main_tree(treedata, final_gal)\n",
    "        if nout_ini == None:\n",
    "            nout_ini = min(temp_tree['nout'])\n",
    "        if nout_fi == None:\n",
    "            nout_fi = max(temp_tree['nout'])            \n",
    "            \n",
    "        self.nouts = np.arange(nout_fi, nout_ini -1, -1)\n",
    "        self.idxs = temp_tree['id'] # nout_ini, nout_fi consideration needed.\n",
    "        self.ids = temp_tree['Orig_halo_id']\n",
    "        self.data = None\n",
    "    \n",
    "    def set_data(self, cat, nout):\n",
    "        \"\"\"\n",
    "        compile data from catalogs.\n",
    "        \"\"\"\n",
    "        if nout in self.nouts:\n",
    "            # Declare self.data first if there isn't any.\n",
    "            if self.data == None:\n",
    "                self.data = np.zeros(len(self.nouts), dtype=cat.dtype)\n",
    "            inow = self.nouts == nout\n",
    "            a = np.where(cat['id'] == self.ids[inow])[0]\n",
    "            if len(a) > 0:\n",
    "                self.data[inow] = cat[a]        \n",
    "            else:\n",
    "                pass\n",
    "                #print(self.ids[inow],cat['id'])\n",
    "        else:\n",
    "            pass\n",
    "            #print(\"No {} in the catalog\".format(nout))\n",
    "            \n",
    "    def clip_non_detection(self):\n",
    "        # end of galaxy tree = last non-zero position.\n",
    "        i_first_nout = max(np.where(self.data['id'] > 0)[0])\n",
    "        # then, only [0-i_first_nout] are valid.\n",
    "        # earlier then 187 - 91-th are zero. so get rid of them.\n",
    "        self.data = self.data[:i_first_nout].copy()\n",
    "        self.nouts = self.nouts[:i_first_nout].copy()\n",
    "        self.ids = self.ids[:i_first_nout].copy()\n",
    "        self.idxs = self.idxs[:i_first_nout].copy()\n",
    "        \n",
    "    def fill_missing_data(self):\n",
    "        assert (self.ids[-1] != 0)\n",
    "        def locate_wrong_arr(arrays, len_cut = 2):\n",
    "            ind_bad = []\n",
    "            for i, arr in enumerate(arrays):\n",
    "                if isinstance(arr, int): \n",
    "                    ind_bad.append(i)\n",
    "                elif len(arr) < len_cut:\n",
    "                    ind_bad.append(i)\n",
    "            return ind_bad\n",
    "        \n",
    "        # loop over all fields except id, index, and non-physical entries.\n",
    "        i_bad = np.where(self.data['id'] == 0)[0]\n",
    "        for field in self.data.dtype.names:\n",
    "            if field in [\"index\", \"id\"]:\n",
    "                continue\n",
    "            arr = self.data[field] # it's a view.\n",
    "        #    i_bad = locate_wrong_arr(arr)\n",
    "\n",
    "            for i_b in i_bad:\n",
    "                # neighbouring array might also be empty. Search for closest valid array.\n",
    "                # left point\n",
    "                i_l = i_b - 1\n",
    "                while(i_l in i_bad):\n",
    "                    i_l = i_l - 1\n",
    "                # right point\n",
    "                i_r = i_b + 1\n",
    "                while(i_r in i_bad):\n",
    "                    i_r = i_r + 1\n",
    "\n",
    "                arr[i_b] = (arr[i_b -1] + arr[i_b +1])/2.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# Read a single galaxy evolution catalog.\n",
    "import pickle\n",
    "#wdir = '/home/hoseung/Work/data/05427/'\n",
    "wdir = '/home/hoseung/Work/data/28928/'\n",
    "cdir = 'catalog_GM/'\n",
    "\n",
    "#idxs = [122668, 122669, 122683, 122695, 122747, 122750, 122835, 123087] 05427"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded an extended tree\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hoseung/.local/lib/python3.4/site-packages/IPython/kernel/__main__.py:24: FutureWarning: comparison to `None` will result in an elementwise object comparison in the future.\n"
     ]
    }
   ],
   "source": [
    "# Serialize catalogs. -> Only main galaxies\n",
    "\n",
    "nout_fi = 187\n",
    "\n",
    "# main galaxy list\n",
    "import tree.ctutils as ctu\n",
    "alltrees = ctu.load_tree(wdir, is_gal=True)\n",
    "ad = alltrees.data\n",
    "tn = ad[ad['nout'] == nout_fi]\n",
    "\n",
    "cat = pickle.load(open(wdir + cdir + 'catalog' + str(nout_fi) + '.pickle', 'rb'))\n",
    "    \n",
    "idx_all = [tn['id'][tn['Orig_halo_id'] == id_final][0] for id_final in cat['id']]\n",
    "mpgs = [MainPrg(ad, idx) for idx in idx_all]\n",
    "#print(mpgs[0].nouts)\n",
    "#print(mpgs[0].ids)\n",
    "for nout in range(60,188):\n",
    "    cat = pickle.load(open(wdir + cdir + 'catalog' + str(nout) + '.pickle', 'rb'))\n",
    "    for mpg in mpgs:\n",
    "        mpg.set_data(cat, nout)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "중간에 비는 것은 아마도 phantom이라 'Orig_halo_id'는 없는 경우일 듯. \n",
    "그렇기 때문에..! cat을 만들때 idx를 넣어야함!  : 넣었음. (근데 final_ID는 뺐나...?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What mass cut was applied? (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gal.nouts 33 187\n"
     ]
    }
   ],
   "source": [
    "# from Complete-main-tree criterion, nout = 33 ~ 187.\n",
    "print(\"gal.nouts\",min(gal.nouts), max(gal.nouts))\n",
    "\n",
    "# But if galaxy goes below the mass cut at some point, \n",
    "# galaxy property is no longer measured.\n",
    "plt.plot(gal.data['mstar'])\n",
    "plt.show()\n",
    "#print(\"gal.data['mstar']\", gal.data['mstar'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "constant mass cut... 5e9. Need to re-run it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1)\n",
    "for gal in mpgs:\n",
    "    ax.plot(np.log10(gal.data['mstar'][gal.data['mstar'] > 0]))\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def smoothed_reff(cat, nout_merger):\n",
    "    \"\"\"\n",
    "    returns \"representative\" lambda at each nout by assuming monotonic change in Reff. \n",
    "    During merger, Reff can fluctuate, and if has no physical meaning to infer Labda at Reff during merger stage. \n",
    "    So Reff' is derived by linear interpolating Reffs before and after the merger. \n",
    "    \n",
    "    cat is one galaxy catalog over time.\n",
    "    \"\"\"\n",
    "    import utils.match as mtc\n",
    "    i_merger = np.where(cat['nout'] == nout_merger)[0]\n",
    "    ind_lower = 20\n",
    "    ind_upper = 20\n",
    "    \n",
    "    reffs = cat['rgal']\n",
    "    # left and right values chosen by sigma-clipping\n",
    "    r_lefts, b, c = scipy.stats.sigmaclip(reffs[max([0,i_merger-ind_lower]):i_merger], sig_lower, sig_upper)\n",
    "    print(r_lefts)\n",
    "    r_left = r_lefts[-1]\n",
    "    i_left = np.where(reffs == r_left)[0]\n",
    "    \n",
    "\n",
    "    r_rights, b,c = scipy.stats.sigmaclip(reffs[i_merger:min([i_merger+ind_upper,len(reffs)])], sig_lower, sig_upper)\n",
    "    r_right = r_rights[0]\n",
    "    i_right = np.where(reffs == r_right)[0]\n",
    "\n",
    "    r_prime = reffs\n",
    "    print(i_left, i_right)\n",
    "    print(np.linspace(r_left, r_right, i_right - i_left + 1))\n",
    "    r_prime[i_left : i_right + 1] = np.linspace(r_left, r_right, i_right - i_left + 1)\n",
    "    return r_prime    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gather same galaxy pngs together (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "new_gal_dir = wdir + '/z1/gal_' + str(gal.idxs[0])\n",
    "os.mkdir(new_gal_dir)\n",
    "\n",
    "for nout, id in zip(gal.nouts, gal.ids):\n",
    "    fname = wdir + \"/z1/galaxy_plot\" + str(nout) + \"/\" + str(nout) + \"_\" + str(id) + '.png'\n",
    "    if os.path.isfile(fname):\n",
    "        shutil.move(fname, new_gal_dir + '/'+ str(nout) + \"_\" + str(id) + '.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### fix Reff of a galaxy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Galaxy ID at the final nout 83196, 84\n"
     ]
    }
   ],
   "source": [
    "#idx = mgl['idx'][2]\n",
    "gal = mpgs[3]\n",
    "gal.clip_non_detection()\n",
    "gal.fill_missing_data()\n",
    "print(\"Galaxy ID at the final nout {}, {}\".format(gal.idxs[0], gal.ids[0]))\n",
    "\n",
    "nout_merger = 118"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have reularized galaxy evolution data.\n",
    "\n",
    "I want to measure rotation parameter before and after a merger.\n",
    "I take 20 lambda values before and after the merger, sigma clip outliers, and take median value.\n",
    "So dLambda = media(Lambda_after) - median(Lambda_before).\n",
    "\n",
    "However, Lambda measurement at 1Reff requires robust Reff measurement, which is very tough during merger events.\n",
    "So I smooth Reff evolution history to guess more reasonable Reff values at all points. Following is the procedure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def fixed_ind_Lr(gal):\n",
    "    nnouts = len(gal.nouts)\n",
    "    ind_reff_fix = np.zeros(nnouts, dtype='i4')\n",
    "\n",
    "    smooth_r = smooth(mask_outlier(gal.data['rgal'], 1.5, 1.5), 50, monotonic=False)\n",
    "\n",
    "    # fixed Reff array\n",
    "    for i in range(nnouts):\n",
    "        # 1Reff = 10 points\n",
    "        reff_real = smooth_r[i]\n",
    "        reff = gal.data['rgal'][i]\n",
    "        try:\n",
    "            ind_reff_fix[i] = np.round(reff_real/reff * 5) -1\n",
    "        except:\n",
    "            pass\n",
    "    return ind_reff_fix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(4,4)\n",
    "axs = axs.flatten()\n",
    "for i, field in enumerate(gal.data.dtype.names):\n",
    "    if field == \"lambda_arr\":\n",
    "        continue\n",
    "    axs[i].plot(gal.data[field])\n",
    "    axs[i].set_ylabel(field)\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ind_reff_fix points to the Lambda_arr element closest to the fixed Reff at every nout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# fixed Lambda array based on Reff_fix.\n",
    "ind_reff_fix = fixed_ind_Lr(gal)\n",
    "lam_fix = np.zeros(sum(ind_reff_fix > 0))\n",
    "lam = np.zeros(sum(ind_reff_fix > 0))\n",
    "for i, ind in enumerate(ind_reff_fix[ind_reff_fix > 0]):\n",
    "    lam_fix[i] = gal.data['lambda_arr'][i][ind]\n",
    "    lam[i] = gal.data['lambda_arr'][i][4]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "왜 lambda_r 이랑 lambda_arr[4]랑 다르지? -> 0.5Reff에서 측정했었음..!\n",
    "그림에는 0.5Reff이지만 나머지는 1.0Reff로 쓸래.. \n",
    "나중에 그림도 1.0으로 바꾸지 뭐.. (lambda_single.py로)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1)\n",
    "ax.plot(lam, 'b-')\n",
    "ax.plot(lam_fix, 'g--')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y = gal.data['rgal']\n",
    "fig, ax = plt.subplots(1)\n",
    "ax.plot(y)\n",
    "ax.plot(smooth_r, 'r--')\n",
    "#ax.plot(smoothed_reff(gal.data['reff'], 102))\n",
    "ax.plot(gal.data['lambda_r'] * 20)\n",
    "ax.set_title(\"Rgal, Rgal_smoothed, and Lambda_r\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "i_merger = 75\n",
    "#i_merger = 187 - mgl[igal][2]\n",
    "\n",
    "lam = lam_fix\n",
    "\n",
    "ind_upper = 20\n",
    "ind_lower = 20\n",
    "sig_upper = 2.0\n",
    "sig_lower = 2.0\n",
    "\n",
    "x_al = range(max([0,i_merger-ind_lower]), i_merger)\n",
    "x_ar = range(i_merger,min([i_merger+ind_upper,len(lam)]))\n",
    "\n",
    "al, b1, c1 = scipy.stats.sigmaclip(lam[x_al], sig_lower, sig_upper)\n",
    "ar, b2, c2 = scipy.stats.sigmaclip(lam[x_ar], sig_lower, sig_upper)\n",
    "\n",
    "dl = np.median(ar) - np.median(al)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.247116707298 0.241349076274\n",
      "0.240646574733 0.245995951079\n"
     ]
    }
   ],
   "source": [
    "# i_merger가 정확해야하는데... \n",
    "# Tree에서 주는 merger는 final coalescence일 가능성이 높음. \n",
    "print(np.mean(al), np.mean(ar))\n",
    "print(np.median(al), np.median(ar))\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1)\n",
    "ax.plot(x_al, lam[x_al], 'r')\n",
    "ax.plot(x_ar, lam[x_ar], 'b')\n",
    "ax.axhline(np.mean(al), color='r')\n",
    "ax.axhline(np.mean(ar), color='b')\n",
    "#ax.plot(smoothed_reff(gal.data['reff'], 102))\n",
    "ax.set_title(\"Rgal, Rgal_smoothed, and Lambda_r\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I can measure dL in this way, but am I following the right galaxy? is the tree right?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1)\n",
    "ax.scatter(mr, dl)\n",
    "ax.set_ylim([-1,+1])\n",
    "ax.set_xlim([0, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(83116, 1.6080775310169404, 171) (83334, 9.723992317756643, 113)\n",
      " (83117, 5.628116671634298, 107) (83139, 1.8823297100888297, 124)\n",
      " (83345, 2.8883693284502954, 165) (83345, 1.0428572316559068, 152)\n",
      " (83184, 1.532682197682854, 105) (83155, 1.3627227787912803, 141)\n",
      " (83155, 1.4007294519675875, 138) (83178, 7.298628930814874, 150)\n",
      " (83208, 8.469499127479162, 113) (83242, 3.650532934609259, 136)\n",
      " (83196, 1.7698715554171962, 115)]\n"
     ]
    }
   ],
   "source": [
    "# load merger galaxy list (geneated by scripts/notebooks/halo/Merter_no_cat.ipynb)\n",
    "with open(wdir + 'merger_list.txt', 'rb') as f:\n",
    "    mgl = np.genfromtxt(f, dtype=[('idx','i8'),('mr','f8'),('nout','i4')])\n",
    "print(mgl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83116"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mgl[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len Lr_arr 91\n",
      "72\n",
      "[0]\n",
      "[ array([ 0.24895497,  0.44111995,  0.61401316,  0.74073474,  0.93864124,\n",
      "        1.03958405,  1.06799237,  1.09722928,  1.07574542,  1.19460084,\n",
      "        1.15060364,  1.26472134,  1.37878218,  1.39374947,  1.63227243])]\n"
     ]
    }
   ],
   "source": [
    "# Obsolete\n",
    "# lambda_arr = [0] instead of an array if ill measured.\n",
    "# filter them.\n",
    "\n",
    "def locate_wrong_arr(arrays, len_cut = 2):\n",
    "    ind_bad = []\n",
    "    for i, arr in enumerate(arrays):\n",
    "        if isinstance(arr, int): \n",
    "            ind_bad.append(i)\n",
    "        elif len(arr) < len_cut:\n",
    "            ind_bad.append(i)\n",
    "    return ind_bad\n",
    "\n",
    "arr = gal.data['lambda_arr'].copy()\n",
    "i_bad = locate_wrong_arr(arr)\n",
    "\n",
    "#print(\"len Lr_arr\", len(arr))\n",
    "\n",
    "for i_b in i_bad:\n",
    "    # neighbouring array might also be empty. Search for closest valid array.\n",
    "    # left point\n",
    "    i_l = i_b - 1\n",
    "    while(i_l in i_bad):\n",
    "        i_l = i_l - 1\n",
    "    # right point\n",
    "    i_r = i_b + 1\n",
    "    while(i_r in i_bad):\n",
    "        i_r = i_r + 1\n",
    "\n",
    "    arr[i_b] = arr[i_b -1] + arr[i_b +1]\n",
    "\n",
    "#fig, ax = plt.subplots(1)      \n",
    "#for arr in Lr_arr:\n",
    "#    ax.plot(arr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
