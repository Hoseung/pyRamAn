{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "\n",
    "def join_struct_arrays(arrays):\n",
    "    sizes = np.array([a.itemsize for a in arrays])\n",
    "    offsets = np.r_[0, sizes.cumsum()]\n",
    "    n = len(arrays[0])\n",
    "    joint = np.empty((n, offsets[-1]), dtype=np.uint8)\n",
    "    for a, size, offset in zip(arrays, sizes, offsets):\n",
    "        joint[:,offset:offset+size] = a.view(np.uint8).reshape(n,size)\n",
    "    dtype = sum((a.dtype.descr for a in arrays), [])\n",
    "    return joint.ravel().view(dtype)\n",
    "\n",
    "def augment_tree(treedata, base, is_gal=False):\n",
    "    \"\"\"\n",
    "        Add more quantities to existing tree data. \n",
    "        \n",
    "        Consistent tree (built with HM/GM output) does not provide much detail of halos/galaxies.\n",
    "        I need to add some more information from original HM/GM output.\n",
    "    \"\"\"\n",
    "    \n",
    "    dtype_new_quantities = [('np', '<i4'), ('id', '<i4'), ('m', '<f4'), ('mvir', '<f4'),\n",
    "                            ('r', '<f4'), ('rvir', '<f4'), ('tvir', '<f4'), ('cvel', '<f4'),\n",
    "                            ('x', '<f4'), ('y', '<f4'), ('z', '<f4'),\n",
    "                            ('vx', '<f4'), ('vy', '<f4'), ('vz', '<f4'),\n",
    "                            ('ax', '<f4'), ('ay', '<f4'), ('az', '<f4'),\n",
    "                            ('sp', '<f4')]\n",
    "    if is_gal:\n",
    "        [dtype_new_quantities.append(i) for i in [('sig', '<f4'), ('sigbulge', '<f4'), ('mbulge', '<f4')]]\n",
    "           \n",
    "    New_arr = np.zeros(len(treedata), dtype=dtype_new_quantities)\n",
    "    import tree.halomodule as hmo\n",
    "    for nout in np.unique(treedata['nout']):\n",
    "        # nout and Orig_halo_id are required.\n",
    "        gal_org = hmo.Halo(base=wdir, nout=nout, halofinder='HM', load=True, is_gal=is_gal)\n",
    "        # Before we start, remove unnecessary coulmns\n",
    "        dtype_names = [field[0] for field in dtype_new_quantities]\n",
    "        gal_org = gal_org.data[dtype_names]\n",
    "        \n",
    "        ind_tree_this_nout = np.where(treedata['nout'] == nout)[0]\n",
    "        ok_gals = treedata['Orig_halo_id'][ind_tree_this_nout]\n",
    "        \n",
    "        # Galaxies are from a snapshot. Galaxy ID list must be a unique set.\n",
    "        assert len(ok_gals) == len(np.unique(ok_gals))\n",
    "        \n",
    "        ind_org_gals = [np.where(gal_org['id'] == gal)[0] for gal in ok_gals]\n",
    "        \n",
    "        for i, ind in enumerate(ind_org_gals):\n",
    "            assert sum(New_arr[ind_tree_this_nout[i]]) == 0. # array must be empty\n",
    "            New_arr[ind_tree_this_nout[i]] = gal_org[ind]\n",
    " \n",
    "    # Drop duplicate fields\n",
    "    #[\"id\", \"mvir\", \"rvir\", \"x\", \"y\", \"z\", \"vx\", \"vy\", \"vz\"]\n",
    "    keep_fields = [\"np\", \"m\", \"r\", \"tvir\", \"cvel\"]\n",
    "    if is_gal:\n",
    "        [keep_fields.append(i) for i in ['sig', 'sigbulge', 'mbulge']]\n",
    "        \n",
    "    return join_struct_arrays([treedata, New_arr[keep_fields]])\n",
    "\n",
    "\n",
    "def extract_data(halo, rscale=0.25):\n",
    "    xc_tmp0 = halo['x']\n",
    "    yc_tmp0 = halo['y']\n",
    "    zc_tmp0 = halo['z']\n",
    "    \n",
    "    rr_tmp0 = min([halo['rvir'] * rscale, 0.0002]) \n",
    "    # arbitrary! < 20kpc\n",
    "    rr_tmp0 = max([rr_tmp0, 0.000025])\n",
    "    # When merger occurs, larger radius is likely to include \n",
    "    # companion galaxy resulting center to be in the middle of nowhere.\n",
    "    # If you want a larger galaxy, # increase rgal_tmp instead. \n",
    "    #        \n",
    "    # xx is easier to search for than x.\n",
    "\n",
    "    if star_all is not None:\n",
    "        ind_s = np.where((star_all['x'] - xc_tmp0)**2 + (star_all['y'] - yc_tmp0)**2 \n",
    "                        + (star_all['z'] - zc_tmp0)**2 < rr_tmp0**2)[0]\n",
    "    if dm_all is not None:\n",
    "        ind_d = np.where((dm_all['x'] - xc_tmp0)**2 + (dm_all['y'] - yc_tmp0)**2 \n",
    "                        + (dm_all['z'] - zc_tmp0)**2 < rr_tmp0**2)[0]\n",
    "    if cell_all is not None:\n",
    "        ind_c = np.where((cell_all['x'] - xc_tmp0)**2 + (cell_all['y'] - yc_tmp0)**2 \n",
    "                        + (cell_all['z'] - zc_tmp0)**2 < rr_tmp0**2)[0]\n",
    "    else:\n",
    "        return star_all[ind_s], dm_all[ind_d], None\n",
    "        \n",
    "#    print(len(ind_s), len(ind_d), len(ind_c))    \n",
    "\n",
    "    return star_all[ind_s], dm_all[ind_d], cell_all[ind_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def distance_to(xc, xx):\n",
    "    import numpy as np\n",
    "    return np.sqrt([(xc[0] - xx[0])**2 + (xc[1] - xx[1])**2 + (xc[2] - xx[2])**2])[0]\n",
    "\n",
    "def extract_halos_within(halos, i_center, info, dist_in_mpc=1.0):\n",
    "\n",
    "    xc = halos['x'][i_center]\n",
    "    yc = halos['y'][i_center]\n",
    "    zc = halos['z'][i_center]\n",
    "    rvir= halos['rvir'][i_center]\n",
    "\n",
    "    xx = halos['x']\n",
    "    yy = halos['y']\n",
    "    zz = halos['z']\n",
    "\n",
    "    dd = np.multiply(distance_to([xc,yc,zc], [xx,yy,zz]), info.pboxsize)\n",
    "\n",
    "    return (dd < (dist_in_mpc))\n",
    "\n",
    "def all_gals(treedata, final_gals, nout_ini=None, nout_fi=None):\n",
    "    if nout_ini == None:\n",
    "        nout_ini = min(treedata['nout'])\n",
    "    if nout_fi == None:\n",
    "        nout_fi = max(treedata['nout'])\n",
    "    \n",
    "    all_gals_at_nouts = []\n",
    "    for inout, nout in enumerate(range(nout_ini, nout_fi+1)):\n",
    "        all_gals_this_nout = []\n",
    "        tree_now = treedata[np.where(treedata['nout'] == nout)]\n",
    "\n",
    "        for finalgal in final_gals:\n",
    "            i_gals_include = np.where(tree_now['tree_root_id'] == finalgal)[0]\n",
    "            [all_gals_this_nout.append(gal) for gal in tree_now['id'][i_gals_include]]\n",
    "            \n",
    "        all_gals_at_nouts.append(all_gals_this_nout)\n",
    "        \n",
    "    return all_gals_at_nouts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mk_gal(halodata, out_q, info, i, final_gal,\n",
    "           save=False, rscale=0.3, verbose=False, galaxy_plot_dir='./',\n",
    "           rscale_lambda=2.0, npix_lambda=50, npix=400, galaxy_plot=False,\n",
    "           method_com=2, mstar_min=5e9):\n",
    "    \"\"\"\n",
    "    Direct plot,\n",
    "    Create galaxy, \n",
    "    Calculate lambda_r (using Cappellari 2003)\n",
    "    Draw ed map of galaxy.\n",
    "    \n",
    "    \"\"\"\n",
    "    #t = time.time()\n",
    "    #print(i, time.time() - t, \"seconds --- 1\")\n",
    "    \n",
    "#    print(\" !!!!!!!!!!\" )\n",
    "    print(\"This is {}-th halo\".format(i))\n",
    "#    print(\" !!!!!!!!!! \\n\" )\n",
    "    from galaxy import galaxy\n",
    "\n",
    "    #print(\"IDs:\", id(star), id(dm), id(cell))\n",
    "\n",
    "    gal_out = {\"id\":0, \"xc\":0.0, \"yc\":0.0, \"zc\":0.0,\n",
    "               \"vx\":0.0, \"vy\":0.0, \"vz\":0.0,\n",
    "               \"mstar\":0.0, \"nstar\":0.0, \"mgas\":0.0,\n",
    "               \"lambda_arr\":[], \"lambda_r\":0, \"rgal\":0, \"final_gal\":final_gal,\n",
    "               \"rhalo\":halodata['rvir'], \"boxtokpc\":info.pboxsize*1000}\n",
    "               \n",
    "    star, dm, cell = extract_data(h.data[i])\n",
    "\n",
    "    if sum(star['m']) * info.msun < mstar_min:\n",
    "        print(\"(1)Not enough stars: {:.2f} Msun\".format(sum(star['m']) * info.msun))\n",
    "        print(\"Aborting... \\n\")\n",
    "        print(\" Not a good galaxy\")\n",
    "        out_q.put(gal_out)\n",
    "        return\n",
    "               \n",
    "               \n",
    "    # Direct plot ---------------------------------------------------------                                \n",
    "    if galaxy_plot:\n",
    "        import utils.sampling as smp\n",
    "        import draw\n",
    "        import matplotlib.pyplot as plt            \n",
    "        region = smp.set_region(xc=halodata['x'],\n",
    "                            yc=halodata['y'],\n",
    "                            zc=halodata['z'],\n",
    "                            radius = halodata['rvir'])\n",
    "\n",
    "        extent = (0, npix, 0, npix)        \n",
    "        star_map = draw.pp.den2d(star['x'],star['y'],star['z'],star['m'], npix,\n",
    "                                 region=region, cic=True, norm_integer=False)\n",
    "        if star_map is not False:\n",
    "            ls = np.zeros((npix,npix))\n",
    "            ii = star_map > 0\n",
    "            ls[ii] = np.log10(star_map[ii]) # Stellar map HAS empty pixels.\n",
    "            ls[star_map <= 0] = np.floor(ls[ii].min())\n",
    "            plt.imshow(ls, cmap=\"CMRmap\", interpolation='nearest', extent=extent)\n",
    "        \n",
    "        # One of two should be transposed.\n",
    "        # But which one?\n",
    "#        gas_map = draw.pp.pp_cell(cell, npix, info, region=region, verbose=False)\n",
    "#        im2 = plt.imshow(np.transpose(np.log10(gas_map)), cmap=\"CMRmap\", alpha=.5, interpolation='bilinear', extent=extent)\n",
    "    \n",
    "        rgal = region['radius'] * s.info.pboxsize * 1000\n",
    "\n",
    "        ax = plt.gca()\n",
    "        ax.set_xlabel(\"position [kpc]\")\n",
    "        ax.set_xticks(np.linspace(0,npix,5))\n",
    "        xticks = [\"{:.2f}\".format(x) \\\n",
    "                    for x in np.linspace(-rgal, rgal, num=5)]\n",
    "        ax.set_xticklabels(xticks)\n",
    "        ax.set_ylabel(\"position [kpc]\")\n",
    "        ax.set_yticks(np.linspace(0,npix,5))\n",
    "        yticks = [\"{:.2f}\".format(y) \\\n",
    "                    for y in np.linspace(-rgal, rgal, num=5)]\n",
    "        ax.set_yticklabels(yticks)\n",
    "        \n",
    "        plt.savefig(galaxy_plot_dir+\"2dmap_\"+str(halodata['id']).zfill(5)+'.png', dpi=144)\n",
    "        plt.close()\n",
    "\n",
    "    #Create galaxy ----------------------------------------------\n",
    "    gal = galaxy.Galaxy(halodata, radius_method='eff', info=info)\n",
    "    #print(i, time.time() - t, \"seconds ---2\")\n",
    "    good_gal = gal.mk_gal(star, dm, cell,\n",
    "                        mstar_min=mstar_min,\n",
    "               rscale=rscale, verbose=verbose, method_com=method_com)\n",
    "    #print(i, time.time() - t, \"seconds ---3\")               \n",
    "    #-----------------------------------------------------------------------    \n",
    "#    print(gal.id, \"IS_GAL\",is_gal)\n",
    "    if not good_gal:\n",
    "        print(gal.id, \" Not a good galaxy\")\n",
    "        out_q.put(gal_out)\n",
    "    else:\n",
    "        # Save to catalog -------------------------------------------------------\n",
    "#        print(\"Good galaxy, R eff:\", gal.reff)\n",
    "        gal.cal_lambda_r(npix=npix_lambda, method=1, rscale=rscale_lambda) # calculate within 1.0 * reff    \n",
    "        #print(i, time.time() - t, \"seconds ---4\")\n",
    "        # Calculate lambda_r ---------------------------------------------------\n",
    "\n",
    "#        gal.plot_gal(fn_save = galaxy_plot_dir + str(nout).zfill(3) \\\n",
    "#                             + \"_\" + str(final_gal).zfill(5) + \"_\"  \\\n",
    "#                             + str(gal.id) + \".png\", ioff=True)\n",
    "#       gal.save_gal(base=wdir)\n",
    "\n",
    "        # save in a dict.\n",
    "        gal_out['mstar'] = gal.mstar\n",
    "        gal_out['mgas'] = gal.mgas\n",
    "        gal_out['nstar'] = gal.nstar\n",
    "        gal_out['id'] = gal.id\n",
    "        gal_out['xc'] = gal.xc * info.pboxsize\n",
    "        gal_out['yc'] = gal.yc * info.pboxsize\n",
    "        gal_out['zc'] = gal.zc * info.pboxsize\n",
    "        gal_out['vx'] = gal.vxc * info.kms\n",
    "        gal_out['vy'] = gal.vyc * info.kms\n",
    "        gal_out['vz'] = gal.vzc * info.kms        \n",
    "        gal_out['lambda_arr'] = gal.lambda_arr\n",
    "        gal_out['lambda_r'] = gal.lambda_r\n",
    "        gal_out['rgal'] = gal.reff# * info.pboxsize * 1000.0 # in kpc  \n",
    "        out_q.put(gal_out)\n",
    "\n",
    "#    print(\"mk_gal done \\n\")\n",
    "    \n",
    "\n",
    "def plot_lambda(catalog, i_early, i_late, i_bad, fn_out='./'):\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.ioff()\n",
    "    f = plt.figure()\n",
    "    ax = f.add_subplot(111)\n",
    "    #for i, val in enumerate(lambdar_arr):\n",
    "    for i in i_early:\n",
    "        a = np.asarray(catalog['lambda_arr'][i])\n",
    "        ax.plot(a, 'r-', alpha=0.5) # Red = Early\n",
    "    for i in i_late:\n",
    "        ax.plot(catalog['lambda_arr'][i], 'b-', alpha=0.3) # Red = Early\n",
    "    \n",
    "    #plt.xlabel() # in the unit of Reff\n",
    "    ax.set_title(r\"$\\lambda _{R}$\") \n",
    "    ax.set_ylabel(r\"$\\lambda _{R}$\") \n",
    "    ax.set_xlabel(\"[\"+ r'$R/R_{eff}$'+\"]\")\n",
    "    ax.set_xlim(right=9)\n",
    "    ax.set_xticks([0, 4.5, 9])\n",
    "    ax.set_xticklabels([\"0\", \"0.5\", \"1\"])\n",
    "    plt.savefig(fn_out)\n",
    "    plt.close()    \n",
    "    \n",
    "\n",
    "def set_affinity_on_worker():\n",
    "    import os\n",
    "    \"\"\"When a new worker process is created, the affinity is set to all CPUs\"\"\"\n",
    "    print(\"I'm the process %d, setting affinity to all CPUs.\" % os.getpid())\n",
    "    os.system(\"taskset -p 0xff %d\" % os.getpid())    \n",
    "    \n",
    "    \n",
    "\n",
    "def worker(halodata, out_q, info, inds, final_gal, **kwargs):        \n",
    "    worker_q = Queue()\n",
    "    if type(inds) == int:\n",
    "        inds = [inds]\n",
    "    for i in inds:\n",
    "        mk_gal(h.data[i], worker_q, s.info, i, final_gal[i], **kwargs)\n",
    "    for i in inds:\n",
    "        out_q.put(worker_q.get())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How many cores? \n",
      "2\n",
      "First snapshot: (default = 37 , z=3) \n",
      "\n",
      "Last snapshot: (default = 187, z=0) \n",
      "\n",
      "Loaded an extended tree\n"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "\n",
    "\"\"\"\n",
    "The processing pool needs to be instantiated in the main \n",
    "thread of execution. \n",
    "\"\"\"\n",
    "import multiprocessing as mp    \n",
    "import load\n",
    "from tree import tmtree, treemodule\n",
    "import tree.ctutils as ctu\n",
    "import utils.sampling as smp\n",
    "import tree.halomodule as hmo \n",
    "from utils import match\n",
    "import os\n",
    "multi = True # \n",
    "hydro = False\n",
    "is_gal = True\n",
    "\n",
    "#wdir = input(\"Working directory \\n\")\n",
    "#wdir = './'\n",
    "wdir = '/home/hoseung/Work/data/05427/'\n",
    "#ncore = 16\n",
    "if multi: ncore = int(input(\"How many cores? \\n\"))\n",
    "nout_ini = input(\"First snapshot: (default = 37 , z=3) \\n\")\n",
    "nout_end = input(\"Last snapshot: (default = 187, z=0) \\n\")\n",
    "#ncore=1\n",
    "#nout_ini=186\n",
    "#nout_end=186\n",
    "#----------------------------------------------------------------------\n",
    "# 27 : z=4;  37 : z=3;  20 : ~ z=5\n",
    "\n",
    "if nout_ini == \"\":\n",
    "    nout_ini = 37\n",
    "else:\n",
    "    nout_ini = int(nout_ini)\n",
    "\n",
    "if nout_end == \"\":\n",
    "    nout_end = 187\n",
    "else:\n",
    "    nout_end = int(nout_end)\n",
    "\n",
    "nout_ini0 = 37\n",
    "nout_fi = 187\n",
    "nouts = range(nout_fi, nout_ini -1, -1) \n",
    "#----------------------------------------------------------------------\n",
    "mstar_min = 5e9\n",
    "# Only galaxies above this stellar mass at the final snapshot are considered.\n",
    "mstar_min_plot = 5e9\n",
    "mk_gal_rscale = 2.0 # unit of Rvir,galaxy\n",
    "rscale = 1.5\n",
    "r_cluster_scale = 2.0 # maximum radius inside which galaxies are searched for\n",
    "npix=800\n",
    "rscale_lambda = 2.0 # Reff unit.\n",
    "npix_lambda = int(10 * rscale_lambda)\n",
    "lmax = 19\n",
    "ptypes=[\"star id pos mass vel time metal\", \"dm id pos mass vel\"]\n",
    "\n",
    "## halo part -----------------------------------------------------------\n",
    "m_halo_min = 5e9 # minimum galaxy mass above which galaxies are searched for. \n",
    "dir_out = wdir + 'catalog_GM/'\n",
    "\n",
    "# optional parameters ----------------------------------------------------\n",
    "lambda_plot = False \n",
    "\n",
    "# Load complete tree -----------------------------------------------------\n",
    "\n",
    "if is_gal:\n",
    "    # Galaxy tree\n",
    "    tree_path = 'GalaxyMaker/Trees/'\n",
    "else:\n",
    "    # halo tree\n",
    "    tree_path = 'halo/Trees/'\n",
    "    \n",
    "try:\n",
    "    alltrees = pickle.load(open(wdir + tree_path + \"extended_tree.pickle\", \"rb\" ))\n",
    "    print(\"Loaded an extended tree\")\n",
    "except:\n",
    "    alltrees = treemodule.CTree()\n",
    "    alltrees.load(filename= wdir + tree_path + 'tree_0_0_0.dat')\n",
    "    # Fix nout -----------------------------------------------------\n",
    "    nout_max = alltrees.data['nout'].max()\n",
    "    alltrees.data['nout'] += nout_fi - nout_max\n",
    "    print(\"------ NOUT fixed\")\n",
    "    alltrees.data = augment_tree(alltrees.data, wdir, is_gal=is_gal)\n",
    "    print(\"------ tree data extended\")\n",
    "\n",
    "tt = alltrees.data\n",
    "tt_final = tt[tt['nout'] == nout_fi]\n",
    "\n",
    "info = load.info.Info(nout=nout_fi, base=wdir, load=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 475 galaxies \n",
      "354 galaxies are selected\n",
      "70 halos left\n"
     ]
    }
   ],
   "source": [
    "# list of all galaxt targets from nout_ini to nout_fi\n",
    "# This is the sum of all galaxies of tree of each final galaxy.\n",
    "if nout_end == nout_fi:\n",
    "    hh = hmo.Halo(base=wdir, nout=nout_fi, halofinder='HM', info=info, load=True, is_gal=is_gal)\n",
    "    i_center = np.where(hh.data['np'] == max(hh.data['np']))\n",
    "    i_satellites = extract_halos_within(hh.data, i_center, info, dist_in_mpc = 2.0)\n",
    "    print(\"Total {0} galaxies \\n{1} galaxies are selected\".format(\n",
    "          len(i_satellites),sum(i_satellites)))\n",
    "    \n",
    "    # halos found inside the cluster and have complete tree back to nout_ini\n",
    "    large_enugh = hh.data['mvir'] > m_halo_min\n",
    "    halo_list = hh.data['id'][i_satellites * large_enugh]\n",
    "    final_ids = ctu.check_tree_complete(tt, nout_ini0, nout_fi, halo_list, idx=False)\n",
    "\n",
    "    final_gals_idx = []\n",
    "    for final_gal in final_ids:\n",
    "        i = np.where(tt_final['Orig_halo_id'] == final_gal)[0]\n",
    "        if len(i) > 0:\n",
    "            final_gals_idx.append(tt_final['id'][i][0])\n",
    "    \n",
    "    print(len(final_gals_idx), \"halos left\")\n",
    "    ngals = len(final_gals_idx)\n",
    "\n",
    "# Search for all galaxies that listed in the trees of final_gals\n",
    "all_gals_in_trees = all_gals(tt, final_gals_idx)\n",
    "\n",
    "# Save it\n",
    "pickle.dump(all_gals_in_trees, open( wdir + \"all_gals_in_trees.pickle\", \"wb\" ))\n",
    "with open(wdir + 'lambda_mp_status.txt', 'w') as f:\n",
    "    f.write(\"mstar_min = \" + str(mstar_min) + \"\\n\")\n",
    "    f.write(\"ptypes : \\n\")\n",
    "    for i in ptypes:\n",
    "        f.write(\"  \" + str(i) + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 187 187\n",
      "Mstar min: 5000000000.0\n",
      "halo_ok [1, 2, 4, 5, 7, 9, 12, 13, 14, 15, 18, 19, 20, 22, 23, 26, 31, 32, 33, 34, 35, 36, 37, 40, 43, 44, 45, 48, 49, 53, 54, 56, 61, 63, 66, 68, 76, 84, 86, 87, 89, 90, 91, 92, 97, 98, 100, 111, 112, 115, 119, 133, 145, 163, 171, 238, 363, 364, 369, 371, 376, 378, 379, 386, 390, 393, 409, 411, 415, 417]\n",
      "Final target halos: [  1   2   4   5   7   9  12  13  14  15  18  19  20  22  23  26  31  32\n",
      "  33  34  35  36  37  40  43  44  45  48  49  53  54  56  61  63  66  68\n",
      "  76  84  86  87  89  90  91  92  97  98 100 111 112 115 119 133 145 163\n",
      " 171 238 363 364 369 371 376 378 379 386 390 393 409 411 415 417] 70\n",
      "Ranges = [[0.0, 1.0], [0.0, 1.0], [0.0, 1.0]]\n",
      "\n",
      "No AMR instance,\n",
      "Loading one...\n",
      "An AMR instance is created\n",
      "\n",
      "Updating info.cpus\n",
      "An AMR instance is created\n",
      "\n",
      "Updating info.cpus\n",
      " Simulation set up.\n",
      "Types of particles you want to load are:  ['star id pos mass vel time metal', 'dm id pos mass vel']\n",
      "No AMR instance,\n",
      "Loading one...\n",
      "An AMR instance is created\n",
      "\n",
      "Updating info.cpus\n",
      "No info._set_cpus attribute??\n",
      "A particle instance is created\n",
      "\n",
      "Loading by fortran module\n",
      "Fortran-reading done\n",
      "Looking for galaxies inside 70 halos\n",
      "[[0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26, 28, 30, 32, 34, 36, 38, 40, 42, 44, 46, 48, 50, 52, 54, 56, 58, 60, 62, 64, 66, 68, 70, 72, 74, 76], [1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29, 31, 33, 35, 37, 39, 41, 43, 45, 47, 49, 51, 53, 55, 57, 59, 61, 63, 65, 67, 69, 71, 73, 75, 77]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-4:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.4/threading.py\", line 920, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/usr/local/lib/python3.4/dist-packages/zmq/utils/garbage.py\", line 37, in run\n",
      "    s.bind(self.gc.url)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 444, in zmq.backend.cython.socket.Socket.bind (zmq/backend/cython/socket.c:4092)\n",
      "  File \"zmq/backend/cython/checkrc.pxd\", line 21, in zmq.backend.cython.checkrc._check_rc (zmq/backend/cython/socket.c:6251)\n",
      "zmq.error.ZMQError: Address already in use\n",
      "Exception in thread Thread-4:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.4/threading.py\", line 920, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/usr/local/lib/python3.4/dist-packages/zmq/utils/garbage.py\", line 37, in run\n",
      "    s.bind(self.gc.url)\n",
      "  File \"zmq/backend/cython/socket.pyx\", line 444, in zmq.backend.cython.socket.Socket.bind (zmq/backend/cython/socket.c:4092)\n",
      "  File \"zmq/backend/cython/checkrc.pxd\", line 21, in zmq.backend.cython.checkrc._check_rc (zmq/backend/cython/socket.c:6251)\n",
      "zmq.error.ZMQError: Address already in use\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-81-4ddc4a053004>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     84\u001b[0m         \u001b[1;31m# Exit the completed processes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mprocesses\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 86\u001b[1;33m             \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmulti\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib/python3.4/multiprocessing/process.py\u001b[0m in \u001b[0;36mjoin\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    119\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parent_pid\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetpid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'can only join a child process'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_popen\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'can only join a started process'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 121\u001b[1;33m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_popen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    122\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m             \u001b[0m_children\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdiscard\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib/python3.4/multiprocessing/popen_fork.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m     52\u001b[0m                     \u001b[1;32mreturn\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m             \u001b[1;31m# This shouldn't block if wait() returned successfully.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mWNOHANG\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0.0\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     55\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib/python3.4/multiprocessing/popen_fork.py\u001b[0m in \u001b[0;36mpoll\u001b[1;34m(self, flag)\u001b[0m\n\u001b[0;32m     28\u001b[0m             \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m                     \u001b[0mpid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwaitpid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrno\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0merrno\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEINTR\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from queue import Queue\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "    \n",
    "for inout, nout in enumerate(nouts):\n",
    "    print(inout, nout, nout_end)\n",
    "    print(\"Mstar min:\", mstar_min, )\n",
    "    if nout > nout_end:\n",
    "        mstar_min = 0\n",
    "        continue\n",
    "\n",
    "    # If nout != 187, load all galaxy list from \n",
    "    if (nout == nout_end) and (nout < nout_fi):\n",
    "        with open(wdir + 'all_gals_in_trees.pickle', 'rb') as f:\n",
    "            all_gals_in_trees = f.load()\n",
    "        #from astropy.io import ascii\n",
    "        #data = ascii.read(dir_out + 'galaxies187.txt')\n",
    "        #halo_list = data['final_ID']\n",
    "        #mstar_min = 0\n",
    "    \n",
    "        # hlao_ok = complete-tree halos at all nouts.\n",
    "        #h_ind_ok, halo_ok = ctu.check_tree_complete(tt, 0, nout_fi - nout_ini0, halo_list)\n",
    "        \n",
    "        #print(len(halo_ok), \"halos left\")\n",
    "        final_gals_idx = all_gals_in_trees[-1]\n",
    "        ngals = len(final_gals_idx)\n",
    "\n",
    "\n",
    "    snout = str(nout)\n",
    "    fcat = dir_out +\"catalog\" + snout + \".pickle\"    \n",
    "    galaxy_plot_dir = wdir + 'galaxy_plot' + snout + '/'\n",
    "    if not os.path.isdir(galaxy_plot_dir):\n",
    "        os.mkdir(galaxy_plot_dir)\n",
    "\n",
    "    info = load.info.Info(nout=nout, base=wdir, load=True)\n",
    "    \n",
    "    halo_ok = ctu.idxs_to_ids(tt, all_gals_in_trees[inout])\n",
    "    print(\"halo_ok\", halo_ok)\n",
    "    # Load all halo\n",
    "    # Do I really need halo bricks?\n",
    "    hh = hmo.Halo(base=wdir, nout=nout, halofinder='HM', info=info, load=True, is_gal=is_gal)\n",
    "    hind = match.match_list_ind(hh.data['id'], halo_ok)\n",
    "    h = hmo.Halo(base=wdir, nout=nout, halofinder='HM', info=info, is_gal=is_gal)\n",
    "    h.derive_from(hh, hind)\n",
    "    print(\"Final target halos:\", h.data['id'], len(h.data['id']))\n",
    "\n",
    "    s = load.sim.Sim(nout=nout, base=wdir, setup=True)#,ranges=[[0.4,0.5],[0.4,0.5],[0.4,0.5]])\n",
    "    s.add_part(ptypes, load=True, fortran=True)\n",
    "    #assert s.part.nstar > 0, \"Not enough stellar particles in given cpus\"\n",
    "    if hydro:\n",
    "        s.add_hydro(load=True, lmax=lmax)\n",
    "        cell_all = s.hydro.cell\n",
    "    else:\n",
    "        cell_all = None\n",
    "\n",
    "    star_all = s.part.star\n",
    "    dm_all = s.part.dm\n",
    "    \n",
    "\n",
    "    nh = len(h.data)\n",
    "    keywords = dict(galaxy_plot_dir=galaxy_plot_dir,\n",
    "                rscale = mk_gal_rscale,\n",
    "                verbose=False, rscale_lambda=rscale_lambda,\n",
    "                npix_lambda=npix_lambda, galaxy_plot = False,\n",
    "                mstar_min=mstar_min)\n",
    "\n",
    "    if multi == 1:\n",
    "#   Multiprocessing -----------------------------------------------------------\n",
    "        m = mp.Manager()\n",
    "        out_q = m.Queue()\n",
    "        print(\"Looking for galaxies inside {} halos\".format(nh))\n",
    "        inds=[]\n",
    "        [inds.append([]) for i in range(ncore)]\n",
    "        \n",
    "        for i in range(ngals):\n",
    "            j = i % ncore\n",
    "            inds[j].append(i)\n",
    "\n",
    "        print(inds)\n",
    "        processes = [mp.Process(target=worker, args=(h.data, out_q,\n",
    "                    s.info, inds[i], final_gals_idx), kwargs=keywords) for i in range(ncore)]\n",
    "\n",
    "        # Run processes\n",
    "        for p in processes:\n",
    "            p.start()\n",
    "        \n",
    "        # Exit the completed processes\n",
    "        for p in processes:\n",
    "            p.join()\n",
    "            \n",
    "    elif multi == 2:\n",
    "        m = mp.Manager()\n",
    "        out_q = m.Queue()\n",
    "        print(\"Looking for galaxies inside {} halos\".format(nh))\n",
    "        \n",
    "        pool = mp.Pool(processes=ncore)\n",
    "        for i in range(nh):\n",
    "            pool.apply_async(mk_gal, args=(h.data[i], out_q,\n",
    "                              s.info, i, final_gals_idx[i]), kwds=keywords)\n",
    "        pool.close()\n",
    "        pool.join()\n",
    "    else:\n",
    "        for i in range(nh):\n",
    "            out_q = Queue()\n",
    "            mk_gal(h.data[i], out_q, s.info, i, final_gals_idx[i], **keywords)\n",
    "    \n",
    "    print(\"----------Done---------\")\n",
    "    \n",
    "    dictout=[]\n",
    "    try:\n",
    "        if not os.path.isdir(dir_out):\n",
    "            os.mkdir(dir_out)\n",
    "        f = open(dir_out + 'galaxies' + snout + '.txt', 'w')\n",
    "    except:\n",
    "        print(\"No filename is given.\\n \")\n",
    "    \n",
    "    f.write(\" nout    ID        x          y       z[Mpc]       vx      vy     vz[km/s]\")\n",
    "    f.write(\"    Reff[kpc]     Mstar    Mgas[Msun]  Rhalo[kpc]  boxtokpc  final_ID \\n\")    \n",
    "    \n",
    "    for i in range(nh):\n",
    "        try:\n",
    "            tmp =  out_q.get(timeout=0.1)\n",
    "#            print(tmp)\n",
    "            if tmp['id'] == 0:\n",
    "                continue\n",
    "            dd = tmp\n",
    "            f.write(\"{:<4}   {:<4}   {:.5f}  {:.5f}  {:.5f}\".format(nout,\n",
    "                    dd['id'],dd['xc'],dd['yc'],dd['zc']))\n",
    "            f.write(\"  {:.3f}  {:.3f}  {:.3f}\".format(dd['vx'],dd['vy'],dd['vz']))\n",
    "            f.write(\"  {:.6f}  {:.0f}  {:.0f}\".format(dd['rgal'],dd['mstar'], dd['mgas']))\n",
    "            f.write(\"  {:.5f}  {:.5f}  {:<4}   \\n\".format(dd['rhalo'],dd['boxtokpc'],dd['final_gal']))\n",
    "            dictout.append(dd)\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    f.close()    \n",
    "    print(\"Text file written\")\n",
    "\n",
    "    catalog = pd.DataFrame(dictout).to_records()    \n",
    "\n",
    "    with open(fcat, 'wb') as f:\n",
    "        pickle.dump(catalog, f)\n",
    "        \n",
    "    star_all = 0\n",
    "    dm_all = 0\n",
    "    cell_all = 0\n",
    "    s = 0\n",
    "    # minimum stellar mass check only for the final snapshot galaxies,\n",
    "    # No more mstar_min test.\n",
    "    print(\"------------------\")\n",
    "    #print(\"main loop took \", time.time() - t0, \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9, 12, 21, 32, 50, 80, 100, 125, 153, 174, 196, 215, 246, 270, 292, 303, 320, 340, 366, 381, 391, 398, 407, 421, 428, 438, 438, 448, 444, 447, 444, 442, 438, 440, 445, 450, 449, 446, 438, 440, 435, 432, 426, 422, 419, 412, 401, 400, 386, 383, 377, 368, 360, 364, 359, 358, 352, 347, 340, 336, 334, 326, 315, 316, 314, 313, 309, 309, 306, 302, 293, 289, 286, 281, 276, 274, 271, 264, 256, 250, 249, 249, 245, 243, 240, 230, 229, 225, 222, 220, 215, 213, 210, 207, 205, 204, 201, 198, 195, 193, 190, 188, 185, 183, 182, 179, 180, 179, 177, 176, 175, 172, 171, 168, 164, 161, 159, 158, 158, 156, 154, 155, 154, 152, 150, 150, 149, 146, 145, 145, 144, 143, 139, 138, 136, 135, 132, 130, 128, 128, 128, 127, 124, 120, 118, 117, 114, 113, 112, 109, 107, 106, 104, 103, 102, 102, 101, 99, 95, 94, 92, 92, 91, 91, 90, 88, 84, 84, 84, 83, 81, 79, 77, 75, 73, 72, 70]\n"
     ]
    }
   ],
   "source": [
    "ll = [len(i) for i in all_gals_in_trees]\n",
    "print(ll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
