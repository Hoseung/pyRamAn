{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import load\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "matplotlib.use(\"Qt5Agg\")\n",
    "import matplotlib.pyplot as plt\n",
    "import tree\n",
    "#import makegal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/hoseung/Work/pyclusterevol/repo/'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from general import defaults\n",
    "#from galaxymodule import quick_mock\n",
    "dfl = defaults.Default()\n",
    "dfl.dir_repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from galaxymodule import make_gal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/hoseung/btrfs/Horizon-AGN\n"
     ]
    }
   ],
   "source": [
    "cd ~/Work/data/Horizon-AGN/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/hoseung/Work/data/NH\n"
     ]
    }
   ],
   "source": [
    "cd ~/Work/data/NH/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[sim._hilbert_cpulist] No AMR instance,\n",
      "[sim._hilbert_cpulist] Loading one...\n",
      "An AMR instance is created\n",
      " Sim\n",
      "An AMR instance is created\n",
      " Sim\n",
      "Simulation set up.\n",
      "[Halo.load_info] loading info\n",
      "[Halo.load_info] nout = 782, base =./\n"
     ]
    }
   ],
   "source": [
    "nout = 782#312#782 # 312\n",
    "s = load.sim.Sim(nout=nout)\n",
    "gcat = tree.halomodule.Halo(nout=nout, is_gal=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "info <load.info.Info object at 0x7fa1b36d56d8>\n",
      "File Not Found: ./halo/HAL_00782/hal_dms_0000105\n",
      "No DM data loaded\n",
      "File Not Found: ./GalaxyMaker/CELL_00782/gal_cells_0000105\n",
      "No CELL data loaded\n",
      "catalog center -44.2949333190918 51.372005462646484 23.004234313964844\n",
      "star x [-44.26342773 -44.33200455 -44.30377579 ..., -44.29323578 -44.29428864\n",
      " -44.29762268]\n",
      "star x [ 31.50558472 -37.07122803  -8.84246826 ...,   1.69754028   0.64468384\n",
      "  -2.68936157]\n",
      "gal.debug False\n",
      "11.8439622296\n"
     ]
    }
   ],
   "source": [
    "#gg = load.rd_GM.Gal(nout, catalog=gcat.data[21].copy(), info=s.info)\n",
    "gg = load.rd_GM.Gal(nout, catalog=gcat.data[104].copy(), info=s.info)\n",
    "gg.debug=False\n",
    "make_gal.mk_gal(gg)\n",
    "print(np.log10(gg.meta.mstar))\n",
    "#gg1.cal_norm_vec()\n",
    "#gg1.meta.nvec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "arr = np.arange(4)\n",
    "mat = np.random.rand(4,3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.83086452,  0.23718903,  0.32862803],\n",
       "       [ 0.2366768 ,  0.33746605,  0.75426078],\n",
       "       [ 0.1154754 ,  0.3073384 ,  0.19447749],\n",
       "       [ 0.74724667,  0.62018871,  0.83527797]])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.70936759,  2.81270899,  3.64904966])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.tensordot(mat.T, arr, axes=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.2366768 ,  0.23095079,  2.24174   ],\n",
       "       [ 0.        ,  0.33746605,  0.6146768 ,  1.86056613],\n",
       "       [ 0.        ,  0.75426078,  0.38895498,  2.5058339 ]])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.multiply(mat.T, arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tonumpyarray(mp_arr):\n",
    "    return np.frombuffer(mp_arr.get_obj())\n",
    "\n",
    "from multiprocessing import Process, Value, Array\n",
    "import numpy as np\n",
    "class Simplemock():\n",
    "    def __init__(self, repo=\"/home/hoseung/Work/pyclusterevol/repo/sed/\",\n",
    "                 filter_system=\"SDSS\",\n",
    "                 sed_model=\"bc03\",\n",
    "                 load=True, \n",
    "                 parallel=True):\n",
    "        self.filter_system = filter_system\n",
    "        self.repo = repo\n",
    "        self.sed_model = sed_model\n",
    "        self.parallel = parallel\n",
    "        if load:\n",
    "            self.load_all()\n",
    "            \n",
    "    def load_all(self):\n",
    "        self.load_filters()\n",
    "        self.load_SED_wavelength()\n",
    "        return self.load_SED_all()\n",
    "\n",
    "    def load_filters(self):\n",
    "        if self.filter_system == \"SDSS\":\n",
    "            filter_lambda, filter_u, filter_g, filter_r, filter_i, filter_z = \\\n",
    "                np.genfromtxt(self.repo + \"filter_sdss.dat\",\n",
    "                                skip_header=1, unpack=True)\n",
    "\n",
    "            self.filters = {\"lambda\":filter_lambda,\n",
    "                            \"u\":filter_u,\n",
    "                            \"g\":filter_g,\n",
    "                            \"r\":filter_r,\n",
    "                            \"i\":filter_i,\n",
    "                            \"z\":filter_z}\n",
    "\n",
    "    def load_SED_wavelength(self):\n",
    "        if self.sed_model == \"bc03\":\n",
    "            self.sed_wavelength = np.genfromtxt(self.repo + \"lambda.dat\")\n",
    "\n",
    "    def load_SED_all(self):\n",
    "        \"\"\"\n",
    "        Full SEDs are just a few tens of MB.\n",
    "        \"\"\"\n",
    "        if self.sed_model == \"bc03\":\n",
    "            self.metal_points = np.array([0.0004, 0.001, 0.004, 0.01, 0.02, 0.04])\n",
    "            # age points in tables.\n",
    "            self.age_points = np.genfromtxt(self.repo+\"ages_yybc.dat\") # in Gry unit\n",
    "            \n",
    "            \n",
    "            if self.parallel:\n",
    "                SED_shared=Array('d', np.zeros(6*221*1221))\n",
    "                self.SEDs = tonumpyarray(SED_shared).reshape(6,221,1221)\n",
    "                print(self.SEDs.shape)\n",
    "            else:\n",
    "                self.SEDs = np.zeros((6, 221, 1221))\n",
    "                \n",
    "            \n",
    "            for i, metal in enumerate(self.metal_points):\n",
    "                #self.SEDs[i,:,:] = np.genfromtxt(self.repo +\n",
    "                self.SEDs[i,:,:] = np.genfromtxt(self.repo +\n",
    "                                            \"bc03_yy_{:.4f}\".format(metal)).reshape(221, 1221)\n",
    "\n",
    "            if self.parallel:\n",
    "                return SED_shared\n",
    "            #else:\n",
    "            #    return SEDs\n",
    "        else:\n",
    "            print(\"Sorry, Only bc03 is implemented.\")\n",
    "\n",
    "def get_flux(extinction = False,\n",
    "             metal_lower_cut = False,\n",
    "             filter_name='r'):\n",
    "    #import gc\n",
    "    #import os\n",
    "    ### star data ########################################################\n",
    "    global star\n",
    "    global SEDs\n",
    "    \n",
    "    #print(\"PID \",os.getpid(), \"reference counter\", len(gc.get_referrers(star)))\n",
    "    \n",
    "    starmetal = star[\"metal\"] # Is the original array modified?\n",
    "    if metal_lower_cut:\n",
    "        # No star with metallicity lower than the lowest table.\n",
    "        # Modifying array will result in meory copy!!\n",
    "        starmetal[starmetal < min(self.metal_points)] = min(self.metal_points) * 1.0001\n",
    "\n",
    "    locate_metal = np.digitize(starmetal, self.metal_points)-1 # GOOD\n",
    "    relevant_metals = self.metal_points[:max(locate_metal)+2]\n",
    "    nmetals = len(relevant_metals)\n",
    "\n",
    "    # Star Age\n",
    "    t_univ = 13.7\n",
    "    starage = t_univ - star[\"time\"]\n",
    "\n",
    "    locate_age = np.digitize(starage, self.age_points)-1 # GOOD\n",
    "    relevant_ages = self.age_points[:max(locate_age)+2]\n",
    "    nages = len(relevant_ages)\n",
    "\n",
    "    ### Filter optimization. #################################################\n",
    "\n",
    "    # Pick one\n",
    "    this_filter = self.filters[filter_name]\n",
    "\n",
    "    # band range\n",
    "    i_filter_pos = this_filter > 0\n",
    "\n",
    "    this_filter = this_filter[i_filter_pos]\n",
    "    filter_lambda_this_band = self.filters[\"lambda\"][i_filter_pos]\n",
    "\n",
    "    lambda_min_this_band = min(filter_lambda_this_band)\n",
    "    lambda_max_this_band = max(filter_lambda_this_band)\n",
    "\n",
    "    i_lambda_min = np.argmax(self.sed_wavelength > lambda_min_this_band) -1\n",
    "    #print(i_lambda_min, wavelength[i_lambda_min], lambda_min_this_band)\n",
    "    i_lambda_max = np.argmax(self.sed_wavelength > lambda_max_this_band)\n",
    "    #print(i_lambda_max, wavelength[i_lambda_max], lambda_max_this_band)\n",
    "\n",
    "    # Only a small part of SED is needed.\n",
    "    wavelength = self.sed_wavelength[i_lambda_min:i_lambda_max+1]\n",
    "    n_wavelength = i_lambda_max - i_lambda_min + 1\n",
    "\n",
    "    ##### Caclulate band flux #################\n",
    "    # Load only necessary data\n",
    "    # Load all once, keep under the class and copy part of it when needed heere.\n",
    "    seds = np.zeros((nmetals, nages, n_wavelength)) # metal age lambda\n",
    "    nages_org =221\n",
    "    nmetal_org=6\n",
    "    n_wavs_org=1221\n",
    "    if self.sed_model == \"bc03\":\n",
    "        for i, metal in enumerate(relevant_metals):\n",
    "            for j, age in enumerate(relevant_ages):\n",
    "                seds[i,j,:] = SEDs[ i * nages_org*n_wavs_org\n",
    "                                  + j * n_wavs_org + i_lambda_min:\n",
    "                                    i * nages_org*n_wavs_org\n",
    "                                  + j * n_wavs_org + i_lambda_max+1]\n",
    "\n",
    "    # All are array-wise calculations.\n",
    "    # interpolation weight\n",
    "    dmda = np.sqrt((relevant_metals[locate_metal+1] - relevant_metals[locate_metal]) * (relevant_ages[locate_age+1] - relevant_ages[locate_age]))\n",
    "    dl_m = (starmetal - relevant_metals[locate_metal] )# / \\\n",
    "           #(relevant_metals[locate_metal+1] - relevant_metals[locate_metal])\n",
    "    dr_m = (relevant_metals[locate_metal+1] - starmetal)# / \\\n",
    "           #(relevant_metals[locate_metal+1] - relevant_metals[locate_metal])\n",
    "    dl_a = (starage - relevant_ages[locate_age] )#   / \\\n",
    "           #(relevant_ages[locate_age+1] - relevant_ages[locate_age])\n",
    "    dr_a = (relevant_ages[locate_age+1] - starage )# / \\\n",
    "           #(relevant_ages[locate_age+1] - relevant_ages[locate_age])\n",
    "\n",
    "    # 2D linear interpolation\n",
    "    # weight * SED.\n",
    "    print(dmda.shape)\n",
    "    if True:\n",
    "        Flux = np.multiply(1/dmda,\n",
    "            np.multiply( (dr_m * dr_a), seds[locate_metal, locate_age,:].T) +\\\n",
    "            np.multiply( (dl_m * dr_a), seds[locate_metal + 1, locate_age,:].T) +\\\n",
    "            np.multiply( (dr_m * dl_a), seds[locate_metal, locate_age + 1, :].T) +\\\n",
    "            np.multiply( (dl_m * dl_a), seds[locate_metal + 1, locate_age + 1,:].T))\n",
    "        #print(Flux.shape)\n",
    "    else:\n",
    "        Flux = (np.multiply(seds[locate_metal, locate_age,:], (dr_m * dr_a)) +\\\n",
    "               np.multiply(seds[locate_metal + 1, locate_age,:], (dl_m * dr_a)) +\\\n",
    "               np.multiply(seds[locate_metal, locate_age + 1, :], (dr_m * dl_a)) +\\\n",
    "               np.multiply(seds[locate_metal + 1, locate_age + 1,:], (dl_m * dl_a)))/dmda\n",
    "        #print(Flux.shape)\n",
    "\n",
    "    # Convolve filter\n",
    "    # Wavelengths at which filter function are defined are different from the SED wavelength points.\n",
    "    # Interpolate filter function on SED points.\n",
    "    filter_in_sed_wavelengths = np.interp(wavelength, filter_lambda_this_band, this_filter)\n",
    "    Flux = np.multiply(filter_in_sed_wavelengths, Flux)\n",
    "    \n",
    "    if not extinction:\n",
    "        return np.sum(Flux, axis=1)\n",
    "    else:\n",
    "        print(\"Extinction - Not yet implemented\")\n",
    "        return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 221, 1221)\n"
     ]
    }
   ],
   "source": [
    "SED_shared=Array('d', np.zeros((6*221*1221)))#, lock=False)\n",
    "SEDs = tonumpyarray(SED_shared).reshape(6,221,1221)\n",
    "print(SEDs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 221, 1221)\n"
     ]
    }
   ],
   "source": [
    "MockSED = Simplemock(repo=dfl.dir_repo+'sed/', load=False)\n",
    "SEDs = MockSED.load_all()\n",
    "global self\n",
    "global SEDs\n",
    "#SEDs = MockSED.SEDs.copy()\n",
    "MockSED.SEDs=0\n",
    "self = MockSED#.SEDs\n",
    "global star\n",
    "star = gg.star\n",
    "#gg.star[\"metal\"][gg.star[\"metal\"] >= 0.04] = 0.04 - 1e-9\n",
    "## Improve Boundary cases. !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even everything to be shared are global, \n",
    "having a subprocess referencing to the original memory modifies the original memory.\n",
    "That's because Python needs to count references to a memory so that it can clean up the memory when no other objects are referencing the memory. \n",
    "That means, just having one more subprocess means another copy of memory. \n",
    "\n",
    "A great article on this problem. \n",
    "https://llvllatrix.wordpress.com/2016/02/19/python-vs-copy-on-write/\n",
    "\n",
    "\n",
    "#### The core of our solution is to tell the operating system that it should be using shared memory that isnâ€™t reference counted. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hoseung/Work/hspy/lib/python3.5/site-packages/ipykernel_launcher.py:139: RuntimeWarning: invalid value encountered in sqrt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200516,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hoseung/Work/hspy/lib/python3.5/site-packages/ipykernel_launcher.py:139: RuntimeWarning: invalid value encountered in sqrt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200516,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hoseung/Work/hspy/lib/python3.5/site-packages/ipykernel_launcher.py:139: RuntimeWarning: invalid value encountered in sqrt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200516,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hoseung/Work/hspy/lib/python3.5/site-packages/ipykernel_launcher.py:139: RuntimeWarning: invalid value encountered in sqrt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200516,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hoseung/Work/hspy/lib/python3.5/site-packages/ipykernel_launcher.py:139: RuntimeWarning: invalid value encountered in sqrt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200516,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-141:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-118-25afadb03634>\", line 167, in get_flux\n",
      "    Flux = np.multiply(filter_in_sed_wavelengths, Flux)\n",
      "ValueError: operands could not be broadcast together with shapes (58,) (58,200516) \n",
      "Process Process-143:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-118-25afadb03634>\", line 167, in get_flux\n",
      "    Flux = np.multiply(filter_in_sed_wavelengths, Flux)\n",
      "ValueError: operands could not be broadcast together with shapes (92,) (92,200516) \n",
      "Process Process-142:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-118-25afadb03634>\", line 167, in get_flux\n",
      "    Flux = np.multiply(filter_in_sed_wavelengths, Flux)\n",
      "ValueError: operands could not be broadcast together with shapes (109,) (109,200516) \n",
      "Process Process-144:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-118-25afadb03634>\", line 167, in get_flux\n",
      "    Flux = np.multiply(filter_in_sed_wavelengths, Flux)\n",
      "ValueError: operands could not be broadcast together with shapes (109,) (109,200516) \n",
      "Process Process-145:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-118-25afadb03634>\", line 167, in get_flux\n",
      "    Flux = np.multiply(filter_in_sed_wavelengths, Flux)\n",
      "ValueError: operands could not be broadcast together with shapes (137,) (137,200516) \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8866689205169678\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing as mp\n",
    "import gc\n",
    "\n",
    "mp.set_start_method('fork', force=True)\n",
    "\n",
    "Ps = []\n",
    "# args must be a tuple. (something,) note the trailing comma.\n",
    "#Ps.append(mp.Process(target = get_flux, kwargs={\"filter_name\":'u'}))\n",
    "#Ps.append(mp.Process(target = get_flux, kwargs={\"filter_name\":'g'}))\n",
    "#Ps.append(mp.Process(target = get_flux, kwargs={\"filter_name\":'r'}))\n",
    "#Ps.append(mp.Process(target = get_flux, kwargs={\"filter_name\":'i'}))\n",
    "#Ps.append(mp.Process(target = get_flux, kwargs={\"filter_name\":'z'}))\n",
    "\n",
    "t0 = time.time()\n",
    "\n",
    "for filtername in ['u','g','r','i','z']:\n",
    "    p=mp.Process(target = get_flux, kwargs={\"filter_name\":filtername})\n",
    "    p.start()\n",
    "    #print(len(gc.get_referrers(MockSED)))\n",
    "    Ps.append(p)\n",
    "    \n",
    "for p in Ps:\n",
    "    p.join()\n",
    "\n",
    "print(time.time()-t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9056005477905273\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "Flux_u = get_flux(filter_name='u')\n",
    "Flux_g = get_flux(filter_name='g')\n",
    "Flux_r = get_flux(filter_name='r')\n",
    "Flux_i = get_flux(filter_name='i')\n",
    "Flux_z = get_flux(filter_name='z')\n",
    "print(time.time()-t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "name 'shared_data' is parameter and global (<ipython-input-48-79065e72f4f6>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-48-79065e72f4f6>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    global shared_data\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m name 'shared_data' is parameter and global\n"
     ]
    }
   ],
   "source": [
    "def launch_jobs(shared_data, num_jobs=5, num_worker=4):\n",
    "    global shared_data\n",
    "    data_array = shared_data\n",
    "\n",
    "    pool = multiprocessing.Pool(num_worker)\n",
    "    return pool.map(job_handler, range(num_jobs))\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Can rotate galaxy. \n",
    "gg1.reorient(pops=[\"star\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Fluxs = [Flux_u, Flux_g, Flux_r, Flux_i, Flux_z]\n",
    "draw(Fluxs, gg1.star[\"x\"], gg1.star[\"y\"], suffix=\"face\")\n",
    "draw(Fluxs, gg1.star[\"x\"], gg1.star[\"z\"], suffix=\"edge\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unit + observation condition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
