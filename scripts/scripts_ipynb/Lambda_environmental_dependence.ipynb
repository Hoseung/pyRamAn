{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import utils.sampling as smp\n",
    "import matplotlib.pyplot as plt\n",
    "import tree\n",
    "import pickle\n",
    "import tree.halomodule as hmo\n",
    "import numpy as np\n",
    "from analysis.misc import load_cat\n",
    "import scipy.stats\n",
    "import tree.ctutils as ctu\n",
    "#from analysis.evol_lambda_HM import MainPrg\n",
    "import draw\n",
    "import load\n",
    "\n",
    "\n",
    "class MainPrg():\n",
    "    def __init__(self, idx, nnza):\n",
    "        \"\"\"\n",
    "            Separate tree data and lambda catalog data. \n",
    "            \n",
    "            early snapshot first.\n",
    "        \"\"\"\n",
    "        self.root_idx = idx\n",
    "        self.nsteps = nnza[\"nstep\"] # truncate later.\n",
    "        #self.idxs = np.zeros(len(nnza), dtype=int)\n",
    "        #self.ids = np.zeros(len(nnza), dtype=int)\n",
    "        self.nouts = nnza[\"nout\"]\n",
    "        self.zreds = nnza[\"zred\"]\n",
    "        self.aexps = 1/(1+self.zreds)       \n",
    "        \n",
    "    def initialize_data(self, cat, force=False):\n",
    "        if hasattr(self, \"data\"):\n",
    "            if not force:\n",
    "                print(\"self.data already exists. use force=True to re-initialize it.\")\n",
    "                pass\n",
    "        else:\n",
    "            self.data=np.zeros(len(self.nsteps),\n",
    "                                  dtype=cat.dtype)\n",
    "\n",
    "    def set_data(self, cat, nout):\n",
    "        ind = np.where(cat[\"tree_root_id\"] == self.root_idx)[0]\n",
    "        if len(ind) == 1:\n",
    "            self.data\n",
    "            inout = np.where(self.nouts == nout)[0]\n",
    "            if len(inout) == 1:\n",
    "                self.data[inout] = cat[ind]\n",
    "                #self.id[inout] = cat[ind][\"id\"]\n",
    "    \n",
    "    def fill_missing_data(self):\n",
    "        assert (self.ids[0] != 0)\n",
    "        # position angles cannot be linearly interpolated.\n",
    "        # skip.\n",
    "        #\n",
    "        # position and velocity are also not that linear..\n",
    "        # but let me just interpolate them.\n",
    "        # \n",
    "        # excluded=[\"lambda_arr2\"]\n",
    "        filled_fields = [\"eps\", \"epsh\", \"epsq\", \"lambda_12kpc\",\n",
    "                         \"lambda_arr\", \"lambda_arrh\",\n",
    "                         \"lambda_r\",\"lambda_r12kpc\",\n",
    "                         \"lambda_r2\",\"lambda_rh\",\"mgas\",\"mrj\",\"mstar\",\n",
    "                         \"reff\",\"reff2\",\"rgal\",\"rgal2\",\"rscale_lambda\",\n",
    "                         \"sfr\",\"sma\",\"smah\",\"smaq\",\"smi\",\"smih\",\"smiq\",\"ssfr\",\n",
    "                         \"vxc\", \"vyc\", \"vzc\", \"xc\", \"yc\", \"zc\"]\n",
    "\n",
    "        i_good_max = max(np.where(self.data[\"reff\"] > 0)[0])\n",
    "        i_bad = np.where(self.data['idx'] == 0)[0]\n",
    "        i_bad = i_bad[i_bad < i_good_max]\n",
    "        if len(i_bad) > 0:\n",
    "            for field in filled_fields:\n",
    "                # do not modify index and id fields.\n",
    "                arr = self.data[field] # it's a view.\n",
    "\n",
    "                for i_b in i_bad:\n",
    "                    # neighbouring array might also be empty. Search for closest valid element.\n",
    "                    # left point\n",
    "                    i_l = i_b - 1 \n",
    "                    while(i_l in i_bad):\n",
    "                        i_l = i_l - 1 \n",
    "                    # right point\n",
    "                    i_r = i_b + 1 \n",
    "                    while(i_r in i_bad):\n",
    "                        i_r = i_r + 1 \n",
    "                    arr[i_b] = (arr[i_b -1] + arr[i_b +1])/2.\n",
    "    \n",
    "    def truncate(self):\n",
    "        imax = np.where(self.data[\"lambda_r\"] > 0)[0] + 1\n",
    "        self.nsteps = self.nsteps[:imax]\n",
    "        self.nouts = self.nouts[:imax]\n",
    "        self.zreds = self.zreds[:imax]\n",
    "        self.aexps = self.aexps[:imax]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wdir = '/home/hoseung/Work/data/Horizon-AGN/'\n",
    "nout_fi = 782\n",
    "\n",
    "# Serialize catalogs. -> Only main galaxies\n",
    "# main galaxy list\n",
    "#alltrees = ctu.load_tree(wdir, is_gal=True)\n",
    "#ad = alltrees.data\n",
    "#tn = ad[ad['nout'] == nout_fi]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nnza = np.genfromtxt(wdir + \"nout_nstep_zred_aexp.txt\",\n",
    "                     dtype=[(\"nout\", int),\n",
    "                            (\"nstep\", int),\n",
    "                            (\"zred\", float),\n",
    "                            (\"aexp\", float)])\n",
    "\n",
    "#mpgs = pickle.load(open(wdir + \"MPGS_data_set.pickle\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from analysis.misc import load_cat\n",
    "from analysis.all_plot_modules import *\n",
    "from analysis.MajorMinorAccretion_module import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "load_init = False\n",
    "if load_init:\n",
    "    mpgs = pickle.load(open(wdir + \"MPGS_init.pickle\", \"rb\"))\n",
    "else:\n",
    "    mpgs=[]\n",
    "    samples = [0,1,2,3,4,6,7,8,9,10,11,12,13,15,16,17,18,19,20]\n",
    "    for sample in samples:\n",
    "        # initialize mpgs\n",
    "        ss = str(sample)\n",
    "        f_cat = load_cat(wdir + 'lambda_results/' + ss + '/catalog' + str(nout_fi) + ss +'.pickle')\n",
    "        root_idx_all = f_cat['idx'][f_cat[\"idx\"] > 0].astype(int) # why idx are float???\n",
    "        for i, idx in enumerate(root_idx_all):\n",
    "            mpgs.append(MainPrg(idx, nnza))\n",
    "\n",
    "        # assign lambda measurement data\n",
    "        for nout in nnza[\"nout\"][:1]:\n",
    "            cat = load_cat(wdir + 'lambda_results/' + ss + '/catalog' + str(nout) + ss +'.pickle')\n",
    "            #print(nout)\n",
    "            for gal in mpgs:\n",
    "                if nout == 782:\n",
    "                    gal.initialize_data(cat, force=True)\n",
    "                gal.set_data(cat, nout)\n",
    "        \n",
    "    for gal in mpgs:\n",
    "        gal.ids = gal.data[\"id\"]\n",
    "        gal.idxs = gal.data[\"idx\"]\n",
    "        #self.ids = np.zeros(len(nnza), dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Measure d5 of all galaxies in the catalog.\n",
    "Not just for the galaxies with lambda measurement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Halo.load_info] loading info\n",
      "[Halo.load_info] nout = 782, base =/home/hoseung/Work/data/Horizon-AGN/\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'mpgs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-d8bf1bb6aa9e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mgalidlist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mgal\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmpgs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mgalidlist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'mpgs' is not defined"
     ]
    }
   ],
   "source": [
    "from tree import halomodule as hmo\n",
    "allgal = hmo.Halo(nout=782, is_gal=True, base=wdir)\n",
    "\n",
    "import load\n",
    "info = load.info.Info(nout=782, base=wdir)\n",
    "\n",
    "galidlist = []\n",
    "for gal in mpgs:\n",
    "    galidlist.append(gal.ids[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xall = allgal.data[\"x\"]\n",
    "yall = allgal.data[\"y\"]\n",
    "zall = allgal.data[\"z\"]\n",
    "\n",
    "bins = np.linspace(0, 1, 20)\n",
    "\n",
    "xbin = np.digitize(xall, bins)\n",
    "ybin = np.digitize(yall, bins)\n",
    "zbin = np.digitize(zall, bins)\n",
    "\n",
    "dist_cut = 5/info.pboxsize\n",
    "\n",
    "d5 = []\n",
    "N5 = []\n",
    "for idgal in galidlist:\n",
    "#for igal in range(len(allgal.data)):\n",
    "    igal = np.where(allgal.data[\"id\"] == idgal)[0]\n",
    "    x_this = allgal.data[\"x\"][igal]\n",
    "    y_this = allgal.data[\"y\"][igal]\n",
    "    z_this = allgal.data[\"z\"][igal]\n",
    "    \n",
    "    # get subsample to speed up the code\n",
    "    xb_this = xbin[igal]\n",
    "    yb_this = ybin[igal]\n",
    "    zb_this = zbin[igal]\n",
    "    \n",
    "    first_candidates = allgal.data[(np.abs(xbin - xb_this) < 2) \\\n",
    "                                  * (np.abs(ybin - yb_this) < 2)\\\n",
    "                                  * (np.abs(zbin - zb_this) < 2)]\n",
    "    \n",
    "    dist = np.sqrt(np.square(first_candidates[\"x\"] - x_this) + \n",
    "                   np.square(first_candidates[\"y\"] - y_this) + \n",
    "                   np.square(first_candidates[\"z\"] - z_this))\n",
    "    #print(len(dist))\n",
    "    N5.append(sum(dist < dist_cut))\n",
    "    d5.append(np.sort(dist)[4] * info.pboxsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the d5 of top 20% galaxies?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'd5all' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-0c184c211ca8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#d5all = d5\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mhh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbinedge\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistogram\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md5all\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'd5all' is not defined"
     ]
    }
   ],
   "source": [
    "#d5all = d5\n",
    "hh, binedge = np.histogram(d5all, bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.hist(d5, bins=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "~50% = 1Mpc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d5_80 = d5[np.argsort(d5)[np.ceil(0.8 * len(d5)).astype(int)]]\n",
    "i_isol = np.where(d5 >= d5_80)[0]\n",
    "isolated = [mpgs[i] for i in i_isol]\n",
    "\n",
    "d5_20 = d5[np.argsort(d5)[np.ceil(0.2 * len(d5)).astype(int)]]\n",
    "i_dense = np.where(d5 <= d5_20)[0]\n",
    "dense = [mpgs[i] for i in i_dense]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mgal_a = np.array([gal.data[\"mstar\"][0] for gal in mpgs])\n",
    "lambda_a = np.array([gal.data[\"lambda_r\"][0] for gal in mpgs])\n",
    "\n",
    "mgal_i = np.array([gal.data[\"mstar\"][0] for gal in isolated])\n",
    "lambda_i = np.array([gal.data[\"lambda_r\"][0] for gal in isolated])\n",
    "\n",
    "mgal_d = np.array([gal.data[\"mstar\"][0] for gal in dense])\n",
    "lambda_d = np.array([gal.data[\"lambda_r\"][0] for gal in dense])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2130 2131\n"
     ]
    }
   ],
   "source": [
    "print(len(isolated), len(dense))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Cluster sample\n",
    "mpgs_c = pickle.load(open(\"/home/hoseung/Work/data/main_prgs_final_augmented_5_10_0.5_0.5_0.5_37_0.01_filtered_.pickle\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#gal = load_cat(\"./29176/HAGN/catalog187.pickle\")\n",
    "gal = load_cat(\"./29176/easy_final/catalog187.pickle\")\n",
    "mgal_c = gal[\"mstar\"]\n",
    "lambda_c = gal[\"lambda_r\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "eps_c = []\n",
    "lambda_c = []\n",
    "mgal_c = []\n",
    "inout = 0 # nout=187\n",
    "mstar_cut_hard = 5e9\n",
    "\n",
    "inout = 0\n",
    "for gal in mpgs_c:\n",
    "    mgal = gal.data[\"mstar\"][0]\n",
    "    if mgal > mstar_cut_hard:\n",
    "        eps_c.append(gal.data['eps'][inout])\n",
    "        lambda_c.append(gal.data['lambda_r'][inout])\n",
    "        mgal_c.append(gal.data['mstar'][inout])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mgal_c = np.array(mgal_c)\n",
    "lambda_c = np.array(lambda_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2,2, sharex=True, sharey=True)\n",
    "fig.set_size_inches(12,9)\n",
    "axs[0,0].scatter(np.log10(mgal_a), lambda_a, c='grey', edgecolor=\"none\", label=\"All (H)\")\n",
    "axs[0,0].scatter(np.log10(mgal_i), lambda_i, c='b', edgecolor=\"none\",label=\"isolated (H)\", alpha=0.5)\n",
    "axs[0,0].scatter(np.log10(mgal_d), lambda_d, c='r', edgecolor=\"none\", label=\"dense (H)\", alpha=0.5)\n",
    "axs[0,0].scatter(np.log10(mgal_c), lambda_c, c='g', edgecolor=\"none\", label=\"cluster\", alpha=0.5)\n",
    "axs[0,0].legend()\n",
    "\n",
    "axs[0,1].scatter(np.log10(mgal_i), lambda_i, c='b', edgecolor=\"none\",label=\"isolated (H)\", alpha=0.5)\n",
    "axs[0,1].legend()\n",
    "axs[1,0].scatter(np.log10(mgal_d), lambda_d, c='r', edgecolor=\"none\", label=\"dense (H)\", alpha=0.5)\n",
    "axs[1,0].legend()\n",
    "axs[1,1].scatter(np.log10(mgal_c), lambda_c, c='g', edgecolor=\"none\", label=\"cluster\", alpha=0.5)\n",
    "axs[1,1].legend()\n",
    "\n",
    "for ax in axs.ravel():\n",
    "    ax.set_xlim([9.4,12.8])\n",
    "    ax.set_ylim([0,0.8])\n",
    "\n",
    "axs[1,0].set_xlabel(r\"$log10(M_{\\odot})$\", fontsize=14)\n",
    "axs[1,1].set_xlabel(r\"$log10(M_{\\odot})$\", fontsize=14)\n",
    "axs[0,0].set_ylabel(r\"$\\lambda_{R_{e}}$\", fontsize=16)\n",
    "axs[1,0].set_ylabel(r\"$\\lambda_{R_{e}}$\", fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"LambdaVsMstar_Env.png\", dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0.8)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "samples = [0,1,2,3,4,6,7,8,9,10,11,12,13,15,16,17,18,19,20,1000]\n",
    "for sample in samples:\n",
    "    # initialize mpgs\n",
    "    ss = str(sample)\n",
    "    f_cat = load_cat(wdir + 'lambda_results/' + ss + '/catalog' + str(nout_fi) + ss +'.pickle')\n",
    "    if sample == 1000:\n",
    "        ax.scatter(nf_cat[\"mstar\"]), f_cat[\"lambda_r\"], c='r')\n",
    "    else:\n",
    "        ax.scatter(np.log10(f_cat[\"mstar\"]), f_cat[\"lambda_r\"], c='b')\n",
    "    \n",
    "    \n",
    "ax.set_ylim(0,0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clusters=[6098, 7206, 29172, 29176]\n",
    "for cluster in clusters[:3]:\n",
    "    cat = load_cat(\"/home/hoseung/Work/data/\" + str(cluster).zfill(5) + \"/easy_final/catalog187.pickle\")\n",
    "    plt.scatter(np.log10(cat[\"mstar\"]), cat[\"lambda_r\"], c='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clusters=[6098, 7206, 29172, 29176]\n",
    "for cluster in clusters[3:]:\n",
    "    cat = load_cat(\"/home/hoseung/Work/data/\" + str(cluster).zfill(5) + \"/easy_final/catalog187.pickle\")\n",
    "    plt.scatter(np.log10(cat[\"mstar\"]), cat[\"lambda_r\"], c='b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
