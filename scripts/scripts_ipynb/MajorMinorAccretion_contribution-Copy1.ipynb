{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measure contribution of Major merger, minor merger, and smooth accretion for only the 'safe' samples...?. \n",
    "Because tree bad link more likely occur at major merger events, I guess the 'safe' samples have less major mergers than the total sample. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import analysis.Major_Minor_accretion as mma\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Largest halo in the refinement region is not the main cluster.\n",
    "Is the largest NP halo the main cluster? \n",
    "To check it, color halos in NP.\n",
    "\n",
    "No, max_np galaxy/halo is the main galaxy/halo.\n",
    "But 'rvir' value is wrong.\n",
    "\n",
    "and fixed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import utils.sampling as smp\n",
    "import matplotlib.pyplot as plt\n",
    "import tree\n",
    "import pickle\n",
    "import tree.halomodule as hmo\n",
    "import numpy as np\n",
    "from analysis.misc import load_cat\n",
    "import scipy.stats\n",
    "import tree.ctutils as ctu\n",
    "from analysis.evol_lambda import MainPrg\n",
    "import draw\n",
    "import load\n",
    "import analysis.evol_lambda as evl\n",
    "import analysis.Major_Minor_accretion as mma\n",
    "import analysis.misc as amsc\n",
    "import tree.ctutils as ctu\n",
    "import utils.match as mtc\n",
    "# Read a single galaxy evolution catalog.\n",
    "\n",
    "from analysis.MajorMinorAccretion_module import *\n",
    "from analysis.all_plot_modules import *\n",
    "\n",
    "verbose=True\n",
    "# In[4]:\n",
    "base = './'\n",
    "cdir = ['catalog/', 'HM/', 'catalog_GM/', \"easy_final/\"][3]\n",
    "\n",
    "clusters = ['01605', '07206', \\\n",
    "            '35663', '24954', '49096', \\\n",
    "            '05427', '05420', '29172', \\\n",
    "            '29176', '10002', '36415', \\\n",
    "            '06098', '39990', '36413', \\\n",
    "            '17891', '04466']\n",
    "# parameters used for lambda_arr clipping.\n",
    "#ind_upper = 20\n",
    "#ind_lower = 20\n",
    "#sig_upper = 2.0\n",
    "#sig_lower = 2.0\n",
    "\n",
    " # 62: z = 1.666\n",
    "nout_fi = 187\n",
    "\n",
    "minimum_good_snap = 87\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def body(clusters,\n",
    "         dist_gal_scale_in=5,\n",
    "         dist_gal_scale_out=10,\n",
    "         dt_before=0.5,\n",
    "         dt_after=0.5,\n",
    "         dt_settle=0.5,\n",
    "         load=False,\n",
    "         nout_ini = 37,\n",
    "         filter_small=True,\n",
    "         min_mass_ratio = 0.05,\n",
    "         measure_delta_savefig=False,\n",
    "         find_merger_epoch_plot=False,\n",
    "         cdir=\"\"):\n",
    "\n",
    "    suffix = \"_{}_{}_{}_{}_{}_{}_{}\".format(dist_gal_scale_in,\n",
    "    dist_gal_scale_out,dt_before,dt_after,dt_settle,nout_ini,\n",
    "                                           min_mass_ratio)\n",
    "    if filter_small: \n",
    "        suffix = suffix + \"_filtered_\"\n",
    "\n",
    "    if load:\n",
    "        return pickle.load(open(\"main_prgs_final_augmented\" + suffix + \".pickle\", 'rb'))\n",
    "        \n",
    "    else:\n",
    "        mpgs = []\n",
    "        for cluster in clusters:\n",
    "            print(cluster)\n",
    "            wdir = base + cluster + '/'\n",
    "\n",
    "            # Serialize catalogs. -> Only main galaxies\n",
    "            # main galaxy list\n",
    "            alltrees = ctu.load_tree(wdir, is_gal=True)\n",
    "            ad = alltrees.data\n",
    "            tn = ad[ad['nout'] == nout_fi]\n",
    "\n",
    "            cat = load_cat(wdir + cdir + 'catalog' + str(nout_fi) + '.pickle')\n",
    "            #idx_all = [tn['id'][tn['Orig_halo_id'] == id_final][0] for id_final in cat['id']]\n",
    "            idx_all = cat['idx'][cat[\"idx\"] > 0].astype(int) # why idx are float???\n",
    "\n",
    "            mpg_tmp = []\n",
    "            for i, idx in enumerate(idx_all):\n",
    "                #print(i, idx)\n",
    "\n",
    "                mpg_tmp.append(MainPrg(ad, idx))\n",
    "            #    mpg_tmp =[MainPrg(ad, idx) for idx in idx_all]\n",
    "            for nout in range(nout_ini, nout_fi + 1):\n",
    "                cat = load_cat(wdir + cdir + 'catalog' + str(nout) + '.pickle')\n",
    "                for gal in mpg_tmp:\n",
    "                    gal.set_data(cat, nout)\n",
    "                    gal.cluster = int(cluster)\n",
    "        #        print(nout)\n",
    "            # get rid of galaxies with too short tree.\n",
    "            mpg_tmp = [gg for gg in mpg_tmp if sum(gg.data[\"reff\"] > 0) > minimum_good_snap]\n",
    "            for gal in mpg_tmp:\n",
    "                gal.fill_missing_data()\n",
    "                gal.clip_non_detection()\n",
    "                gal.smoothed_lambda_org = mma.smooth(gal.data[\"lambda_r\"], window_len=15)[:-1]\n",
    "                gal.smoothed_r = mma.smooth(gal.data[\"reff\"], window_len=15)[:-1]\n",
    "                gal.smoothed_lambda = mma.smooth(l_at_smoothed_r(gal, npix_per_reff=5), window_len=15)[:-1]\n",
    "\n",
    "            # save for each cluser\n",
    "            with open(wdir + \"main_prgs\" + suffix + \".pickle\", \"wb\") as f:\n",
    "                pickle.dump(mpg_tmp, f)    \n",
    "                \n",
    "            # Find_merger_epochs needs smoothed_r\n",
    "            find_merger_epochs(alltrees,\n",
    "                               idx_all,\n",
    "                               mpg_tmp,\n",
    "                               nout_ini=nout_ini,\n",
    "                               dist_gal_scale_in=dist_gal_scale_in,\n",
    "                               dist_gal_scale_out=dist_gal_scale_out,\n",
    "                               min_mass_ratio = min_mass_ratio,\n",
    "                               mass_ratio='early',\n",
    "                               verbose=False,\n",
    "                               do_plot=find_merger_epoch_plot,\n",
    "                               max_rgal=40,\n",
    "                               pdf_fname=str(cluster) + \"merger_ratio_epoch\" + suffix + \".pdf\")\n",
    "            \n",
    "\n",
    "            while len(mpg_tmp) > 0:\n",
    "                mpgs.append(mpg_tmp.pop())\n",
    "\n",
    "        if filter_small:\n",
    "            for gal in mpgs:\n",
    "                # Keep only the largest merger among multiple mergers\n",
    "                filter_small_mergers(gal.merger)\n",
    "\n",
    "        with open(\"main_prgs\" + suffix + \".pickle\", 'wb') as f:\n",
    "            mpgs.pop(2)\n",
    "            pickle.dump(mpgs, f)\n",
    "\n",
    "        measure_delta(mpgs,\n",
    "                      dt_before=dt_before,\n",
    "                      dt_after=dt_after,\n",
    "                      dt_settle=dt_settle,\n",
    "                      nout_ini=nout_ini,\n",
    "                      savefig=measure_delta_savefig,\n",
    "                      figname=\"figs/measure_delta\" + suffix)\n",
    "\n",
    "        Maj_min_acc_ratio(mpgs, major_ratio=4)\n",
    "\n",
    "        with open(\"main_prgs_final_augmented\" + suffix + \".pickle\", 'wb') as f:\n",
    "            pickle.dump(mpgs, f)\n",
    "    return mpgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Skewed Gaussian fit Major/Minor merger distribution and \n",
    "# qunatify how efficient major/minor mergers are in changing rotation paramter.\n",
    "def skew_fit(xvals, yvals, amp=10, center=0, sigma=1, gamma=0):\n",
    "    from lmfit.models import SkewedGaussianModel\n",
    "    model = SkewedGaussianModel()\n",
    "\n",
    "    # set initial parameter values\n",
    "    params = model.make_params(amplitude=amp, center=center, sigma=sigma, gamma=gamma)\n",
    "\n",
    "    # adjust parameters  to best fit data.\n",
    "    return model.fit(yvals, params, x=xvals)\n",
    "\n",
    "\n",
    "def draw_kdes_fit(dlM, dlm, dlo, dlt, ax\n",
    "                  , nevents\n",
    "                  , lw=1.5\n",
    "                  , excess=False\n",
    "                  , do_fit=False):\n",
    "\n",
    "        dM = kde_den(dlM)\n",
    "        dm = kde_den(dlm)\n",
    "        do = kde_den(dlo)\n",
    "        dtot = kde_den(dlt)\n",
    "\n",
    "        xs=np.linspace(-0.7,0.7,51)\n",
    "        if excess:\n",
    "            i_positive = np.linspace(0.0,0.6,26)\n",
    "            dM_curve = dM(xs) - np.concatenate((dM(i_positive)[::-1], dM(i_positive[1:])))\n",
    "            dm_curve = dm(xs) - np.concatenate((dm(i_positive)[::-1], dm(i_positive[1:])))\n",
    "            do_curve = do(xs) - np.concatenate((do(i_positive)[::-1], do(i_positive[1:])))\n",
    "            dtot_curve = dtot(xs) - np.concatenate((dtot(i_positive)[::-1], dtot(i_positive[1:])))\n",
    "        else:\n",
    "            dM_curve = dM(xs)\n",
    "            dm_curve = dm(xs)\n",
    "            do_curve = do(xs)\n",
    "            dtot_curve = dtot(xs)\n",
    "\n",
    "        nM = len(dlM)\n",
    "        nm = len(dlm)\n",
    "        no = len(dlo)\n",
    "        ntot = len(dlt)\n",
    "\n",
    "\n",
    "        Mlabel=\"Major \\n\" +r\"$N_{g}(N_{e})$\" + \" = {}({})\".format(nM, nevents[0])\n",
    "        mlabel=\"Minor \\n\" +r\"$N_{g}(N_{e})$\" + \" = {}({})\".format(nm, nevents[1])\n",
    "        olabel=\"Rest  \\n\" +r\"$N_{g}$\" + \" = {}\".format(no)\n",
    "        totlabel=\"Total\\n\" +r\"$N_{g}$\" + \" = {}\".format(ntot)\n",
    "        ax.plot(xs, dM_curve*nM/ntot, label=Mlabel, lw=lw, color=\"r\")\n",
    "        ax.plot(xs, dm_curve*nm/ntot, label=mlabel, lw=lw, color=\"g\")\n",
    "        ax.plot(xs, do_curve*no/ntot, label=olabel, lw=lw, color=\"b\")\n",
    "        ax.plot(xs, dtot_curve, label=totlabel, lw=lw, color=\"black\")\n",
    "        \n",
    "        ax.set_ylim([0, 1.15*ax.get_ylim()[1]])\n",
    "        \n",
    "        if do_fit:\n",
    "            fits=[]\n",
    "            fits.append(skew_fit(xs, dM_curve*nM/ntot, amp=nM/ntot, center=0, sigma=0.3, gamma=0))\n",
    "            fits.append(skew_fit(xs, dm_curve*nm/ntot, amp=nm/ntot, center=0, sigma=0.3, gamma=0))\n",
    "            fits.append(skew_fit(xs, do_curve*no/ntot, amp=no/ntot, center=0, sigma=0.3, gamma=0))\n",
    "            fits.append(skew_fit(xs, dtot_curve, amp=1, center=0, sigma=0.3, gamma=0))\n",
    "            #print(dM_curve*nM/ntot, rr.best_fit)\n",
    "            ax.plot(xs, fits[0].best_fit, lw=lw, color=\"r\", linestyle=\":\")\n",
    "            ax.plot(xs, fits[1].best_fit, lw=lw, color=\"g\", linestyle=\":\")\n",
    "            ax.plot(xs, fits[2].best_fit, lw=lw, color=\"b\", linestyle=\":\")\n",
    "            ax.plot(xs, fits[3].best_fit, lw=lw, color=\"black\", linestyle=\":\")\n",
    "\n",
    "            return fits\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# This part is already done. \n",
    "mpgs = body(clusters,\n",
    "        dist_gal_scale_in=5,\n",
    "        dist_gal_scale_out=10,\n",
    "        dt_before=0.5,\n",
    "        dt_after=0.5,\n",
    "        dt_settle=0.5,\n",
    "        load=False,\n",
    "        nout_ini=37,\n",
    "        filter_small=True,\n",
    "        min_mass_ratio = 0.01, # 0.1로 테스트\n",
    "        measure_delta_savefig=False,\n",
    "        find_merger_epoch_plot=False,\n",
    "        cdir=cdir)# z = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wdir = '/home/hoseung/Work/data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "suffix1 = \"_5_10_0.5_0.5_0.5_\"\n",
    "#suffix2 = [\"37_0.01\", \"37_0.1\", \"37_0.001\", \"27_0.01\"][2]\n",
    "suffix2 = \"37_0.02\"\n",
    "mpgs = pickle.load(open(wdir + \"all_prgs/main_prgs_final_augmented\" + suffix1 + suffix2 + \"_filtered_.pickle\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def kde_sci(mpgs,\n",
    "            mstar_cut_hard = 5e9,\n",
    "            mcut = 3.3e10,\n",
    "            hist=False,\n",
    "            shade=False,\n",
    "            kde=True,\n",
    "            norm_hist=False,\n",
    "            detected=True,\n",
    "            maj_ratio=4,\n",
    "            excess=False,\n",
    "            fname=None,\n",
    "            img_scale=1.5,\n",
    "            do_fit=False):\n",
    "\n",
    "    fontsize_ticks = 6 * img_scale\n",
    "    fontsize_tick_label = 8 * img_scale\n",
    "    fontsize_legend = 5 * img_scale\n",
    "\n",
    "    from matplotlib.ticker import NullFormatter\n",
    "\n",
    "    #examplegal = mpgs[449]\n",
    "    examplegal = None\n",
    "\n",
    "    l_dl_e = []\n",
    "    l_mr_e = []\n",
    "    l_mass_e = []\n",
    "\n",
    "    s_dl_e = []\n",
    "    s_mr_e = []\n",
    "    s_mass_e = []\n",
    "\n",
    "    l_dlt_g=[]\n",
    "    l_dlo_g=[]\n",
    "    l_dlM_g=[]\n",
    "    l_dlm_g=[]\n",
    "    l_mass_g=[]\n",
    "\n",
    "    s_dlt_g=[]\n",
    "    s_dlo_g=[]\n",
    "    s_dlM_g=[]\n",
    "    s_dlm_g=[]\n",
    "    s_mass_g=[]\n",
    "\n",
    "    M_changed = 0\n",
    "    m_changed = 0\n",
    "    no_merger_count = 0\n",
    "    count = 0\n",
    "    Maj_small = 0\n",
    "    for i, gal in enumerate(mpgs):\n",
    "        mgal = gal.data[\"mstar\"][0]\n",
    "        if mgal > mstar_cut_hard:\n",
    "            delta_lambda_tot = np.average(gal.data['lambda_r'][:5]) - np.average(gal.data['lambda_r'][-5:])\n",
    "            delta_lambda_major = 0\n",
    "            delta_lambda_minor = 0\n",
    "\n",
    "            # Large\n",
    "            if mgal > mcut:\n",
    "                if hasattr(gal, \"merger\"):\n",
    "                    if gal.merger is not None:\n",
    "                        l_dl_e.extend(gal.merger.delta_l)\n",
    "                        l_mr_e.extend(gal.merger.mr)\n",
    "                        for dl, mr in zip(gal.merger.delta_l, gal.merger.mr):\n",
    "                            if (mr < maj_ratio) and (dl > -1):\n",
    "                                delta_lambda_major = delta_lambda_major + dl\n",
    "                            if (mr > maj_ratio) and (dl > -1):\n",
    "                                delta_lambda_minor = delta_lambda_minor + dl\n",
    "\n",
    "                delta_lambda_other = delta_lambda_tot - delta_lambda_major - delta_lambda_minor\n",
    "                l_dlt_g.append(delta_lambda_tot)\n",
    "                l_dlo_g.append(delta_lambda_other)\n",
    "                l_dlM_g.append(delta_lambda_major)\n",
    "                l_dlm_g.append(delta_lambda_minor)\n",
    "            # small\n",
    "            else:\n",
    "                #s_mass_g.append(mgal)\n",
    "                if hasattr(gal, \"merger\"):\n",
    "                    if gal.merger is not None:\n",
    "                        s_dl_e.extend(gal.merger.delta_l)\n",
    "                        s_mr_e.extend(gal.merger.mr)\n",
    "                        for dl, mr in zip(gal.merger.delta_l, gal.merger.mr):\n",
    "                            if (mr < maj_ratio) and (dl > -1):\n",
    "                                delta_lambda_major = delta_lambda_major + dl\n",
    "                            if (mr > maj_ratio) and (dl > -1):\n",
    "                                delta_lambda_minor = delta_lambda_minor + dl\n",
    "\n",
    "\n",
    "                    delta_lambda_other = delta_lambda_tot - delta_lambda_major - delta_lambda_minor\n",
    "                    s_dlt_g.append(delta_lambda_tot)\n",
    "                    s_dlo_g.append(delta_lambda_other)\n",
    "                    s_dlM_g.append(delta_lambda_major)\n",
    "                    s_dlm_g.append(delta_lambda_minor)\n",
    "\n",
    "    l_dlt_g = np.array(l_dlt_g)\n",
    "    l_dlo_g = np.array(l_dlo_g)\n",
    "    l_dlM_g = np.array(l_dlM_g)\n",
    "    l_dlm_g = np.array(l_dlm_g)\n",
    "    #l_mass_g = np.array(l_mass_g)\n",
    "\n",
    "    s_dlt_g = np.array(s_dlt_g)\n",
    "    s_dlo_g = np.array(s_dlo_g)\n",
    "    s_dlM_g = np.array(s_dlM_g)\n",
    "    s_dlm_g = np.array(s_dlm_g)\n",
    "    #s_mass_g = np.array(s_mass_g)\n",
    "\n",
    "    # detected\n",
    "    l_dlM_g = l_dlM_g [l_dlM_g !=0]\n",
    "    #l_dlM_M = l_mass_g[l_dlM_g !=0]\n",
    "    l_dlm_g = l_dlm_g [l_dlm_g !=0]\n",
    "    #l_dlm_M = l_mass_g[l_dlm_g !=0]\n",
    "    #l_dlo_M = l_mass_g\n",
    "\n",
    "    s_dlM_g = s_dlM_g [s_dlM_g !=0]\n",
    "    #s_dlM_M = s_mass_g[s_dlM_g !=0]\n",
    "    s_dlm_g = s_dlm_g [s_dlm_g !=0]\n",
    "    #s_dlm_M = s_mass_g[s_dlm_g !=0]\n",
    "    #s_dlo_M = s_mass_g\n",
    "\n",
    "\n",
    "    l_dl_e = np.array(l_dl_e)\n",
    "    l_mr_e = np.array(l_mr_e)\n",
    "    #l_mass_e = []\n",
    "\n",
    "    s_dl_e = np.array(s_dl_e)\n",
    "    s_mr_e = np.array(s_mr_e)\n",
    "    #s_mass_e = []\n",
    "\n",
    "    fig, axs = plt.subplots(3, sharex=True)\n",
    "    fig.set_size_inches(4.75,7)\n",
    "    plt.subplots_adjust(hspace=0.01)\n",
    "\n",
    "    all_dlM_g = np.concatenate((l_dlM_g,s_dlM_g))\n",
    "    all_dlm_g = np.concatenate((l_dlm_g,s_dlm_g))\n",
    "    all_dlo_g = np.concatenate((l_dlo_g,s_dlo_g))\n",
    "    all_dlt_g = np.concatenate((l_dlt_g,s_dlt_g))\n",
    "\n",
    "    skew_fits=[]\n",
    "\n",
    "    skew_fits.append(\n",
    "              draw_kdes_fit(all_dlM_g,\n",
    "              all_dlm_g,\n",
    "              all_dlo_g,\n",
    "              all_dlt_g,\n",
    "              axs[0],\n",
    "              [sum(s_mr_e < maj_ratio) + sum(l_mr_e < maj_ratio),\n",
    "               sum(s_mr_e > maj_ratio) + sum(l_mr_e > maj_ratio),\n",
    "               len(all_dlo_g)],\n",
    "              excess=excess,\n",
    "              do_fit=do_fit))\n",
    "\n",
    "    skew_fits.append(\n",
    "              draw_kdes_fit(l_dlM_g,\n",
    "              l_dlm_g,\n",
    "              l_dlo_g,\n",
    "              l_dlt_g,\n",
    "              axs[1],\n",
    "              [sum(l_mr_e < maj_ratio),\n",
    "               sum(l_mr_e > maj_ratio),\n",
    "               len(l_dlo_g)],\n",
    "              excess=excess,\n",
    "              do_fit=do_fit))\n",
    "\n",
    "    skew_fits.append(\n",
    "              draw_kdes_fit(s_dlM_g,\n",
    "              s_dlm_g,\n",
    "              s_dlo_g,\n",
    "              s_dlt_g,\n",
    "              axs[2],\n",
    "              [sum(s_mr_e < maj_ratio),\n",
    "               sum(s_mr_e > maj_ratio),\n",
    "               len(s_dlo_g)],\n",
    "              excess=excess,\n",
    "              do_fit=do_fit))\n",
    "\n",
    "    axs[0].set_xlim([-0.6,0.6])\n",
    "\n",
    "    for ax in axs:\n",
    "        ax.xaxis.grid()\n",
    "        leg = ax.legend(fontsize=fontsize_legend)\n",
    "        leg.get_frame().set_alpha(0.5)\n",
    "        ax.yaxis.set_major_formatter(NullFormatter())\n",
    "        ax.set_ylabel(\"relative probability\", fontsize=fontsize_tick_label)\n",
    "\n",
    "    axs[2].set_xlabel(r\"$\\Delta \\lambda_{R_{eff}}$\", fontsize=fontsize_tick_label, family=\"Liberation Sans\")\n",
    "    axs[2].tick_params(labelsize=fontsize_ticks)\n",
    "    axs[2].set_xlim([-0.7,0.6])\n",
    "    #axs[0].legend(fontsize=12)\n",
    "\n",
    "\n",
    "    axs[0].text(0.05, 0.87, \"(A)\", weight=\"bold\", transform=axs[0].transAxes, fontsize=fontsize_ticks)\n",
    "    axs[0].text(0.15, 0.87, \"All\",transform=axs[0].transAxes, fontsize=fontsize_ticks)\n",
    "    axs[1].text(0.05, 0.87, \"(B) \", weight=\"bold\",transform=axs[1].transAxes, fontsize=fontsize_ticks)\n",
    "    axs[1].text(0.15, 0.87, r\"$log_{10}M_{\\star} > $ \" +\"{:.1f}\".format(np.log10(mcut))\n",
    "                , fontsize=fontsize_ticks\n",
    "                , transform=axs[1].transAxes)\n",
    "    axs[2].text(0.05, 0.87, \"(C) \", weight=\"bold\",transform=axs[2].transAxes, fontsize=fontsize_ticks)\n",
    "    axs[2].text(0.15, 0.87, r\"$log_{10}M_{\\star} < $ \" +\"{:.1f}\".format(np.log10(mcut))\n",
    "                , fontsize=fontsize_ticks\n",
    "                , transform=axs[2].transAxes)\n",
    "\n",
    "\n",
    "    if examplegal is not None:\n",
    "        dls = examplegal.merger.delta_l\n",
    "        mrs = examplegal.merger.mr\n",
    "\n",
    "        for dl, mr in zip(dls, mrs):\n",
    "            if mr < maj_ratio:\n",
    "                axs[0].scatter(dl, [0.15], facecolor='r', edgecolor=\"w\", marker=\"d\", s=40, zorder=20)\n",
    "            else:\n",
    "                axs[0].scatter(dl, [0.15], facecolor='g', edgecolor=\"w\", marker=\"d\", s=40, zorder=20)\n",
    "\n",
    "        dl_tot = examplegal.data[\"lambda_r\"][0] - examplegal.data[\"lambda_r\"][-1]\n",
    "        axs[0].scatter(dl_tot, [0.15], facecolor='black', edgecolor=\"w\", marker=\"d\", s=40, zorder=20)\n",
    "        dl_o = dl_tot - sum(examplegal.merger.delta_l)\n",
    "        axs[0].scatter(dl_o, 0.15, facecolor='b', edgecolor=\"w\", marker=\"d\", s=40, zorder=20)\n",
    "\n",
    "        # legend\n",
    "        axs[0].scatter(0.21, 1, facecolor='none', edgecolor=\"black\", marker=\"d\", s=40)\n",
    "        axs[0].text(0.24, 0.95, \"example galaxy\", fontsize=8)\n",
    "        print(\"Example gal\")\n",
    "\n",
    "    axs[0].set_ylim([0,3.5])\n",
    "    axs[1].set_ylim([0,3.5])\n",
    "    axs[2].set_ylim([0,3.5])\n",
    "\n",
    "\n",
    "    plt.savefig(fname + \"{:.1f}.png\".format(np.log10(mcut)), dpi=150, bbox_inches=\"tight\")\n",
    "    plt.savefig(fname + \"{:.1f}.pdf\".format(np.log10(mcut)), bbox_inches='tight') # eps does NOT support transparency!\n",
    "    #plt.savefig(fname + \"{:.1f}.eps\".format(np.log10(mcut)), bbox_inches='tight')\n",
    "    #plt.savefig(fname + \"{:.1f}.svg\".format(np.log10(mcut)), bbox_inches='tight')\n",
    "\n",
    "    #plt.close()\n",
    "    return skew_fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fnames = glob(\"/home/hoseung/Work/data/all_prgs/main_prgs_final_augmented*02_filtered_.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fits=[]\n",
    "for fname in fnames:\n",
    "    mpgs = pickle.load(open(fname, \"rb\"))\n",
    "    suffix = fname.split(\"augmented\")[1].split(\"filtered\")[0]\n",
    "    fit = kde_sci(mpgs,\n",
    "            mstar_cut_hard = 5e9,\n",
    "            mcut = 3.3e10,\n",
    "            hist=False,\n",
    "            shade=False,\n",
    "            kde=True,\n",
    "            norm_hist=False,\n",
    "            detected=True,\n",
    "            maj_ratio=4,\n",
    "            excess=False,\n",
    "            fname=wdir + \"figs/MajMinNon_contribution\" + suffix,\n",
    "            img_scale=1.5,\n",
    "            do_fit=True)\n",
    "    fits.append(fit)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
