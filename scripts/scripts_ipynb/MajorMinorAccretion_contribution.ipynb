{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measure contribution of Major merger, minor merger, and smooth accretion for only the 'safe' samples...?. \n",
    "Because tree bad link more likely occur at major merger events, I guess the 'safe' samples have less major mergers than the total sample. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import analysis.Major_Minor_accretion as mma\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Largest halo in the refinement region is not the main cluster.\n",
    "Is the largest NP halo the main cluster? \n",
    "To check it, color halos in NP.\n",
    "\n",
    "No, max_np galaxy/halo is the main galaxy/halo.\n",
    "But 'rvir' value is wrong.\n",
    "\n",
    "and fixed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import utils.sampling as smp\n",
    "import matplotlib.pyplot as plt\n",
    "import tree\n",
    "import pickle\n",
    "import tree.halomodule as hmo\n",
    "import numpy as np\n",
    "from analysis.misc import load_cat\n",
    "import scipy.stats\n",
    "import tree.ctutils as ctu\n",
    "from analysis.evol_lambda import MainPrg\n",
    "import draw\n",
    "import load\n",
    "import analysis.evol_lambda as evl\n",
    "import analysis.Major_Minor_accretion as mma\n",
    "import analysis.misc as amsc\n",
    "import tree.ctutils as ctu\n",
    "import utils.match as mtc\n",
    "# Read a single galaxy evolution catalog.\n",
    "\n",
    "from analysis.MajorMinorAccretion_module import *\n",
    "from analysis.all_plot_modules import *\n",
    "\n",
    "verbose=True\n",
    "# In[4]:\n",
    "base = './'\n",
    "cdir = ['catalog/', 'HM/', 'catalog_GM/', \"easy_final/\"][3]\n",
    "\n",
    "clusters = ['01605', '07206', \\\n",
    "            '35663', '24954', '49096', \\\n",
    "            '05427', '05420', '29172', \\\n",
    "            '29176', '10002', '36415', \\\n",
    "            '06098', '39990', '36413', \\\n",
    "            '17891', '04466']\n",
    "# parameters used for lambda_arr clipping.\n",
    "#ind_upper = 20\n",
    "#ind_lower = 20\n",
    "#sig_upper = 2.0\n",
    "#sig_lower = 2.0\n",
    "\n",
    " # 62: z = 1.666\n",
    "nout_fi = 187\n",
    "\n",
    "minimum_good_snap = 87\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def body(clusters,\n",
    "         dist_gal_scale_in=5,\n",
    "         dist_gal_scale_out=10,\n",
    "         dt_before=0.5,\n",
    "         dt_after=0.5,\n",
    "         dt_settle=0.5,\n",
    "         load=False,\n",
    "         nout_ini = 37,\n",
    "         filter_small=True,\n",
    "         min_mass_ratio = 0.05,\n",
    "         measure_delta_savefig=False,\n",
    "         find_merger_epoch_plot=False,\n",
    "         cdir=\"\"):\n",
    "\n",
    "    suffix = \"_{}_{}_{}_{}_{}_{}_{}\".format(dist_gal_scale_in,\n",
    "    dist_gal_scale_out,dt_before,dt_after,dt_settle,nout_ini,\n",
    "                                           min_mass_ratio)\n",
    "    if filter_small: \n",
    "        suffix = suffix + \"_filtered_\"\n",
    "\n",
    "    if load:\n",
    "        return pickle.load(open(\"main_prgs_final_augmented\" + suffix + \".pickle\", 'rb'))\n",
    "        \n",
    "    else:\n",
    "        mpgs = []\n",
    "        for cluster in clusters:\n",
    "            print(cluster)\n",
    "            wdir = base + cluster + '/'\n",
    "\n",
    "            # Serialize catalogs. -> Only main galaxies\n",
    "            # main galaxy list\n",
    "            alltrees = ctu.load_tree(wdir, is_gal=True)\n",
    "            ad = alltrees.data\n",
    "            tn = ad[ad['nout'] == nout_fi]\n",
    "\n",
    "            cat = load_cat(wdir + cdir + 'catalog' + str(nout_fi) + '.pickle')\n",
    "            #idx_all = [tn['id'][tn['Orig_halo_id'] == id_final][0] for id_final in cat['id']]\n",
    "            idx_all = cat['idx'][cat[\"idx\"] > 0].astype(int) # why idx are float???\n",
    "\n",
    "            mpg_tmp = []\n",
    "            for i, idx in enumerate(idx_all):\n",
    "                #print(i, idx)\n",
    "\n",
    "                mpg_tmp.append(MainPrg(ad, idx))\n",
    "            #    mpg_tmp =[MainPrg(ad, idx) for idx in idx_all]\n",
    "            for nout in range(nout_ini, nout_fi + 1):\n",
    "                cat = load_cat(wdir + cdir + 'catalog' + str(nout) + '.pickle')\n",
    "                for gal in mpg_tmp:\n",
    "                    gal.set_data(cat, nout)\n",
    "                    gal.cluster = int(cluster)\n",
    "        #        print(nout)\n",
    "            # get rid of galaxies with too short tree.\n",
    "            mpg_tmp = [gg for gg in mpg_tmp if sum(gg.data[\"reff\"] > 0) > minimum_good_snap]\n",
    "            for gal in mpg_tmp:\n",
    "                gal.fill_missing_data()\n",
    "                gal.clip_non_detection()\n",
    "                gal.smoothed_lambda_org = mma.smooth(gal.data[\"lambda_r\"], window_len=15)[:-1]\n",
    "                gal.smoothed_r = mma.smooth(gal.data[\"reff\"], window_len=15)[:-1]\n",
    "                gal.smoothed_lambda = mma.smooth(l_at_smoothed_r(gal, npix_per_reff=5), window_len=15)[:-1]\n",
    "\n",
    "            # save for each cluser\n",
    "            with open(wdir + \"main_prgs\" + suffix + \".pickle\", \"wb\") as f:\n",
    "                pickle.dump(mpg_tmp, f)    \n",
    "                \n",
    "            # Find_merger_epochs needs smoothed_r\n",
    "            find_merger_epochs(alltrees,\n",
    "                               idx_all,\n",
    "                               mpg_tmp,\n",
    "                               nout_ini=nout_ini,\n",
    "                               dist_gal_scale_in=dist_gal_scale_in,\n",
    "                               dist_gal_scale_out=dist_gal_scale_out,\n",
    "                               min_mass_ratio = min_mass_ratio,\n",
    "                               mass_ratio='early',\n",
    "                               verbose=False,\n",
    "                               do_plot=find_merger_epoch_plot,\n",
    "                               max_rgal=40,\n",
    "                               pdf_fname=str(cluster) + \"merger_ratio_epoch\" + suffix + \".pdf\")\n",
    "            \n",
    "\n",
    "            while len(mpg_tmp) > 0:\n",
    "                mpgs.append(mpg_tmp.pop())\n",
    "\n",
    "        if filter_small:\n",
    "            for gal in mpgs:\n",
    "                # Keep only the largest merger among multiple mergers\n",
    "                filter_small_mergers(gal.merger)\n",
    "\n",
    "        with open(\"main_prgs\" + suffix + \".pickle\", 'wb') as f:\n",
    "            mpgs.pop(2)\n",
    "            pickle.dump(mpgs, f)\n",
    "\n",
    "        measure_delta(mpgs,\n",
    "                      dt_before=dt_before,\n",
    "                      dt_after=dt_after,\n",
    "                      dt_settle=dt_settle,\n",
    "                      nout_ini=nout_ini,\n",
    "                      savefig=measure_delta_savefig,\n",
    "                      figname=\"figs/measure_delta\" + suffix)\n",
    "\n",
    "        Maj_min_acc_ratio(mpgs, major_ratio=4)\n",
    "\n",
    "        with open(\"main_prgs_final_augmented\" + suffix + \".pickle\", 'wb') as f:\n",
    "            pickle.dump(mpgs, f)\n",
    "    return mpgs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# This part is already done. \n",
    "mpgs = body(clusters,\n",
    "        dist_gal_scale_in=5,\n",
    "        dist_gal_scale_out=10,\n",
    "        dt_before=0.5,\n",
    "        dt_after=0.5,\n",
    "        dt_settle=0.5,\n",
    "        load=False,\n",
    "        nout_ini=37,\n",
    "        filter_small=True,\n",
    "        min_mass_ratio = 0.01, # 0.1로 테스트\n",
    "        measure_delta_savefig=False,\n",
    "        find_merger_epoch_plot=False,\n",
    "        cdir=cdir)# z = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wdir = '/home/hoseung/Work/data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "suffix = [\"_5_10_0.5_0.5_0.5_\",\n",
    "          \"_5_15_0.5_0.5_0.5_\",\n",
    "          \"_5_10_0.5_0.5_1.0_\",\n",
    "          \"_5_15_0.5_0.5_1.0_\",\n",
    "          \"_10_20_0.5_0.5_0.5_\",\n",
    "          \"_2_5_0.5_0.5_1.0_\"][5]\n",
    "mpgs = pickle.load(open(wdir + \"all_prgs/main_prgs_final_augmented\" + suffix + \"37_0.01_filtered_.pickle\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example gal\n"
     ]
    }
   ],
   "source": [
    "#def kde_sci(mpgs\n",
    "mstar_cut_hard = 5e9\n",
    "mcut = 3.3e10\n",
    "hist=False\n",
    "shade=False\n",
    "kde=True\n",
    "norm_hist=False\n",
    "detected=True\n",
    "maj_ratio=4\n",
    "excess=False\n",
    "fname=wdir + \"figs/MajMinNon_contribution\" + suffix\n",
    "img_scale=1.5\n",
    "\n",
    "\n",
    "fontsize_ticks = 6 * img_scale\n",
    "fontsize_tick_label = 8 * img_scale\n",
    "fontsize_legend = 5 * img_scale\n",
    "\n",
    "from matplotlib.ticker import NullFormatter\n",
    "\n",
    "examplegal = mpgs[449]\n",
    "\n",
    "l_dl_e = []\n",
    "l_mr_e = []\n",
    "l_mass_e = []\n",
    "\n",
    "s_dl_e = []\n",
    "s_mr_e = []\n",
    "s_mass_e = []\n",
    "\n",
    "l_dlt_g=[]\n",
    "l_dlo_g=[]\n",
    "l_dlM_g=[]\n",
    "l_dlm_g=[]\n",
    "l_mass_g=[]\n",
    "\n",
    "s_dlt_g=[]\n",
    "s_dlo_g=[]\n",
    "s_dlM_g=[]\n",
    "s_dlm_g=[]\n",
    "s_mass_g=[]\n",
    "\n",
    "M_changed = 0\n",
    "m_changed = 0\n",
    "no_merger_count = 0\n",
    "count = 0\n",
    "Maj_small = 0\n",
    "for i, gal in enumerate(mpgs):\n",
    "    mgal = gal.data[\"mstar\"][0]\n",
    "    if mgal > mstar_cut_hard:\n",
    "        delta_lambda_tot = np.average(gal.data['lambda_r'][:5]) - np.average(gal.data['lambda_r'][-5:])\n",
    "        delta_lambda_major = 0\n",
    "        delta_lambda_minor = 0\n",
    "\n",
    "        # Large\n",
    "        if mgal > mcut:\n",
    "            if hasattr(gal, \"merger\"):\n",
    "                if gal.merger is not None:\n",
    "                    l_dl_e.extend(gal.merger.delta_l)\n",
    "                    l_mr_e.extend(gal.merger.mr)\n",
    "                    for dl, mr in zip(gal.merger.delta_l, gal.merger.mr):\n",
    "                        if (mr < maj_ratio) and (dl > -1):\n",
    "                            delta_lambda_major = delta_lambda_major + dl\n",
    "                        if (mr > maj_ratio) and (dl > -1):\n",
    "                            delta_lambda_minor = delta_lambda_minor + dl\n",
    "\n",
    "            delta_lambda_other = delta_lambda_tot - delta_lambda_major - delta_lambda_minor\n",
    "            l_dlt_g.append(delta_lambda_tot)\n",
    "            l_dlo_g.append(delta_lambda_other)\n",
    "            l_dlM_g.append(delta_lambda_major)\n",
    "            l_dlm_g.append(delta_lambda_minor)\n",
    "        # small\n",
    "        else:\n",
    "            #s_mass_g.append(mgal)\n",
    "            if hasattr(gal, \"merger\"):\n",
    "                if gal.merger is not None:\n",
    "                    s_dl_e.extend(gal.merger.delta_l)\n",
    "                    s_mr_e.extend(gal.merger.mr)\n",
    "                    for dl, mr in zip(gal.merger.delta_l, gal.merger.mr):\n",
    "                        if (mr < maj_ratio) and (dl > -1):\n",
    "                            delta_lambda_major = delta_lambda_major + dl\n",
    "                        if (mr > maj_ratio) and (dl > -1):\n",
    "                            delta_lambda_minor = delta_lambda_minor + dl\n",
    "\n",
    "\n",
    "                delta_lambda_other = delta_lambda_tot - delta_lambda_major - delta_lambda_minor\n",
    "                s_dlt_g.append(delta_lambda_tot)\n",
    "                s_dlo_g.append(delta_lambda_other)\n",
    "                s_dlM_g.append(delta_lambda_major)\n",
    "                s_dlm_g.append(delta_lambda_minor)\n",
    "\n",
    "l_dlt_g = np.array(l_dlt_g)\n",
    "l_dlo_g = np.array(l_dlo_g)\n",
    "l_dlM_g = np.array(l_dlM_g)\n",
    "l_dlm_g = np.array(l_dlm_g)\n",
    "#l_mass_g = np.array(l_mass_g)\n",
    "\n",
    "s_dlt_g = np.array(s_dlt_g)\n",
    "s_dlo_g = np.array(s_dlo_g)\n",
    "s_dlM_g = np.array(s_dlM_g)\n",
    "s_dlm_g = np.array(s_dlm_g)\n",
    "#s_mass_g = np.array(s_mass_g)\n",
    "\n",
    "# detected\n",
    "l_dlM_g = l_dlM_g [l_dlM_g !=0]\n",
    "#l_dlM_M = l_mass_g[l_dlM_g !=0]\n",
    "l_dlm_g = l_dlm_g [l_dlm_g !=0]\n",
    "#l_dlm_M = l_mass_g[l_dlm_g !=0]\n",
    "#l_dlo_M = l_mass_g\n",
    "\n",
    "s_dlM_g = s_dlM_g [s_dlM_g !=0]\n",
    "#s_dlM_M = s_mass_g[s_dlM_g !=0]\n",
    "s_dlm_g = s_dlm_g [s_dlm_g !=0]\n",
    "#s_dlm_M = s_mass_g[s_dlm_g !=0]\n",
    "#s_dlo_M = s_mass_g\n",
    "\n",
    "\n",
    "l_dl_e = np.array(l_dl_e)\n",
    "l_mr_e = np.array(l_mr_e)\n",
    "#l_mass_e = []\n",
    "\n",
    "s_dl_e = np.array(s_dl_e)\n",
    "s_mr_e = np.array(s_mr_e)\n",
    "#s_mass_e = []\n",
    "\n",
    "fig, axs = plt.subplots(3, sharex=True)\n",
    "fig.set_size_inches(4.75,7)\n",
    "plt.subplots_adjust(hspace=0.01)\n",
    "\n",
    "all_dlM_g = np.concatenate((l_dlM_g,s_dlM_g))\n",
    "all_dlm_g = np.concatenate((l_dlm_g,s_dlm_g))\n",
    "all_dlo_g = np.concatenate((l_dlo_g,s_dlo_g))\n",
    "all_dlt_g = np.concatenate((l_dlt_g,s_dlt_g))\n",
    "\n",
    "draw_kdes(all_dlM_g,\n",
    "          all_dlm_g,\n",
    "          all_dlo_g,\n",
    "          all_dlt_g,\n",
    "          axs[0],\n",
    "          [sum(s_mr_e < maj_ratio) + sum(l_mr_e < maj_ratio),\n",
    "           sum(s_mr_e > maj_ratio) + sum(l_mr_e > maj_ratio),\n",
    "           len(all_dlo_g)],\n",
    "          excess=excess)\n",
    "\n",
    "draw_kdes(l_dlM_g,\n",
    "          l_dlm_g,\n",
    "          l_dlo_g,\n",
    "          l_dlt_g,\n",
    "          axs[1],\n",
    "          [sum(l_mr_e < maj_ratio),\n",
    "           sum(l_mr_e > maj_ratio),\n",
    "           len(l_dlo_g)],\n",
    "          excess=excess)\n",
    "\n",
    "draw_kdes(s_dlM_g,\n",
    "          s_dlm_g,\n",
    "          s_dlo_g,\n",
    "          s_dlt_g,\n",
    "          axs[2],\n",
    "          [sum(s_mr_e < maj_ratio),\n",
    "           sum(s_mr_e > maj_ratio),\n",
    "           len(s_dlo_g)],\n",
    "          excess=excess)\n",
    "\n",
    "axs[0].set_xlim([-0.6,0.6])\n",
    "\n",
    "for ax in axs:\n",
    "    ax.xaxis.grid()\n",
    "    leg = ax.legend(fontsize=fontsize_legend)\n",
    "    leg.get_frame().set_alpha(0.5)\n",
    "    ax.yaxis.set_major_formatter(NullFormatter())\n",
    "    ax.set_ylabel(\"relative probability\", fontsize=fontsize_tick_label)\n",
    " \n",
    "axs[2].set_xlabel(r\"$\\Delta \\lambda_{R_{eff}}$\", fontsize=fontsize_tick_label, family=\"Liberation Sans\")\n",
    "axs[2].tick_params(labelsize=fontsize_ticks)\n",
    "axs[2].set_xlim([-0.7,0.6])\n",
    "#axs[0].legend(fontsize=12)\n",
    "\n",
    "\n",
    "axs[0].text(0.05, 0.87, \"(A)\", weight=\"bold\", transform=axs[0].transAxes, fontsize=fontsize_ticks)\n",
    "axs[0].text(0.15, 0.87, \"All\",transform=axs[0].transAxes, fontsize=fontsize_ticks)\n",
    "axs[1].text(0.05, 0.87, \"(B) \", weight=\"bold\",transform=axs[1].transAxes, fontsize=fontsize_ticks)\n",
    "axs[1].text(0.15, 0.87, r\"$log_{10}M_{\\star} > $ \" +\"{:.1f}\".format(np.log10(mcut))\n",
    "            , fontsize=fontsize_ticks\n",
    "            , transform=axs[1].transAxes)\n",
    "axs[2].text(0.05, 0.87, \"(C) \", weight=\"bold\",transform=axs[2].transAxes, fontsize=fontsize_ticks)\n",
    "axs[2].text(0.15, 0.87, r\"$log_{10}M_{\\star} < $ \" +\"{:.1f}\".format(np.log10(mcut))\n",
    "            , fontsize=fontsize_ticks\n",
    "            , transform=axs[2].transAxes)\n",
    "\n",
    "\n",
    "if examplegal is not None:\n",
    "    dls = examplegal.merger.delta_l\n",
    "    mrs = examplegal.merger.mr\n",
    "\n",
    "    for dl, mr in zip(dls, mrs):\n",
    "        if mr < maj_ratio:\n",
    "            axs[0].scatter(dl, [0.15], facecolor='r', edgecolor=\"w\", marker=\"d\", s=40, zorder=20)\n",
    "        else:\n",
    "            axs[0].scatter(dl, [0.15], facecolor='g', edgecolor=\"w\", marker=\"d\", s=40, zorder=20)\n",
    "            \n",
    "    dl_tot = examplegal.data[\"lambda_r\"][0] - examplegal.data[\"lambda_r\"][-1]\n",
    "    axs[0].scatter(dl_tot, [0.15], facecolor='black', edgecolor=\"w\", marker=\"d\", s=40, zorder=20)\n",
    "    dl_o = dl_tot - sum(examplegal.merger.delta_l)\n",
    "    axs[0].scatter(dl_o, 0.15, facecolor='b', edgecolor=\"w\", marker=\"d\", s=40, zorder=20)\n",
    "\n",
    "    # legend\n",
    "    axs[0].scatter(0.21, 1, facecolor='none', edgecolor=\"black\", marker=\"d\", s=40)\n",
    "    axs[0].text(0.24, 0.95, \"example galaxy\", fontsize=8)\n",
    "    print(\"Example gal\")\n",
    "\n",
    "axs[0].set_ylim([0,3.5])\n",
    "axs[1].set_ylim([0,3.5])\n",
    "axs[2].set_ylim([0,3.5])\n",
    "    \n",
    "\n",
    "plt.savefig(fname + \"{:.1f}.png\".format(np.log10(mcut)), dpi=150, bbox_inches=\"tight\")\n",
    "plt.savefig(fname + \"{:.1f}.pdf\".format(np.log10(mcut)), bbox_inches='tight') # eps does NOT support transparency!\n",
    "#plt.savefig(fname + \"{:.1f}.eps\".format(np.log10(mcut)), bbox_inches='tight')\n",
    "#plt.savefig(fname + \"{:.1f}.svg\".format(np.log10(mcut)), bbox_inches='tight')\n",
    "\n",
    "#plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.savefig(fname + \"{:.1f}_11.png\".format(np.log10(mcut)), dpi=200, bbox_inches=\"tight\")\n",
    "plt.savefig(fname + \"{:.1f}_11.pdf\".format(np.log10(mcut)), bbox_inches='tight') # eps does NOT support transparency!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kde_sci(mpgs,\n",
    "        mstar_cut_hard = 5e9,\n",
    "        mcut = 3.3e10,\n",
    "        hist=False,\n",
    "        shade=False,\n",
    "        kde=True,\n",
    "        norm_hist=False,\n",
    "        detected=True,\n",
    "        maj_ratio=4,\n",
    "        excess=False,\n",
    "        fname=\"figs/MajMinNon_contribution_\",\n",
    "        img_scale=1.5)\n",
    "\n",
    "mcut = 3.3e10\n",
    "fname=\"figs/MajMinNon_contribution_\"\n",
    "\n",
    "import matplotlib\n",
    "from matplotlib import rc, font_manager\n",
    "sizeOfFont=9\n",
    "fontProperties = {'family':'Sans',\n",
    "                  'weight' : 'normal', 'size' : sizeOfFont}\n",
    "ticks_font = font_manager.FontProperties(family='Ubuntu Mono', style='normal',\n",
    "                size=sizeOfFont, weight='normal', stretch='normal')\n",
    "\n",
    "#rc('text', usetex=True)\n",
    "#rc('font',**fontProperties)\n",
    "\n",
    "#matplotlib.rcParams.update({'font.size': 16})\n",
    "\n",
    "\n",
    "plt.savefig(fname + \"{:.1f}.png\".format(np.log10(mcut)), dpi=200, bbox_inches=\"tight\")\n",
    "plt.savefig(fname + \"{:.1f}.pdf\".format(np.log10(mcut)), bbox_inches='tight') # eps does NOT support transparency!\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#av = plot_violin2(mpgs,\n",
    "            mstar_cut_hard = 5e9,\n",
    "            massive_cut = 1e11,\n",
    "            use_seaborn=True,\n",
    "            violin=False,\n",
    "            bw=0.1,#\"scott\", \"silverman\",\n",
    "            gridsize=30,\n",
    "            fname=\"figs/MajMinNon_contribution\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "suffix = \"measure_merger_massive\"\n",
    "plt.close()\n",
    "da = plot_violin(mpgs,\n",
    "            mstar_cut_hard= 5e9,\n",
    "            massive_cut = 3.3e10,\n",
    "            use_seaborn=True,\n",
    "            bw=\"scott\",\n",
    "            gridsize=30,\n",
    "            fname=\"figs/mma_violin_sns.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
