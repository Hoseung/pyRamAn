{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measure contribution of Major merger, minor merger, and smooth accretion for only the 'safe' samples...?. \n",
    "Because tree bad link more likely occur at major merger events, I guess the 'safe' samples have less major mergers than the total sample. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import analysis.Major_Minor_accretion as mma\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Largest halo in the refinement region is not the main cluster.\n",
    "Is the largest NP halo the main cluster? \n",
    "To check it, color halos in NP.\n",
    "\n",
    "No, max_np galaxy/halo is the main galaxy/halo.\n",
    "But 'rvir' value is wrong.\n",
    "\n",
    "and fixed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils.sampling as smp\n",
    "import matplotlib.pyplot as plt\n",
    "import tree\n",
    "import pickle\n",
    "import tree.halomodule as hmo\n",
    "import numpy as np\n",
    "from analysis.misc import load_cat\n",
    "import scipy.stats\n",
    "import tree.ctutils as ctu\n",
    "from analysis.evol_lambda import MainPrg\n",
    "import draw\n",
    "import load\n",
    "import analysis.evol_lambda as evl\n",
    "import analysis.Major_Minor_accretion as mma\n",
    "import analysis.misc as amsc\n",
    "import tree.ctutils as ctu\n",
    "import utils.match as mtc\n",
    "# Read a single galaxy evolution catalog.\n",
    "\n",
    "from analysis.MajorMinorAccretion_module import *\n",
    "from analysis.all_plot_modules import *\n",
    "\n",
    "verbose=True\n",
    "# In[4]:\n",
    "base = './'\n",
    "cdir = ['catalog/', 'HM/', 'catalog_GM/', \"easy_final/\"][3]\n",
    "\n",
    "clusters = ['01605', '07206', \\\n",
    "            '35663', '24954', '49096', \\\n",
    "            '05427', '05420', '29172', \\\n",
    "            '29176', '10002', '36415', \\\n",
    "            '06098', '39990', '36413', \\\n",
    "            '17891', '04466']\n",
    "# parameters used for lambda_arr clipping.\n",
    "#ind_upper = 20\n",
    "#ind_lower = 20\n",
    "#sig_upper = 2.0\n",
    "#sig_lower = 2.0\n",
    "\n",
    " # 62: z = 1.666\n",
    "nout_fi = 187\n",
    "\n",
    "minimum_good_snap = 87\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def body(clusters,\n",
    "         dist_gal_scale_in=5,\n",
    "         dist_gal_scale_out=10,\n",
    "         dt_before=0.5,\n",
    "         dt_after=0.5,\n",
    "         dt_settle=0.5,\n",
    "         load=False,\n",
    "         nout_ini = 37,\n",
    "         filter_small=True,\n",
    "         min_mass_ratio = 0.05,\n",
    "         measure_delta_savefig=False,\n",
    "         find_merger_epoch_plot=False,\n",
    "         cdir=\"\"):\n",
    "\n",
    "    suffix = \"_{}_{}_{}_{}_{}_{}_{}\".format(dist_gal_scale_in,\n",
    "    dist_gal_scale_out,dt_before,dt_after,dt_settle,nout_ini,\n",
    "                                           min_mass_ratio)\n",
    "    if filter_small: \n",
    "        suffix = suffix + \"_filtered_\"\n",
    "\n",
    "    if load:\n",
    "        return pickle.load(open(\"main_prgs_final_augmented\" + suffix + \".pickle\", 'rb'))\n",
    "        \n",
    "    else:\n",
    "        mpgs = []\n",
    "        for cluster in clusters:\n",
    "            print(cluster)\n",
    "            wdir = base + cluster + '/'\n",
    "\n",
    "            # Serialize catalogs. -> Only main galaxies\n",
    "            # main galaxy list\n",
    "            alltrees = ctu.load_tree(wdir, is_gal=True)\n",
    "            ad = alltrees.data\n",
    "            tn = ad[ad['nout'] == nout_fi]\n",
    "\n",
    "            cat = load_cat(wdir + cdir + 'catalog' + str(nout_fi) + '.pickle')\n",
    "            #idx_all = [tn['id'][tn['Orig_halo_id'] == id_final][0] for id_final in cat['id']]\n",
    "            idx_all = cat['idx'][cat[\"idx\"] > 0].astype(int) # why idx are float???\n",
    "\n",
    "            mpg_tmp = []\n",
    "            for i, idx in enumerate(idx_all):\n",
    "                #print(i, idx)\n",
    "\n",
    "                mpg_tmp.append(MainPrg(ad, idx))\n",
    "            #    mpg_tmp =[MainPrg(ad, idx) for idx in idx_all]\n",
    "            for nout in range(nout_ini, nout_fi + 1):\n",
    "                cat = load_cat(wdir + cdir + 'catalog' + str(nout) + '.pickle')\n",
    "                for gal in mpg_tmp:\n",
    "                    gal.set_data(cat, nout)\n",
    "                    gal.cluster = int(cluster)\n",
    "        #        print(nout)\n",
    "            # get rid of galaxies with too short tree.\n",
    "            mpg_tmp = [gg for gg in mpg_tmp if sum(gg.data[\"reff\"] > 0) > minimum_good_snap]\n",
    "            for gal in mpg_tmp:\n",
    "                gal.fill_missing_data()\n",
    "                gal.clip_non_detection()\n",
    "                gal.smoothed_lambda_org = mma.smooth(gal.data[\"lambda_r\"], window_len=15)[:-1]\n",
    "                gal.smoothed_r = mma.smooth(gal.data[\"reff\"], window_len=15)[:-1]\n",
    "                gal.smoothed_lambda = mma.smooth(l_at_smoothed_r(gal, npix_per_reff=5), window_len=15)[:-1]\n",
    "\n",
    "            # save for each cluser\n",
    "            with open(wdir + \"main_prgs\" + suffix + \".pickle\", \"wb\") as f:\n",
    "                pickle.dump(mpg_tmp, f)    \n",
    "                \n",
    "            # Find_merger_epochs needs smoothed_r\n",
    "            find_merger_epochs(alltrees,\n",
    "                               idx_all,\n",
    "                               mpg_tmp,\n",
    "                               nout_ini=nout_ini,\n",
    "                               dist_gal_scale_in=dist_gal_scale_in,\n",
    "                               dist_gal_scale_out=dist_gal_scale_out,\n",
    "                               min_mass_ratio = min_mass_ratio,\n",
    "                               mass_ratio='early',\n",
    "                               verbose=False,\n",
    "                               do_plot=find_merger_epoch_plot,\n",
    "                               max_rgal=40,\n",
    "                               pdf_fname=str(cluster) + \"merger_ratio_epoch\" + suffix + \".pdf\")\n",
    "            \n",
    "\n",
    "            while len(mpg_tmp) > 0:\n",
    "                mpgs.append(mpg_tmp.pop())\n",
    "\n",
    "        if filter_small:\n",
    "            for gal in mpgs:\n",
    "                # Keep only the largest merger among multiple mergers\n",
    "                filter_small_mergers(gal.merger)\n",
    "\n",
    "        with open(\"main_prgs\" + suffix + \".pickle\", 'wb') as f:\n",
    "            mpgs.pop(2)\n",
    "            pickle.dump(mpgs, f)\n",
    "\n",
    "        measure_delta(mpgs,\n",
    "                      dt_before=dt_before,\n",
    "                      dt_after=dt_after,\n",
    "                      dt_settle=dt_settle,\n",
    "                      nout_ini=nout_ini,\n",
    "                      savefig=measure_delta_savefig,\n",
    "                      figname=\"figs/measure_delta\" + suffix)\n",
    "\n",
    "        Maj_min_acc_ratio(mpgs, major_ratio=4)\n",
    "\n",
    "        with open(\"main_prgs_final_augmented\" + suffix + \".pickle\", 'wb') as f:\n",
    "            pickle.dump(mpgs, f)\n",
    "    return mpgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01605\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './01605/GalaxyMaker/Trees/tree_0_0_0.dat'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/Work/pyclusterevol/tree/treemodule.py\u001b[0m in \u001b[0;36mload_tree\u001b[0;34m(wdir, is_gal, no_dump, load_ascii)\u001b[0m\n\u001b[1;32m    153\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m             \u001b[0malltrees\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwdir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mext_tree_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_gal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_gal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Loaded an extended tree\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './01605/GalaxyMaker/Trees/extended_tree.pickle'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-69332d69ca7e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mmeasure_delta_savefig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mfind_merger_epoch_plot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         cdir=cdir)# z = 3\n\u001b[0m",
      "\u001b[0;32m<ipython-input-2-bb384f356975>\u001b[0m in \u001b[0;36mbody\u001b[0;34m(clusters, dist_gal_scale_in, dist_gal_scale_out, dt_before, dt_after, dt_settle, load, nout_ini, filter_small, min_mass_ratio, measure_delta_savefig, find_merger_epoch_plot, cdir)\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0;31m# Serialize catalogs. -> Only main galaxies\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0;31m# main galaxy list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m             \u001b[0malltrees\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_gal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m             \u001b[0mad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malltrees\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0mtn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mad\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mad\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'nout'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mnout_fi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Work/pyclusterevol/tree/ctutils.py\u001b[0m in \u001b[0;36mload_tree\u001b[0;34m(wdir, is_gal, no_dump, load_ascii)\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0mUse\u001b[0m \u001b[0mtreemodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0minstead\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \"\"\"\n\u001b[0;32m---> 82\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtreemodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_gal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_gal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mno_dump\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mno_dump\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload_ascii\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mload_ascii\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Work/pyclusterevol/tree/treemodule.py\u001b[0m in \u001b[0;36mload_tree\u001b[0;34m(wdir, is_gal, no_dump, load_ascii)\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m             \u001b[0malltrees\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCTree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m             \u001b[0malltrees\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mwdir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtree_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'tree_0_0_0.dat'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m             \u001b[0;31m# Fix nout -----------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m             \u001b[0mnout_max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malltrees\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'nout'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Work/pyclusterevol/tree/treemodule.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self, filename)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_ascii\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_ascii\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Work/pyclusterevol/tree/treemodule.py\u001b[0m in \u001b[0;36m_load_ascii\u001b[0;34m(self, filename)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m180\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m                 \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './01605/GalaxyMaker/Trees/tree_0_0_0.dat'"
     ]
    }
   ],
   "source": [
    "mpgs = body(clusters,\n",
    "        dist_gal_scale_in=5,\n",
    "        dist_gal_scale_out=10,\n",
    "        dt_before=0.5,\n",
    "        dt_after=0.5,\n",
    "        dt_settle=0.5,\n",
    "        load=False,\n",
    "        nout_ini=37,\n",
    "        filter_small=True,\n",
    "        min_mass_ratio = 0.01, # 0.1로 테스트\n",
    "        measure_delta_savefig=False,\n",
    "        find_merger_epoch_plot=False,\n",
    "        cdir=cdir)# z = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/hoseung/Work/data/main_prgs_final_augmented_5_10_0.5_0.5_0.5_37_0.01_filtered_.pickle'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-886ade8db701>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mwdir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/home/hoseung/Work/data/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmpgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwdir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"main_prgs_final_augmented_5_10_0.5_0.5_0.5_37_0.01_filtered_.pickle\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/hoseung/Work/data/main_prgs_final_augmented_5_10_0.5_0.5_0.5_37_0.01_filtered_.pickle'"
     ]
    }
   ],
   "source": [
    "wdir = '/home/hoseung/Work/data/'\n",
    "\n",
    "mpgs = pickle.load(open(wdir + \"main_prgs_final_augmented_5_10_0.5_0.5_0.5_37_0.01_filtered_.pickle\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#def kde_sci(mpgs\n",
    "mstar_cut_hard = 5e9\n",
    "mcut = 3.3e10\n",
    "hist=False\n",
    "shade=False\n",
    "kde=True\n",
    "norm_hist=False\n",
    "detected=True\n",
    "maj_ratio=4\n",
    "excess=False\n",
    "fname=\"figs/MajMinNon_contribution_per_gal_\"\n",
    "img_scale=1.5\n",
    "\n",
    "\n",
    "fontsize_ticks = 6 * img_scale\n",
    "fontsize_tick_label = 8 * img_scale\n",
    "fontsize_legend = 5 * img_scale\n",
    "\n",
    "from matplotlib.ticker import NullFormatter\n",
    "\n",
    "\n",
    "l_dl_e, l_mr_e, l_mass_e = [], [], []\n",
    "s_dl_e, s_mr_e, s_mass_e = [], [], []\n",
    "l_dlt_g, l_dlo_g, l_dlM_g, l_dlm_g, l_mass_g = [], [], [], [], []\n",
    "s_dlt_g, s_dlo_g, s_dlM_g, s_dlm_g, s_mass_g = [], [], [], [], []\n",
    "\n",
    "M_changed = 0\n",
    "m_changed = 0\n",
    "no_merger_count = 0\n",
    "count = 0\n",
    "Maj_small = 0\n",
    "for i, gal in enumerate(mpgs):\n",
    "    mgal = gal.data[\"mstar\"][0]\n",
    "    if mgal > mstar_cut_hard:\n",
    "        delta_lambda_tot = np.average(gal.data['lambda_r'][:5]) - np.average(gal.data['lambda_r'][-5:])\n",
    "        delta_lambda_major = 0\n",
    "        delta_lambda_minor = 0\n",
    "\n",
    "        # Large\n",
    "        if mgal > mcut:\n",
    "            if hasattr(gal, \"merger\"):\n",
    "                if gal.merger is not None:\n",
    "                    l_dl_e.extend(gal.merger.delta_l)\n",
    "                    l_mr_e.extend(gal.merger.mr)\n",
    "                    for dl, mr in zip(gal.merger.delta_l, gal.merger.mr):\n",
    "                        if (mr < maj_ratio) and (dl > -1):\n",
    "                            delta_lambda_major = delta_lambda_major + dl\n",
    "                        if (mr > maj_ratio) and (dl > -1):\n",
    "                            delta_lambda_minor = delta_lambda_minor + dl\n",
    "\n",
    "                delta_lambda_other = delta_lambda_tot - delta_lambda_major - delta_lambda_minor\n",
    "                l_dlt_g.append(delta_lambda_tot)\n",
    "                l_dlo_g.append(delta_lambda_other)\n",
    "                l_dlM_g.append(delta_lambda_major)\n",
    "                l_dlm_g.append(delta_lambda_minor)\n",
    "        # small\n",
    "        else:\n",
    "            #s_mass_g.append(mgal)\n",
    "            if hasattr(gal, \"merger\"):\n",
    "                if gal.merger is not None:\n",
    "                    s_dl_e.extend(gal.merger.delta_l)\n",
    "                    s_mr_e.extend(gal.merger.mr)\n",
    "                    for dl, mr in zip(gal.merger.delta_l, gal.merger.mr):\n",
    "                        if (mr < maj_ratio) and (dl > -1):\n",
    "                            delta_lambda_major = delta_lambda_major + dl\n",
    "                        if (mr > maj_ratio) and (dl > -1):\n",
    "                            delta_lambda_minor = delta_lambda_minor + dl\n",
    "\n",
    "\n",
    "                delta_lambda_other = delta_lambda_tot - delta_lambda_major - delta_lambda_minor\n",
    "                s_dlt_g.append(delta_lambda_tot)\n",
    "                s_dlo_g.append(delta_lambda_other)\n",
    "                s_dlM_g.append(delta_lambda_major)\n",
    "                s_dlm_g.append(delta_lambda_minor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out a few galaxies with m < 5e9.\n",
    "mpgs = [gal for gal in mpgs if gal.data[\"mstar\"][0] > mstar_cut_hard]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dlt_all = np.array([gal.dlt for gal in mpgs])\n",
    "dlM_all = np.array([gal.dlM for gal in mpgs])\n",
    "dlm_all = np.array([gal.dlm for gal in mpgs])\n",
    "dlo_all = np.array([gal.dlo for gal in mpgs])\n",
    "mgals   = np.array([gal.data[\"mstar\"][0] for gal in mpgs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# All\n",
    "fig, ax = plt.subplots()\n",
    "ax.hist(dlt_all, histtype=\"step\", label=\"total\")\n",
    "ax.hist(dlM_all, histtype=\"step\", label=\"Major\")\n",
    "ax.hist(dlm_all, histtype=\"step\", label=\"minor\")\n",
    "ax.hist(dlo_all, histtype=\"step\", label=\"other\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.ticker import NullFormatter\n",
    "\n",
    "fig, axs = plt.subplots(2)\n",
    "draw_kdes(dlM_all,\n",
    "              dlm_all,\n",
    "              dlo_all,\n",
    "              dlt_all,\n",
    "              axs[0],\n",
    "              [1,2,3])\n",
    "\n",
    "draw_kdes(dlM_all[dlM_all !=0],\n",
    "              dlm_all[dlm_all !=0],\n",
    "              dlo_all,\n",
    "              dlt_all,\n",
    "              axs[1],\n",
    "              [1,2,3])\n",
    "\n",
    "axs[0].yaxis.set_major_formatter(NullFormatter())\n",
    "axs[0].set_ylabel(\"relative probability\", fontsize=fontsize_tick_label)\n",
    "axs[1].yaxis.set_major_formatter(NullFormatter())\n",
    "axs[1].set_ylabel(\"relative probability\", fontsize=fontsize_tick_label)\n",
    "axs[0].set_xlabel(r\"$\\Delta\\lambda\")\n",
    "axs[1].set_xlabel(r\"$\\Delta\\lambda\")\n",
    "axs[0].legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_kdes(dlM, dlm, dlo, dlt, ax\n",
    "                  , nevents = None\n",
    "                  , lw=1.5\n",
    "                  , cov=0.2):\n",
    "    \n",
    "    dM = kde_den(dlM, cov=cov)\n",
    "    dm = kde_den(dlm, cov=cov)\n",
    "    do = kde_den(dlo, cov=cov)\n",
    "    dtot = kde_den(dlt, cov=cov)\n",
    "\n",
    "    xs=np.linspace(-0.7,0.7,51)\n",
    "    dM_curve = dM(xs)\n",
    "    dm_curve = dm(xs)\n",
    "    do_curve = do(xs)\n",
    "    dtot_curve = dtot(xs)\n",
    "\n",
    "    nM = len(dlM)\n",
    "    nm = len(dlm)\n",
    "    no = len(dlo)\n",
    "    ntot = len(dlt)\n",
    "\n",
    "\n",
    "    Mlabel=\"Major\"\n",
    "    mlabel=\"Minor\"\n",
    "    olabel=\"non-merger\"\n",
    "    totlabel=\"Total\"\n",
    "    ax.plot(xs, dM_curve*nM/ntot, label=Mlabel, lw=lw, color=\"r\")\n",
    "    ax.plot(xs, dm_curve*nm/ntot, label=mlabel, lw=lw, color=\"g\")        \n",
    "    ax.plot(xs, do_curve*no/ntot, label=olabel, lw=lw, color=\"b\")\n",
    "    ax.plot(xs, dtot_curve, label=totlabel, lw=lw, color=\"black\")\n",
    "\n",
    "    ax.set_ylim([0, 1.15*ax.get_ylim()[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1222"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([dlM_all ==0]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "#draw_kdes(dlM_all[dlM_all !=0], dlm_all[dlm_all !=0], dlo_all, dlt_all, ax2, lw=1, cov=0.2)\n",
    "yp = 3.0\n",
    "#ax.plot([0,0],[0,yp-0.4], color=\"black\", lw=2)\n",
    "ax.scatter([0,0],[3.5,4], marker=\"*\", s=50)\n",
    "#ax.plot([0, 0.2], [4,4], color=\"black\", lw=1)\n",
    "#ax.plot([0, 0.2], [5,5], color=\"black\", lw=1)\n",
    "ax.text(0.03, 3.9, \"{} galaxies \\nwithout Major merger\".format(np.array([dlM_all ==0]).sum()))\n",
    "ax.text(0.03, 3.4, \"{} galaxies \\nwithout minor merger\".format(np.array([dlm_all ==0]).sum()))\n",
    "\n",
    "#ax.annotate('Without Major mergers', xy=(0,yp -0.4 ), xytext=(0.1,0.0),\n",
    "#            arrowprops={'arrowstyle': '-'}, va='center')\n",
    "#ax.annotate('Without Major mergers', xy=(0,yp + 1), xytext=(0.1,0.0),\n",
    "#            arrowprops={'arrowstyle': '-'}, va='center')\n",
    "#ax.arrow(0, 0, 0, yp + 0.4, head_width=0.05, lw=1.5, head_length=0.1, fc='k', ec='k', arrowstyle='-')\n",
    "\n",
    "#ax.arrow(0, yp + 0.4, 0, 1, head_width=0.05, lw=1.5, head_length=0.1, fc='k', ec='k')\n",
    "\n",
    "\n",
    "draw_kdes(dlM_all[dlM_all !=0], dlm_all[dlm_all !=0], dlo_all, dlt_all, ax, lw=2, cov=0.2)\n",
    "\n",
    "ax.set_ylim(0,4.5)\n",
    "ax.set_yticks([0,1,2,3])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, (ax, ax2) = plt.subplots(2, 1, sharex=True)\n",
    "\n",
    "plot_type=\"hist\"\n",
    "\n",
    "# plot the same data on both axes\n",
    "if plot_type==\"kde\":\n",
    "    draw_kdes(dlM_all[dlM_all !=0], dlm_all[dlm_all !=0], dlo_all, dlt_all, ax, lw=1, cov=0.2)\n",
    "    draw_kdes(dlM_all[dlM_all !=0], dlm_all[dlm_all !=0], dlo_all, dlt_all, ax2, lw=1, cov=0.2)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "elif plot_type==\"hist\":\n",
    "    nbins = 14\n",
    "    hrange = [-0.75, 0.65]\n",
    "    n, bins, patches = ax2.hist(dlt_all, histtype=\"step\", label=\"total\", bins=nbins, range=hrange)\n",
    "    ax2.hist(dlM_all[dlM_all !=0], histtype=\"step\", label=\"Major\", bins=nbins, range=hrange)\n",
    "    ax2.hist(dlm_all[dlm_all !=0], histtype=\"step\", label=\"minor\", bins=nbins, range=hrange)\n",
    "    ax2.hist(dlo_all, histtype=\"step\", label=\"other\", bins=nbins, range=hrange)\n",
    "\n",
    "    #ax2.hist(dlt_all, histtype=\"step\", label=\"total\")\n",
    "    n2, bins2, patches2 = ax.hist(dlM_all[dlM_all ==0], histtype=\"step\", label=\"Major\"\n",
    "                                  , bins=nbins, range=hrange)\n",
    "    ax.hist(dlm_all[dlm_all ==0], histtype=\"step\", label=\"minor\", bins=nbins, range=hrange)\n",
    "    #ax2.hist(dlo_all, histtype=\"step\", label=\"other\")\n",
    "    \n",
    "    ax.set_ylim(max(n) * 1.1, max(n2) * 1.1)  # outliers only\n",
    "    ax2.set_ylim(0, max(n) * 1.1)  # most of the data\n",
    "    \n",
    "    \n",
    "\n",
    "# zoom-in / limit the view to different portions of the data\n",
    "#ax.set_ylim(3., 30)  # outliers only\n",
    "#ax2.set_ylim(0, 3.)  # most of the data\n",
    "\n",
    "# hide the spines between ax and ax2\n",
    "ax.spines['bottom'].set_visible(False)\n",
    "ax2.spines['top'].set_visible(False)\n",
    "ax.xaxis.tick_top()\n",
    "ax.tick_params(labeltop='off')  # don't put tick labels at the top\n",
    "ax2.xaxis.tick_bottom()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.savefig(fname + \"{:.1f}_11.png\".format(np.log10(mcut)), dpi=200, bbox_inches=\"tight\")\n",
    "plt.savefig(fname + \"{:.1f}_11.pdf\".format(np.log10(mcut)), bbox_inches='tight') # eps does NOT support transparency!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
