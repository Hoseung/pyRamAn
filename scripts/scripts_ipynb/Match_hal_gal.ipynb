{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Moster plot for as many galaxies as possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Dummy():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "def radial_profile_cut(star,\n",
    "                       den_lim=2e6, den_lim2=5e6,\n",
    "                       mag_lim=25, nbins=100, rmax=50, dr=0.5,\n",
    "                       debug=False):\n",
    "    # 2D photometry. (if rotated towards +y, then use x and z)\n",
    "    # now assuming +z alignment. \n",
    "    xx = star['x']\n",
    "    yy = star['y']\n",
    "    zz = star['z']\n",
    "    vx = star['vx']\n",
    "    vy = star['vy']\n",
    "    vz = star['vz']\n",
    "    mm = star['m']\n",
    "    \n",
    "    meta = Dummy()\n",
    "    \n",
    "    rr = np.sqrt(np.square(xx) + np.square(yy))# in kpc unit\n",
    "    if debug:\n",
    "        print(min(rr), max(rr), min(xx), max(xx))\n",
    "\n",
    "    # Account for weights.\n",
    "    i_sort = np.argsort(rr)\n",
    "    r_sorted = rr[i_sort]\n",
    "    m_sorted = mm[i_sort]\n",
    "\n",
    "    rmax = min([np.max(rr), rmax])\n",
    "    nbins = int(rmax/dr)\n",
    "\n",
    "    frequency, bins = np.histogram(r_sorted, bins = nbins, range=[0, rmax])\n",
    "    bin_centers = bins[:-1] + 0.5 * dr # remove the rightmost boundary.\n",
    "\n",
    "    m_radial = np.zeros(nbins)\n",
    "    ibins = np.concatenate((np.zeros(1), np.cumsum(frequency)))\n",
    "\n",
    "    i_r_cut1 = nbins -1 # Maximum value\n",
    "    # on rare occasions, a galaxy's stellar surface density\n",
    "    # never crosses the density limit. Then i_r_cut1 = last index.\n",
    "    for i in range(nbins):\n",
    "        m_radial[i] = np.sum(m_sorted[ibins[i]:ibins[i+1]])\n",
    "        if (m_radial[i]/(2 * np.pi * bin_centers[i] * dr)) < den_lim:\n",
    "            i_r_cut1 = i-1\n",
    "            break\n",
    "    #i_r_cut2= np.argmax(m_radial/(2 * np.pi * bin_centers * dr) < den_lim2)\n",
    "    # If for some reason central region is less dense,\n",
    "    # profile can end at the first index.\n",
    "    # Instead coming from backward, search for the point the opposite condition satisfied.\n",
    "    den_radial_inverse = m_radial[::-1]/(2 * np.pi * bin_centers[::-1] * dr)\n",
    "    \n",
    "    if max(den_radial_inverse) < 1.5 * den_lim2:\n",
    "        #print(\"Not dense enough\")\n",
    "        return False\n",
    "    i_r_cut2=len(m_radial) - np.argmax(den_radial_inverse > den_lim2) -1\n",
    "    if debug:\n",
    "        print(\"[galaxy.Galaxy.radial_profile_cut] m_radial \\n\", m_radial)\n",
    "        print(\"[galaxy.Galaxy.radial_profile_cut] den_radial_inverse \\n\", den_radial_inverse)\n",
    "        print(\"[galaxy.Galaxy.radial_profile_cut] i_r_cut2\", i_r_cut2)\n",
    "\n",
    "    mtot2 = sum(m_radial[:i_r_cut2])\n",
    "    mtot1 = sum(m_radial[:i_r_cut1])\n",
    "    i_reff2 = np.argmax(np.cumsum(m_sorted) > (0.5*mtot2))\n",
    "    i_reff1 = np.argmax(np.cumsum(m_sorted) > (0.5*mtot1))\n",
    "    meta.reff2 = r_sorted[i_reff2]\n",
    "    meta.reff  = r_sorted[i_reff1]\n",
    "    #print(bin_centers, i_r_cut2, m_radial)\n",
    "    meta.rgal2 = max([bin_centers[i_r_cut2],4*meta.reff2])\n",
    "    meta.rgal  = max([bin_centers[i_r_cut1],4*meta.reff])#bin_centers[i_r_cut1]\n",
    "\n",
    "    if debug: print(\"[galaxy.Galaxy.radial_profile_cut] mtot, mtot2\", mtot1, mtot2)\n",
    "\n",
    "    i_close = i_sort[:np.argmax(np.cumsum(m_sorted) > (0.2*mtot2))] # 20% closest particles\n",
    "#        i_close = np.argsort(rr)[:min([i_reff1])]\n",
    "#        i_close = i_sort[:min([i_reff1])]\n",
    "\n",
    "    meta.mtot = mtot2\n",
    "\n",
    "    meta.vxc = np.average(vx[i_close])\n",
    "    meta.vyc = np.average(vy[i_close])\n",
    "    meta.vzc = np.average(vz[i_close])\n",
    "\n",
    "    return meta\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def distv3d(halo, center):\n",
    "    norm = np.sqrt(np.square(center['vx'] - halo['vx']) + \n",
    "                   np.square(center['vy'] - halo['vy']) + \n",
    "                   np.square(center['vz'] - halo['vz']))\n",
    "    return norm\n",
    "\n",
    "def distv(halo, center):\n",
    "    norm = center['vx'] - halo['vx'] + \\\n",
    "           center['vy'] - halo['vy'] + \\\n",
    "           center['vz'] - halo['vz']\n",
    "    return norm\n",
    "\n",
    "\n",
    "def dist(halo, center):\n",
    "    norm = np.sqrt(np.square(center['x'] - halo['x']) + \n",
    "                   np.square(center['y'] - halo['y']) + \n",
    "                   np.square(center['z'] - halo['z']))\n",
    "    return norm \n",
    "\n",
    "def match_gal_hal_tree(gt, ht):\n",
    "    nout = 187\n",
    "    dt = 3 # compare progenitor at dt ago.\n",
    "    \n",
    "    gal_now = gt[gt[\"nout\"]==nout]\n",
    "    hal_now = ht[ht[\"nout\"]==nout]\n",
    "    \n",
    "    gal_before = gt[gt[\"nout\"]==nout-dt]\n",
    "    hal_before = ht[ht[\"nout\"]==nout-dt]    \n",
    "    \n",
    "    dominant = 0.1 # matched one should have less error by this amount or smaller \n",
    "                    # compared to the second best matched one.\n",
    "    \n",
    "    abs_tol_pos = 5e-5 # Position absolute tolerance [in code unit?]\n",
    "    abs_tol_vel = 10   # velocity absolute tolerance [in kms?]\n",
    "    \n",
    "    for gal in gal_now:\n",
    "        dd = dist(hal_now, gal)\n",
    "        vv = distv(hal_now, gal)\n",
    "        d_sort = np.argsort(dd)\n",
    "        v_sort = np.argsort(vv)\n",
    "        if (dd[d_sort[0]] < dominant * dd[d_sort[1]]) and (dd[d_sort[0]] < abs_tol_pos) and \\\n",
    "        (vv[v_sort[0]] < dominant * vv[v_sort[1]]) and (vv[v_sort[0]] < abs_tol_vel):\n",
    "            gal['hosthalo'] = allhal.data['id'][d_sort[0]]\n",
    "            i0.append(i)\n",
    "            newhals[i] = allhal.data[d_sort[0]]\n",
    "        else:\n",
    "            atree = tree.atree(gt)\n",
    "            prg = atree[dt]\n",
    "            for gal2 in gal_before:\n",
    "                dd = dist(hal_now, gal2)\n",
    "                vv = distv(hal_now, gal2)\n",
    "                d_sort = np.argsort(dd)\n",
    "                v_sort = np.argsort(vv)\n",
    "            \n",
    "                \n",
    "\n",
    "def get_comp_dist(hal_now, gal, nreturn=5):\n",
    "    dd = dist(hal_now, gal)\n",
    "    vv = distv(hal_now, gal)\n",
    "    dd_q1 = np.percentile(dd,10)\n",
    "    vv_q1 = np.percentile(vv,10)\n",
    "    comp_dist = np.sqrt(np.square(dd/dd_q1) + np.square(vv/vv_q1))\n",
    "    ind_sort = np.argsort(comp_dist)\n",
    "    return comp_dist[ind_sort[:nreturn]], hal_now[ind_sort[:nreturn]]\n",
    "\n",
    "def before_to_now(htdata, hals, dt):\n",
    "    out = []\n",
    "    for hal in hals:\n",
    "        atree_hal = ctu.extract_main_tree_full(htdata, idx=hal['id'])\n",
    "        out.append(atree_hal[hal['nout'] + dt])\n",
    "    return out\n",
    "\n",
    "def now_to_before(htdata, hals, dt):\n",
    "    \"\"\"\n",
    "    progenitor of current halos.\n",
    "    If does not exist, give -1\n",
    "    \"\"\"\n",
    "    out =[]\n",
    "    for hal in hals:\n",
    "        idx = hal['id']\n",
    "        try:\n",
    "            #smalldata = htdata[htdata['tree_root_id'] == idx]\n",
    "            #print(smalldata)\n",
    "            atree_hal = ctu.extract_main_tree(htdata, idx=idx)\n",
    "            out.append(atree_hal[dt])\n",
    "        except:\n",
    "            print(\"broken tree\")\n",
    "            out.append(-1)        \n",
    "            \n",
    "    return np.array(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def measure_mstar_mhal(cluster, \n",
    "                       dominant = 0.4,\n",
    "                       abs_tol_pos = 1e-2,\n",
    "                       abs_tol_vel = 100,\n",
    "                       nout_fi = 187,\n",
    "                       dts = [3,5]):\n",
    "    wdir = \"./\" + cluster + '/' \n",
    "    info = Info(187, base=wdir)\n",
    "\n",
    "    gt = tmo.load_tree(wdir, is_gal=True)\n",
    "    ht = tmo.load_tree(wdir, is_gal=False)\n",
    "\n",
    "    gal_now = gt.data[gt.data[\"nout\"]==nout_fi]\n",
    "    hal_now = ht.data[ht.data[\"nout\"]==nout_fi]\n",
    "\n",
    "    comp_dists=[]\n",
    "    gal_ok = ctu.check_tree_complete(gt.data, nout_fi - max(dts), nout_fi, gal_now[\"id\"], idx=True)\n",
    "\n",
    "    #comp_dists.append(comp_dist)\n",
    "\n",
    "    hal_now = ht.data[ht.data[\"nout\"]==nout_fi]\n",
    "\n",
    "    hal_3 = ht.data[ht.data[\"nout\"]==nout_fi - 3]\n",
    "    hal_5 = ht.data[ht.data[\"nout\"]==nout_fi - 5]\n",
    "    hal_this_list = [hal_3, hal_5]\n",
    "\n",
    "    result = []\n",
    "    mhal_result = []\n",
    "    dist_error = []\n",
    "\n",
    "    i_gal_ok = []\n",
    "    ok_gals = []\n",
    "    for igal, gal in enumerate(gal_now):\n",
    "        if gal['id'] not in gal_ok:\n",
    "            continue\n",
    "        else:\n",
    "            i_gal_ok.append(igal)\n",
    "            nreturn = 10\n",
    "            comp_dist, good_hals_now = get_comp_dist(hal_now, gal, nreturn=10)\n",
    "            # halo must be more massive than the galaxy\n",
    "            matches=[]\n",
    "            good_hals_now = good_hals_now[good_hals_now[\"m\"] > gal[\"m\"]]\n",
    "\n",
    "            atree = ctu.extract_main_tree(gt.data, idx=gal['id'])\n",
    "\n",
    "            matches.append(good_hals_now[\"Orig_halo_id\"])\n",
    "            for idt, dt in enumerate([3,5]):\n",
    "                hal_this = hal_this_list[idt]\n",
    "                gal_this = atree[dt]\n",
    "                comp_dist_this, good_hals_this = get_comp_dist(hal_this, gal_this, nreturn=10)\n",
    "                good_hals_this = good_hals_this[good_hals_this[\"m\"] > gal_this[\"m\"]]\n",
    "\n",
    "                good_hals_prgsthis = now_to_before(ht.data, good_hals_now, dt)\n",
    "\n",
    "                i_good = []\n",
    "                i_good_prg=[]\n",
    "                for i,ghthis in enumerate(good_hals_this['Orig_halo_id']):\n",
    "                    if ghthis in good_hals_prgsthis[\"Orig_halo_id\"]:\n",
    "                        #i_good_prg.append(i)\n",
    "                        i_good.append(np.where(good_hals_prgsthis[\"Orig_halo_id\"] == ghthis)[0][0])\n",
    "\n",
    "                matches.append(good_hals_now[\"Orig_halo_id\"][i_good])\n",
    "            try:\n",
    "                if matches[0][0] == matches[1][0] == matches[2][0]:\n",
    "                    matched = matches[0][0]\n",
    "                    #print(matched)\n",
    "                    #result.append(matched)\n",
    "                    result.append(good_hals_now[0])\n",
    "                    ok_gals.append(gal)\n",
    "                    #mhal_result.append(good_hals_now[\"mvir\"][0])\n",
    "                    #dist_error.append(comp_dist_this[0])\n",
    "                #else:\n",
    "                    #print(\"Not good\")\n",
    "                    #result.append(-1)\n",
    "                    #mhal_result.append(-1)\n",
    "                    #dist_error.append(-1)\n",
    "            except:\n",
    "                pass\n",
    "                #print(\"Not good\")\n",
    "                #result.append(-1)\n",
    "                #mhal_result.append(-1)\n",
    "                #dist_error.append(-1)\n",
    "\n",
    "\n",
    "    result = np.array(result)\n",
    "    ok_gals = np.array(ok_gals)\n",
    "    #mhal_result = np.array(mhal_result)\n",
    "    #dist_error = np.array(dist_error)\n",
    "\n",
    "    print( \"Out of {} galaxies, matched {} galaxies.\".format(len(gal_now), len(result)))\n",
    "\n",
    "    # filter duplicates\n",
    "    unq, unq_idx, unq_cnt = np.unique(result[\"Orig_halo_id\"], return_inverse=True, return_counts=True)\n",
    "    cnt_mask = unq_cnt > 1\n",
    "    cnt_idx, = np.nonzero(cnt_mask)\n",
    "    idx_mask = np.in1d(unq_idx, cnt_idx)\n",
    "    idx_idx, = np.nonzero(idx_mask)\n",
    "    srt_idx = np.argsort(unq_idx[idx_mask])\n",
    "    dup_idx = np.split(idx_idx[srt_idx], np.cumsum(unq_cnt[cnt_mask])[:-1])\n",
    "\n",
    "    # Remove smaller duplicates and leave the largest galaxy.\n",
    "    remove_inds=[]\n",
    "    for dup in dup_idx:\n",
    "        ind_all = np.full(len(dup), True, dtype=bool)\n",
    "        #print(ind_all)\n",
    "        imax = np.argmax(ok_gals[\"m\"][dup])\n",
    "        ind_all[imax] = False\n",
    "        remove_inds.extend(dup[ind_all])\n",
    "\n",
    "    remove_inds = np.array(remove_inds)\n",
    "    inds_ok = np.full(len(result), True, dtype=bool)\n",
    "    inds_ok[remove_inds] = False\n",
    "\n",
    "\n",
    "    # load each galaxy and measure stellar mass\n",
    "    good_gal = ok_gals[\"Orig_halo_id\"][inds_ok]\n",
    "    mhal_result = result[\"mvir\"][inds_ok]\n",
    "\n",
    "    mstar = []\n",
    "    mhal = []\n",
    "\n",
    "    for mhal_this, idgal in zip(mhal_result, good_gal):\n",
    "        gal = Gal(nout_fi, idgal, wdir=wdir, load=False)\n",
    "        gal.load(cell=\"none\", dm=\"none\")\n",
    "        # There are only two options: gm or raw. \n",
    "        # Others are ignored.\n",
    "\n",
    "        gal.star['x'] -= gal.header['xg'][0]\n",
    "        gal.star['y'] -= gal.header['xg'][1]\n",
    "        gal.star['z'] -= gal.header['xg'][2]\n",
    "\n",
    "        # rescale\n",
    "        gal.star['x'] *= 1e3\n",
    "        gal.star['y'] *= 1e3\n",
    "        gal.star['z'] *= 1e3\n",
    "        gal.star['m'] *=1e11\n",
    "        gal.meta = radial_profile_cut(gal.star)\n",
    "        if gal.meta is not False:\n",
    "            mstar.append(gal.meta.mtot)\n",
    "            mhal.append(mhal_this)\n",
    "        else:\n",
    "            pass\n",
    "    \n",
    "    return mstar, mhal\n",
    "\n",
    "\n",
    "\n",
    "    # correct halo mass for extract substructure mass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded an extended tree\n",
      "Loaded an extended tree\n",
      "Out of 125 galaxies, failed to match 95 galaxies.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hoseung/mypy/lib/python3.5/site-packages/ipykernel/__main__.py:43: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not dense enough\n",
      "Not dense enough\n",
      "Not dense enough\n",
      "Not dense enough\n",
      "Not dense enough\n",
      "Not dense enough\n",
      "Not dense enough\n",
      "Not dense enough\n",
      "Not dense enough\n",
      "Not dense enough\n",
      "Not dense enough\n",
      "Not dense enough\n",
      "Not dense enough\n",
      "Not dense enough\n",
      "Not dense enough\n",
      "Not dense enough\n",
      "Not dense enough\n",
      "Not dense enough\n",
      "Not dense enough\n",
      "Not dense enough\n",
      "Not dense enough\n",
      "Not dense enough\n",
      "Not dense enough\n",
      "Not dense enough\n",
      "Not dense enough\n",
      "Not dense enough\n",
      "Not dense enough\n",
      "Not dense enough\n",
      "Not dense enough\n",
      "Not dense enough\n",
      "Not dense enough\n",
      "Not dense enough\n"
     ]
    }
   ],
   "source": [
    "from tree import ctutils as ctu\n",
    "\n",
    "from tree import halomodule as hmo\n",
    "from load.info import Info\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "matplotlib.use(\"Qt4Agg\")\n",
    "import matplotlib.pyplot as plt\n",
    "import tree.treemodule as tmo\n",
    "from load.rd_GM import Gal\n",
    "\n",
    "# Load galaxy catalog\n",
    "# and halo catalog\n",
    "clusters = [\"29172\"]\n",
    "#nout_fi = 187\n",
    "\n",
    "#dominant = 0.4 # matched one should have less error by this amount or smaller \n",
    "                # compared to the second best matched one.\n",
    "\n",
    "#abs_tol_pos = 1e-2 # Position absolute tolerance [in Mpc]\n",
    "#abs_tol_vel = 100   # velocity absolute tolerance [in kms?]\n",
    "\n",
    "dts = [3,5]\n",
    "\n",
    "mstar_all = []\n",
    "mhal_all = []\n",
    "\n",
    "for cluster in clusters:\n",
    "    mstar_t, mhal_t = measure_mstar_mhal(cluster, \n",
    "                                           dominant = 0.4,\n",
    "                                           abs_tol_pos = 1e-2,\n",
    "                                           abs_tol_vel = 100,\n",
    "                                           nout_fi = 187,\n",
    "                                           dts = dts)\n",
    "    mstar_all.extend(mstar_t)\n",
    "    mhal_all.extend(mhal_t)\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
