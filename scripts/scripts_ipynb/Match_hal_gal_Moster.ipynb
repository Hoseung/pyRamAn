{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Moster plot for as many galaxies as possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Dummy():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "def radial_profile_cut(star,\n",
    "                       den_lim=2e6, den_lim2=5e6,\n",
    "                       mag_lim=25, nbins=100, rmax=50, dr=0.5,\n",
    "                       debug=False):\n",
    "    # 2D photometry. (if rotated towards +y, then use x and z)\n",
    "    # now assuming +z alignment. \n",
    "    xx = star['x']\n",
    "    yy = star['y']\n",
    "    zz = star['z']\n",
    "    vx = star['vx']\n",
    "    vy = star['vy']\n",
    "    vz = star['vz']\n",
    "    mm = star['m']\n",
    "    \n",
    "    meta = Dummy()\n",
    "    \n",
    "    rr = np.sqrt(np.square(xx) + np.square(yy))# in kpc unit\n",
    "    if debug:\n",
    "        print(min(rr), max(rr), min(xx), max(xx))\n",
    "\n",
    "    # Account for weights.\n",
    "    i_sort = np.argsort(rr)\n",
    "    r_sorted = rr[i_sort]\n",
    "    m_sorted = mm[i_sort]\n",
    "\n",
    "    rmax = min([np.max(rr), rmax])\n",
    "    nbins = int(rmax/dr)\n",
    "\n",
    "    frequency, bins = np.histogram(r_sorted, bins = nbins, range=[0, rmax])\n",
    "    bin_centers = bins[:-1] + 0.5 * dr # remove the rightmost boundary.\n",
    "\n",
    "    m_radial = np.zeros(nbins)\n",
    "    ibins = np.concatenate((np.zeros(1), np.cumsum(frequency)))\n",
    "\n",
    "    i_r_cut1 = nbins -1 # Maximum value\n",
    "    # on rare occasions, a galaxy's stellar surface density\n",
    "    # never crosses the density limit. Then i_r_cut1 = last index.\n",
    "    for i in range(nbins):\n",
    "        m_radial[i] = np.sum(m_sorted[ibins[i]:ibins[i+1]])\n",
    "        if (m_radial[i]/(2 * np.pi * bin_centers[i] * dr)) < den_lim:\n",
    "            i_r_cut1 = i-1\n",
    "            break\n",
    "    #i_r_cut2= np.argmax(m_radial/(2 * np.pi * bin_centers * dr) < den_lim2)\n",
    "    # If for some reason central region is less dense,\n",
    "    # profile can end at the first index.\n",
    "    # Instead coming from backward, search for the point the opposite condition satisfied.\n",
    "    den_radial_inverse = m_radial[::-1]/(2 * np.pi * bin_centers[::-1] * dr)\n",
    "    \n",
    "    if max(den_radial_inverse) < 1.5 * den_lim2:\n",
    "        #print(\"Not dense enough\")\n",
    "        return False\n",
    "    i_r_cut2=len(m_radial) - np.argmax(den_radial_inverse > den_lim2) -1\n",
    "    if debug:\n",
    "        print(\"[galaxy.Galaxy.radial_profile_cut] m_radial \\n\", m_radial)\n",
    "        print(\"[galaxy.Galaxy.radial_profile_cut] den_radial_inverse \\n\", den_radial_inverse)\n",
    "        print(\"[galaxy.Galaxy.radial_profile_cut] i_r_cut2\", i_r_cut2)\n",
    "\n",
    "    mtot2 = sum(m_radial[:i_r_cut2])\n",
    "    mtot1 = sum(m_radial[:i_r_cut1])\n",
    "    i_reff2 = np.argmax(np.cumsum(m_sorted) > (0.5*mtot2))\n",
    "    i_reff1 = np.argmax(np.cumsum(m_sorted) > (0.5*mtot1))\n",
    "    meta.reff2 = r_sorted[i_reff2]\n",
    "    meta.reff  = r_sorted[i_reff1]\n",
    "    #print(bin_centers, i_r_cut2, m_radial)\n",
    "    meta.rgal2 = max([bin_centers[i_r_cut2],4*meta.reff2])\n",
    "    meta.rgal  = max([bin_centers[i_r_cut1],4*meta.reff])#bin_centers[i_r_cut1]\n",
    "\n",
    "    if debug: print(\"[galaxy.Galaxy.radial_profile_cut] mtot, mtot2\", mtot1, mtot2)\n",
    "\n",
    "    i_close = i_sort[:np.argmax(np.cumsum(m_sorted) > (0.2*mtot2))] # 20% closest particles\n",
    "#        i_close = np.argsort(rr)[:min([i_reff1])]\n",
    "#        i_close = i_sort[:min([i_reff1])]\n",
    "\n",
    "    meta.mtot = mtot2\n",
    "\n",
    "    meta.vxc = np.average(vx[i_close])\n",
    "    meta.vyc = np.average(vy[i_close])\n",
    "    meta.vzc = np.average(vz[i_close])\n",
    "\n",
    "    return meta\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def distv3d(halo, center):\n",
    "    norm = np.sqrt(np.square(center['vx'] - halo['vx']) + \n",
    "                   np.square(center['vy'] - halo['vy']) + \n",
    "                   np.square(center['vz'] - halo['vz']))\n",
    "    return norm\n",
    "\n",
    "def distv(halo, center):\n",
    "    norm = center['vx'] - halo['vx'] + \\\n",
    "           center['vy'] - halo['vy'] + \\\n",
    "           center['vz'] - halo['vz']\n",
    "    return norm\n",
    "\n",
    "\n",
    "def dist(halo, center):\n",
    "    norm = np.sqrt(np.square(center['x'] - halo['x']) + \n",
    "                   np.square(center['y'] - halo['y']) + \n",
    "                   np.square(center['z'] - halo['z']))\n",
    "    return norm \n",
    "\n",
    "def match_gal_hal_tree(gt, ht):\n",
    "    nout = 187\n",
    "    dt = 3 # compare progenitor at dt ago.\n",
    "    \n",
    "    gal_now = gt[gt[\"nout\"]==nout]\n",
    "    hal_now = ht[ht[\"nout\"]==nout]\n",
    "    \n",
    "    gal_before = gt[gt[\"nout\"]==nout-dt]\n",
    "    hal_before = ht[ht[\"nout\"]==nout-dt]    \n",
    "    \n",
    "    dominant = 0.1 # matched one should have less error by this amount or smaller \n",
    "                    # compared to the second best matched one.\n",
    "    \n",
    "    abs_tol_pos = 5e-5 # Position absolute tolerance [in code unit?]\n",
    "    abs_tol_vel = 10   # velocity absolute tolerance [in kms?]\n",
    "    \n",
    "    for gal in gal_now:\n",
    "        dd = dist(hal_now, gal)\n",
    "        vv = distv(hal_now, gal)\n",
    "        d_sort = np.argsort(dd)\n",
    "        v_sort = np.argsort(vv)\n",
    "        if (dd[d_sort[0]] < dominant * dd[d_sort[1]]) and (dd[d_sort[0]] < abs_tol_pos) and \\\n",
    "        (vv[v_sort[0]] < dominant * vv[v_sort[1]]) and (vv[v_sort[0]] < abs_tol_vel):\n",
    "            gal['hosthalo'] = allhal.data['id'][d_sort[0]]\n",
    "            i0.append(i)\n",
    "            newhals[i] = allhal.data[d_sort[0]]\n",
    "        else:\n",
    "            atree = tree.atree(gt)\n",
    "            prg = atree[dt]\n",
    "            for gal2 in gal_before:\n",
    "                dd = dist(hal_now, gal2)\n",
    "                vv = distv(hal_now, gal2)\n",
    "                d_sort = np.argsort(dd)\n",
    "                v_sort = np.argsort(vv)\n",
    "            \n",
    "                \n",
    "\n",
    "def get_comp_dist(hal_now, gal, nreturn=5):\n",
    "    \"\"\"Measure 6D distance and return Nreturn closest entries\"\"\"\n",
    "    dd = dist(hal_now, gal)\n",
    "    vv = distv(hal_now, gal)\n",
    "    dd_q1 = np.percentile(dd,10)\n",
    "    vv_q1 = np.percentile(vv,10)\n",
    "    comp_dist = np.sqrt(np.square(dd/dd_q1) + np.square(vv/vv_q1))\n",
    "    ind_sort = np.argsort(comp_dist)\n",
    "    return comp_dist[ind_sort[:nreturn]], hal_now[ind_sort[:nreturn]]\n",
    "\n",
    "def before_to_now(htdata, hals, dt):\n",
    "    out = []\n",
    "    for hal in hals:\n",
    "        atree_hal = ctu.extract_main_tree_full(htdata, idx=hal['id'])\n",
    "        out.append(atree_hal[hal['nout'] + dt])\n",
    "    return out\n",
    "\n",
    "def now_to_before(htdata, hals, dt):\n",
    "    \"\"\"\n",
    "    progenitor of current halos.\n",
    "    If does not exist, give -1\n",
    "    \"\"\"\n",
    "    out =[]\n",
    "    for hal in hals:\n",
    "        idx = hal['id']\n",
    "        try:\n",
    "            #smalldata = htdata[htdata['tree_root_id'] == idx]\n",
    "            #print(smalldata)\n",
    "            atree_hal = ctu.extract_main_tree(htdata, idx=idx)\n",
    "            out.append(atree_hal[dt])\n",
    "        except:\n",
    "            print(\"broken tree\")\n",
    "            out.append(-1)        \n",
    "            \n",
    "    return np.array(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def gal_hal_pair(cluster, gt, ht,\n",
    "                    dominant = 0.4,\n",
    "                    abs_tol_pos = 1e-2,\n",
    "                    abs_tol_vel = 100,\n",
    "                    nout_fi = 187,\n",
    "                    dts = [3,5],\n",
    "                    wdir='./'):\n",
    "    info = Info(187, base=wdir)\n",
    "\n",
    "    gal_now = gt.data[gt.data[\"nout\"]==nout_fi]\n",
    "    hal_now = ht.data[ht.data[\"nout\"]==nout_fi]\n",
    "\n",
    "    # exclude galaxies with too short tree.\n",
    "    gal_ok = ctu.check_tree_complete(gt.data,\n",
    "                                     nout_fi - max(dts),\n",
    "                                     nout_fi, gal_now[\"id\"],\n",
    "                                     idx=True)\n",
    "\n",
    "    hal_3 = ht.data[ht.data[\"nout\"]==nout_fi - 3]\n",
    "    hal_5 = ht.data[ht.data[\"nout\"]==nout_fi - 5]\n",
    "    hal_this_list = [hal_3, hal_5]\n",
    "    \n",
    "    comp_dists=[]\n",
    "    #comp_dists.append(comp_dist)\n",
    "    result = []\n",
    "    mhal_result = []\n",
    "    dist_error = []\n",
    "\n",
    "    i_gal_ok = []\n",
    "    ok_gals = []\n",
    "    for igal, gal in enumerate(gal_now):\n",
    "        if gal['id'] not in gal_ok:\n",
    "            print(\"ID: {},  Too short tree\".format(gal[\"id\"]))\n",
    "            continue\n",
    "        else:\n",
    "            i_gal_ok.append(igal)\n",
    "            \n",
    "            # Halo descendant - galaxy descendant\n",
    "            comp_dist, good_hals_now = get_comp_dist(hal_now, gal, nreturn=5)\n",
    "            # halo must be more massive than the galaxy\n",
    "            matches=[]\n",
    "            good_hals_now = good_hals_now[good_hals_now[\"m\"] > gal[\"m\"]]\n",
    "\n",
    "            atree = ctu.extract_main_tree(gt.data, idx=gal['id'])\n",
    "\n",
    "            matches.append(good_hals_now[\"Orig_halo_id\"])\n",
    "            \n",
    "            # Halo progenitor - galaxy progenitor\n",
    "            for idt, dt in enumerate([3,5]):\n",
    "                hal_this = hal_this_list[idt]\n",
    "                gal_this = atree[dt]\n",
    "                \n",
    "                # 10 closest galaxies.\n",
    "                comp_dist_this, good_hals_this = get_comp_dist(hal_this, gal_this, nreturn=10)\n",
    "                # halo must be more massive than the galaxy.\n",
    "                good_hals_this = good_hals_this[good_hals_this[\"m\"] > gal_this[\"m\"]]\n",
    "                \n",
    "                # progenitors of the 'good' halo candidates\n",
    "                good_hals_prgsthis = now_to_before(ht.data, good_hals_now, dt)\n",
    "                \n",
    "                i_good = []\n",
    "                i_good_prg=[]\n",
    "                for i, ghthis in enumerate(good_hals_this['Orig_halo_id']):\n",
    "                    # Why halo id at now and before are compared?? \n",
    "                    if ghthis in good_hals_prgsthis[\"Orig_halo_id\"]:\n",
    "                        #i_good_prg.append(i)\n",
    "                        i_good.append(np.where(good_hals_prgsthis[\"Orig_halo_id\"] == ghthis)[0][0])\n",
    "\n",
    "                matches.append(good_hals_now[\"Orig_halo_id\"][i_good])\n",
    "            try:\n",
    "                if matches[0][0] == matches[1][0] == matches[2][0]:\n",
    "                    matched = matches[0][0]\n",
    "                    result.append(good_hals_now[0])\n",
    "                    ok_gals.append(gal)\n",
    "\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "\n",
    "    result = np.array(result)\n",
    "    ok_gals = np.array(ok_gals)\n",
    "\n",
    "    print( \"Out of {} galaxies, matched {} galaxies.\".format(len(gal_now), len(result)))\n",
    "\n",
    "    # filter duplicates\n",
    "    unq, unq_idx, unq_cnt = np.unique(result[\"Orig_halo_id\"], return_inverse=True, return_counts=True)\n",
    "    cnt_mask = unq_cnt > 1\n",
    "    cnt_idx, = np.nonzero(cnt_mask)\n",
    "    idx_mask = np.in1d(unq_idx, cnt_idx)\n",
    "    idx_idx, = np.nonzero(idx_mask)\n",
    "    srt_idx = np.argsort(unq_idx[idx_mask])\n",
    "    dup_idx = np.split(idx_idx[srt_idx], np.cumsum(unq_cnt[cnt_mask])[:-1])\n",
    "\n",
    "    # Remove smaller duplicates and leave the largest galaxy.\n",
    "    remove_inds=[]\n",
    "    for dup in dup_idx:\n",
    "        ind_all = np.full(len(dup), True, dtype=bool)\n",
    "        #print(ind_all)\n",
    "        imax = np.argmax(ok_gals[\"m\"][dup])\n",
    "        ind_all[imax] = False\n",
    "        remove_inds.extend(dup[ind_all])\n",
    "\n",
    "    remove_inds = np.array(remove_inds)\n",
    "    inds_ok = np.full(len(result), True, dtype=bool)\n",
    "    inds_ok[remove_inds] = False\n",
    "\n",
    "\n",
    "    # load each galaxy and measure stellar mass\n",
    "    return result[inds_ok], ok_gals[inds_ok]\n",
    "    \n",
    "    \n",
    "def measure_mstar_mhal(hals, gals,\n",
    "                       wdir='./', nout=None,\n",
    "                       verbose=False):\n",
    "    if nout is None:\n",
    "        raise NameError(\"nout is not defined\")\n",
    "\n",
    "    good_gal = gals[\"Orig_halo_id\"]\n",
    "    mhal_result = hals[\"mvir\"]\n",
    "        \n",
    "    mstar = []\n",
    "    mhal = []\n",
    "    \n",
    "    for mhal_this, idgal in zip(mhal_result, good_gal):\n",
    "        gal = Gal(nout, idgal, wdir=wdir, load=False)\n",
    "        gal.load(cell=\"none\", dm=\"none\")\n",
    "        # There are only two options: gm or raw. \n",
    "        # Others are ignored.\n",
    "\n",
    "        gal.star['x'] -= gal.header['xg'][0]\n",
    "        gal.star['y'] -= gal.header['xg'][1]\n",
    "        gal.star['z'] -= gal.header['xg'][2]\n",
    "\n",
    "        # rescale\n",
    "        gal.star['x'] *= 1e3\n",
    "        gal.star['y'] *= 1e3\n",
    "        gal.star['z'] *= 1e3\n",
    "        gal.star['m'] *= 1e11\n",
    "        gal.meta = radial_profile_cut(gal.star)\n",
    "        if gal.meta is not False:\n",
    "            mstar.append(gal.meta.mtot)\n",
    "            mhal.append(mhal_this)\n",
    "        else:\n",
    "            if verbose: print(\"Galaxy profile failed\")\n",
    "            pass\n",
    "    \n",
    "    return mstar, mhal\n",
    "\n",
    "\n",
    "\n",
    "    # correct halo mass for extract substructure mass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/hoseung/Work/data/29172/GalaxyMaker/Trees/tree_0_0_0.dat'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/home/hoseung/Work/pyclusterevol/tree/treemodule.py\u001b[0m in \u001b[0;36mload_tree\u001b[0;34m(wdir, is_gal, no_dump, load_ascii)\u001b[0m\n\u001b[1;32m    153\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m             \u001b[0malltrees\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwdir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mext_tree_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_gal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_gal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Loaded an extended tree\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/hoseung/Work/data/29172/GalaxyMaker/Trees/extended_tree.pickle'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-8fc2bf2ef23b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcluster\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mclusters\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mwdir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/home/hoseung/Work/data/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcluster\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0mgt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_gal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m     \u001b[0mht\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_gal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/hoseung/Work/pyclusterevol/tree/treemodule.py\u001b[0m in \u001b[0;36mload_tree\u001b[0;34m(wdir, is_gal, no_dump, load_ascii)\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m             \u001b[0malltrees\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCTree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m             \u001b[0malltrees\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mwdir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtree_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'tree_0_0_0.dat'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m             \u001b[0;31m# Fix nout -----------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m             \u001b[0mnout_max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malltrees\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'nout'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/hoseung/Work/pyclusterevol/tree/treemodule.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self, filename)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_ascii\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_ascii\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/hoseung/Work/pyclusterevol/tree/treemodule.py\u001b[0m in \u001b[0;36m_load_ascii\u001b[0;34m(self, filename)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m180\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m                 \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/hoseung/Work/data/29172/GalaxyMaker/Trees/tree_0_0_0.dat'"
     ]
    }
   ],
   "source": [
    "from tree import ctutils as ctu\n",
    "\n",
    "from tree import halomodule as hmo\n",
    "from load.info import Info\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "matplotlib.use(\"Qt5Agg\")\n",
    "import matplotlib.pyplot as plt\n",
    "import tree.treemodule as tmo\n",
    "from load.rd_GM import Gal\n",
    "\n",
    "# Load galaxy catalog\n",
    "# and halo catalog\n",
    "clusters = [\"29172\"]\n",
    "nout_fi = 187\n",
    "\n",
    "#dominant = 0.4 # matched one should have less error by this amount or smaller \n",
    "                # compared to the second best matched one.\n",
    "\n",
    "#abs_tol_pos = 1e-2 # Position absolute tolerance [in Mpc]\n",
    "#abs_tol_vel = 100   # velocity absolute tolerance [in kms?]\n",
    "\n",
    "dts = [3,5]\n",
    "\n",
    "mstar_all = []\n",
    "mhal_all = []\n",
    "\n",
    "for cluster in clusters:\n",
    "    wdir = '/home/hoseung/Work/data/' + cluster + '/'\n",
    "    gt = tmo.load_tree(wdir, is_gal=True)\n",
    "    ht = tmo.load_tree(wdir, is_gal=False)\n",
    "    \n",
    "    \n",
    "    good_hals, good_gals = gal_hal_pair(cluster, gt, ht,\n",
    "                                         wdir = wdir,\n",
    "                                         dominant = 0.4,\n",
    "                                         abs_tol_pos = 1e-2,\n",
    "                                         abs_tol_vel = 100,\n",
    "                                         nout_fi = nout_fi,\n",
    "                                         dts = dts)\n",
    "    mstar_t, mhal_t = measure_mstar_mhal(good_hals, good_gals,\n",
    "                                         wdir=wdir,nout=nout_fi, verbose=False)\n",
    "    mstar_all.extend(mstar_t)\n",
    "    mhal_all.extend(mhal_t)\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "good_hals.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "i_gt_now = gt.data[\"nout\"] == 187\n",
    "i_ht_now = ht.data[\"nout\"] == 187\n",
    "\n",
    "plt.scatter(gt.data[\"x\"][i_gt_now], gt.data[\"y\"][i_gt_now], c='g', alpha=0.5)\n",
    "#plt.scatter(ht.data[\"x\"][i_ht_now], ht.data[\"y\"][i_ht_now], c='yellow', alpha=0.5)\n",
    "\n",
    "plt.scatter(good_hals[\"x\"], good_hals[\"y\"], c='r')\n",
    "plt.scatter(good_gals[\"x\"], good_gals[\"y\"], c='b')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
