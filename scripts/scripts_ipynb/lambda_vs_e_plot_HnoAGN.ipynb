{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data\n",
    "cats = pickle.load(open('./all_cats.pickle', 'rb'))\n",
    "for cnt, cat in enumerate(cats):\n",
    "    ind = np.isfinite(cat['eps'])\n",
    "    lambda_e.extend( cat['lambda_r'][ind])\n",
    "    eps.extend(cat['eps'][ind])\n",
    "\n",
    "    lambda_c.extend( cat['lambda_r'][ind])\n",
    "    stellarmass.extend( cat['mstar'][ind])\n",
    "    reff.extend( cat['reff'][ind])\n",
    "    ids.extend( cat['id'][ind] + cnt*10000) # annotation!\n",
    "    d2t.extend( cat['d2t'][ind])\n",
    "\n",
    "    rank.extend( 100*(np.argsort(cat['mstar'][ind])/sum(ind) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import utils.sampling as smp\n",
    "import matplotlib.pyplot as plt\n",
    "import tree\n",
    "import pickle\n",
    "import tree.halomodule as hmo\n",
    "import numpy as np\n",
    "from analysis.misc import load_cat\n",
    "import scipy.stats\n",
    "import tree.ctutils as ctu\n",
    "#from analysis.evol_lambda_HM import MainPrg\n",
    "import draw\n",
    "import load\n",
    "from utils import match\n",
    "from analysis.all_plot_modules import *\n",
    "\n",
    "\n",
    "def extract_main_tree(t, idx, fatherID, fatherMass):\n",
    "    t_now = t[idx]\n",
    "    nstep = t_now[\"nstep\"]\n",
    "    nouts = [nstep]\n",
    "    atree = np.zeros(nstep + 1, dtype=t.dtype)\n",
    "    atree[0]=t_now\n",
    "    \n",
    "    for i in range(1, nstep + 1):\n",
    "        try:\n",
    "            #print(t[\"flist_index\"][idx])\n",
    "            #id_father = fatherID[t[\"flist_index\"][idx]]\n",
    "            id_father = fatherID[idx]\n",
    "            #print(id_father)\n",
    "            #print(len(id_father))\n",
    "            if len(id_father) > 1:\n",
    "                #mass_father = fatherMass[t[\"flist_index\"][idx]]\n",
    "                mass_father = fatherMass[idx]\n",
    "                #print(mass_father)\n",
    "                id_father = id_father[np.argmax(mass_father)]\n",
    "                ind_father = id_father[id_father > 0] -1\n",
    "                \n",
    "                nstep -= 1\n",
    "                t_father = t[np.where(t[\"nstep\"] == nstep)[0]][ind_father]\n",
    "                idx = t_father[\"idx\"]\n",
    "                #print(idx)\n",
    "                atree[i]=t_father\n",
    "                nouts.append(nstep)\n",
    "            else:\n",
    "                break\n",
    "        except:\n",
    "            break\n",
    "    return atree\n",
    "\n",
    "\n",
    "def find_closest(A, target):\n",
    "    #A must be sorted\n",
    "    idx = A.searchsorted(target)\n",
    "    idx = np.clip(idx, 1, len(A)-1)\n",
    "    left = A[idx-1]\n",
    "    right = A[idx]\n",
    "    idx -= target - left < right - target\n",
    "    return idx\n",
    "\n",
    "\n",
    "def nout2nstep(data, nout):\n",
    "    return data[\"nstep\"][np.where(data[\"nout\"] == nout)]\n",
    "\n",
    "def nstep2nout(data, nstep):\n",
    "    try:\n",
    "        len(nstep)\n",
    "        import utils.match as mtc\n",
    "        ind = mtc.match_list_ind(data[\"nstep\"], nstep)\n",
    "    except:\n",
    "        ind = np.where(data[\"nstep\"] == nstep)[0]\n",
    "    return data[\"nout\"][ind]\n",
    "\n",
    "def zred2nout(data, nout):\n",
    "    return data[\"nstep\"][np.where(data[\"nout\"] == nout)]\n",
    "\n",
    "class MainPrg():\n",
    "    def __init__(self, idx, nnza):\n",
    "        \"\"\"\n",
    "            Separate tree data and lambda catalog data. \n",
    "            \n",
    "            early snapshot first.\n",
    "        \"\"\"\n",
    "        self.root_idx = idx\n",
    "        self.nsteps = nnza[\"nstep\"] # truncate later.\n",
    "        #self.idxs = np.zeros(len(nnza), dtype=int)\n",
    "        #self.ids = np.zeros(len(nnza), dtype=int)\n",
    "        self.nouts = nnza[\"nout\"]\n",
    "        self.zreds = nnza[\"zred\"]\n",
    "        self.aexps = 1/(1+self.zreds)       \n",
    "        \n",
    "    def initialize_data(self, cat, force=False):\n",
    "        if hasattr(self, \"data\"):\n",
    "            if not force:\n",
    "                print(\"self.data already exists. use force=True to re-initialize it.\")\n",
    "                pass\n",
    "        else:\n",
    "            self.data=np.zeros(len(self.nsteps),\n",
    "                                  dtype=cat.dtype)\n",
    "\n",
    "    def set_data(self, cat, nout):\n",
    "        ind = np.where(cat[\"tree_root_id\"] == self.root_idx)[0]\n",
    "        if len(ind) == 1:\n",
    "            #self.data\n",
    "            inout = np.where(self.nouts == nout)[0]\n",
    "            if len(inout) == 1:\n",
    "                self.data[inout] = cat[ind]\n",
    "                #self.id[inout] = cat[ind][\"id\"]\n",
    "    \n",
    "    def fill_missing_data(self):\n",
    "        assert (self.ids[0] != 0)\n",
    "        # position angles cannot be linearly interpolated.\n",
    "        # skip.\n",
    "        #\n",
    "        # position and velocity are also not that linear..\n",
    "        # but let me just interpolate them.\n",
    "        # \n",
    "        # excluded=[\"lambda_arr2\"]\n",
    "        filled_fields = [\"eps\", \"epsh\", \"epsq\", \"lambda_12kpc\",\n",
    "                         \"lambda_arr\", \"lambda_arrh\",\n",
    "                         \"lambda_r\",\"lambda_r12kpc\",\n",
    "                         \"lambda_r2\",\"lambda_rh\",\"mgas\",\"mrj\",\"mstar\",\n",
    "                         \"reff\",\"reff2\",\"rgal\",\"rgal2\",\"rscale_lambda\",\n",
    "                         \"sfr\",\"sma\",\"smah\",\"smaq\",\"smi\",\"smih\",\"smiq\",\"ssfr\",\n",
    "                         \"vxc\", \"vyc\", \"vzc\", \"xc\", \"yc\", \"zc\"]\n",
    "\n",
    "        i_good_max = max(np.where(self.data[\"reff\"] > 0)[0])\n",
    "        i_bad = np.where(self.data['idx'] == 0)[0]\n",
    "        i_bad = i_bad[i_bad < i_good_max]\n",
    "        if len(i_bad) > 0:\n",
    "            for field in filled_fields:\n",
    "                # do not modify index and id fields.\n",
    "                arr = self.data[field] # it's a view.\n",
    "\n",
    "                for i_b in i_bad:\n",
    "                    # neighbouring array might also be empty. Search for closest valid element.\n",
    "                    # left point\n",
    "                    i_l = i_b - 1 \n",
    "                    while(i_l in i_bad):\n",
    "                        i_l = i_l - 1 \n",
    "                    # right point\n",
    "                    i_r = i_b + 1 \n",
    "                    while(i_r in i_bad):\n",
    "                        i_r = i_r + 1 \n",
    "                    arr[i_b] = (arr[i_b -1] + arr[i_b +1])/2.\n",
    "    \n",
    "    def truncate(self):\n",
    "        imax = np.where(self.data[\"lambda_r\"] > 0)[0] + 1\n",
    "        self.nsteps = self.nsteps[:imax]\n",
    "        self.nouts = self.nouts[:imax]\n",
    "        self.zreds = self.zreds[:imax]\n",
    "        self.aexps = self.aexps[:imax]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depending Environments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from analysis.misc import load_cat\n",
    "from analysis.all_plot_modules import *\n",
    "from MajorMinorAccretion_module import *\n",
    "\n",
    "wdir = './Horizon-AGN/Horizon-noAGN/'\n",
    "#nout_fi = 782\n",
    "nout_fi=323\n",
    "\n",
    "nnza = np.genfromtxt(wdir + \"nout_nstep_zred_aexp.txt\",\n",
    "                     dtype=[(\"nout\", int),\n",
    "                            (\"nstep\", int),\n",
    "                            (\"zred\", float),\n",
    "                            (\"aexp\", float)])\n",
    "\n",
    "load_init = False\n",
    "if load_init:\n",
    "    mpgs = pickle.load(open(wdir + \"MPGS_init.pickle\", \"rb\"))\n",
    "else:\n",
    "    mpgs=[]\n",
    "    #samples = [0,1,2,3,4,6,7,8,9,10,11,12,13,15,16,17,18,19,20]\n",
    "    samples = [0,1,2,3,4,6,10,11,12,13,15,16,17,18]\n",
    "    for sample in samples:\n",
    "        # initialize mpgs\n",
    "        ss = str(sample)\n",
    "        f_cat = load_cat(wdir + 'lambda_results/' + ss + '/catalog' + str(nout_fi) + ss +'.pickle')\n",
    "        root_idx_all = f_cat['idx'][f_cat[\"idx\"] > 0].astype(int) # why idx are float???\n",
    "        for i, idx in enumerate(root_idx_all):\n",
    "            #atree = extract_main_tree(tt, idx, fatherID, fatherMass)\n",
    "            mpgs.append(MainPrg(idx, nnza))\n",
    "\n",
    "        # assign lambda measurement data\n",
    "        for nout in nnza[\"nout\"][:1]:\n",
    "            cat = load_cat(wdir + 'lambda_results/' + ss + '/catalog' + str(nout) + ss +'.pickle')\n",
    "            #print(nout)\n",
    "            for gal in mpgs:\n",
    "                if nout == nout_fi:\n",
    "                    gal.initialize_data(cat, force=True)\n",
    "                gal.set_data(cat, nout)\n",
    "        \n",
    "    for gal in mpgs:\n",
    "        gal.ids = gal.data[\"id\"]\n",
    "        gal.idxs = gal.data[\"idx\"]\n",
    "        #self.ids = np.zeros(len(nnza), dtype=int)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from tree import halomodule as hmo\n",
    "allgal = hmo.Halo(nout=nout_fi, is_gal=True, base=wdir)\n",
    "\n",
    "import load\n",
    "info = load.info.Info(nout=nout_fi, base=wdir)\n",
    "\n",
    "galidlist = []\n",
    "for gal in mpgs:\n",
    "    #print(gal.ids)\n",
    "    #plt.plot(np.log10(gal.data[\"mstar\"]))\n",
    "    galidlist.append(gal.ids[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xall = allgal.data[\"x\"]\n",
    "yall = allgal.data[\"y\"]\n",
    "zall = allgal.data[\"z\"]\n",
    "\n",
    "bins = np.linspace(0, 1, 20)\n",
    "\n",
    "xbin = np.digitize(xall, bins)\n",
    "ybin = np.digitize(yall, bins)\n",
    "zbin = np.digitize(zall, bins)\n",
    "\n",
    "dist_cut = 5/info.pboxsize\n",
    "\n",
    "d5 = []\n",
    "N5 = []\n",
    "for idgal in galidlist:\n",
    "#for igal in range(len(allgal.data)):\n",
    "    igal = np.where(allgal.data[\"id\"] == idgal)[0]\n",
    "    x_this = allgal.data[\"x\"][igal]\n",
    "    y_this = allgal.data[\"y\"][igal]\n",
    "    z_this = allgal.data[\"z\"][igal]\n",
    "    \n",
    "    # get subsample to speed up the code\n",
    "    xb_this = xbin[igal]\n",
    "    yb_this = ybin[igal]\n",
    "    zb_this = zbin[igal]\n",
    "    \n",
    "    first_candidates = allgal.data[(np.abs(xbin - xb_this) < 2) \\\n",
    "                                  * (np.abs(ybin - yb_this) < 2)\\\n",
    "                                  * (np.abs(zbin - zb_this) < 2)]\n",
    "    \n",
    "    dist = np.sqrt(np.square(first_candidates[\"x\"] - x_this) + \n",
    "                   np.square(first_candidates[\"y\"] - y_this) + \n",
    "                   np.square(first_candidates[\"z\"] - z_this))\n",
    "    #print(len(dist))\n",
    "    N5.append(sum(dist < dist_cut))\n",
    "    d5.append(np.sort(dist)[4] * info.pboxsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d5_80 = d5[np.argsort(d5)[np.ceil(0.8 * len(d5)).astype(int)]]\n",
    "i_isol = np.where(d5 >= d5_80)[0]\n",
    "isolated = [mpgs[i] for i in i_isol]\n",
    "\n",
    "d5_20 = d5[np.argsort(d5)[np.ceil(0.2 * len(d5)).astype(int)]]\n",
    "i_dense = np.where(d5 <= d5_20)[0]\n",
    "dense = [mpgs[i] for i in i_dense]\n",
    "\n",
    "eps_a = np.array([gal.data[\"eps\"][0] for gal in mpgs])\n",
    "lambda_a = np.array([gal.data[\"lambda_r\"][0] for gal in mpgs])\n",
    "\n",
    "eps_i = np.array([gal.data[\"eps\"][0] for gal in isolated])\n",
    "lambda_i = np.array([gal.data[\"lambda_r\"][0] for gal in isolated])\n",
    "\n",
    "eps_d = np.array([gal.data[\"eps\"][0] for gal in dense])\n",
    "lambda_d = np.array([gal.data[\"lambda_r\"][0] for gal in dense])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8874 1776 1774\n"
     ]
    }
   ],
   "source": [
    "print(len(eps_a), len(eps_d), len(eps_i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "atlas = np.genfromtxt('/home/hoseung/Work/data/ATLAS3D/Emsellem2011_Atlas3D_Paper3_TableB1.txt',\n",
    "                      skip_header=12,\n",
    "                      usecols=(2,7))\n",
    "twocolors=['#4c72b0', '#c44e52']\n",
    "\n",
    "\n",
    "do_plot(eps_a, lambda_a, atlas,\n",
    "        do_scatter=False,\n",
    "        contour_label=False,\n",
    "        surf = False,\n",
    "        img_scale = 2.0,\n",
    "        twocolors=twocolors,\n",
    "        den_cmap = \"YlGnBu_r\",\n",
    "        d_alpha=1.0,\n",
    "        levels=None,#np.linspace(0.02, 1.0, 19),\n",
    "        fname_vs_e = \"./figs/lambda_vs_e_allEnvNH\")\n",
    "\n",
    "do_plot(eps_i, lambda_i, atlas,\n",
    "        do_scatter=False,\n",
    "        contour_label=False,\n",
    "        surf = False,\n",
    "        img_scale = 2.0,\n",
    "        twocolors=twocolors,\n",
    "        den_cmap = \"YlGnBu_r\",\n",
    "        d_alpha=1.0,\n",
    "        levels=None,#np.linspace(0.02, 1.0, 19),\n",
    "        fname_vs_e = \"./figs/lambda_vs_e_isolNH\")\n",
    "\n",
    "do_plot(eps_d, lambda_d, atlas,\n",
    "        do_scatter=False,\n",
    "        contour_label=False,\n",
    "        surf = False,\n",
    "        img_scale = 2.0,\n",
    "        twocolors=twocolors,\n",
    "        den_cmap = \"YlGnBu_r\",\n",
    "        d_alpha=1.0,\n",
    "        levels=None,#np.linspace(0.02, 1.0, 19),\n",
    "        fname_vs_e = \"./figs/lambda_vs_e_denseNH\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Discrete levels\n",
    "do_scatter=True\n",
    "contour_label=False\n",
    "surf = False\n",
    "\n",
    "\n",
    "import itertools\n",
    "for levels in [np.linspace(0.01, 1.0, 19), None]:\n",
    "    for combination in itertools.product(*[(True, False)]*3):\n",
    "        do_scatter, contour_label, surf = combination\n",
    "        do_plot(x,y, \n",
    "                do_scatter=do_scatter,\n",
    "                contour_label=contour_label,\n",
    "                surf = surf,\n",
    "                img_scale = 2.0,\n",
    "                twocolors=twocolors,\n",
    "                den_cmap = \"PuBu\",\n",
    "                levels=levels,\n",
    "                fname_vs_e = \"./figs/lambda_vs_e_z0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
